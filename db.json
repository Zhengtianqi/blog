{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/img/Git工作流程.png","path":"img/Git工作流程.png","modified":1,"renderable":0},{"_id":"source/img/TCPIP用户发送请求.png","path":"img/TCPIP用户发送请求.png","modified":1,"renderable":0},{"_id":"source/img/TCPIP服务器接收请求.png","path":"img/TCPIP服务器接收请求.png","modified":1,"renderable":0},{"_id":"source/img/java对象存储.png","path":"img/java对象存储.png","modified":1,"renderable":0},{"_id":"source/img/java对象存储3.png","path":"img/java对象存储3.png","modified":1,"renderable":0},{"_id":"source/img/clip_image002.png","path":"img/clip_image002.png","modified":1,"renderable":0},{"_id":"source/img/maven配置.png","path":"img/maven配置.png","modified":1,"renderable":0},{"_id":"source/img/java对象存储2.png","path":"img/java对象存储2.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序2.png","path":"img/mysql排序2.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序1.png","path":"img/mysql排序1.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序4.png","path":"img/mysql排序4.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序6.png","path":"img/mysql排序6.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序5.png","path":"img/mysql排序5.png","modified":1,"renderable":0},{"_id":"source/img/nacos-springCloud1.png","path":"img/nacos-springCloud1.png","modified":1,"renderable":0},{"_id":"source/img/nacos1.png","path":"img/nacos1.png","modified":1,"renderable":0},{"_id":"source/img/nacos-producer.png","path":"img/nacos-producer.png","modified":1,"renderable":0},{"_id":"source/img/secondaryNameNode.jpg","path":"img/secondaryNameNode.jpg","modified":1,"renderable":0},{"_id":"source/img/nacos-springCloud2.png","path":"img/nacos-springCloud2.png","modified":1,"renderable":0},{"_id":"source/img/pasted-0.png","path":"img/pasted-0.png","modified":1,"renderable":0},{"_id":"source/img/三次握手协议1.png","path":"img/三次握手协议1.png","modified":1,"renderable":0},{"_id":"source/img/wordcount.png","path":"img/wordcount.png","modified":1,"renderable":0},{"_id":"source/img/信任链.png","path":"img/信任链.png","modified":1,"renderable":0},{"_id":"source/img/三次握手协议2.png","path":"img/三次握手协议2.png","modified":1,"renderable":0},{"_id":"source/img/使用协议进行通讯.png","path":"img/使用协议进行通讯.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥6.png","path":"img/公钥私钥6.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥8.png","path":"img/公钥私钥8.png","modified":1,"renderable":0},{"_id":"source/img/加密算法.png","path":"img/加密算法.png","modified":1,"renderable":0},{"_id":"source/img/可信根.png","path":"img/可信根.png","modified":1,"renderable":0},{"_id":"source/img/对称加密算法.png","path":"img/对称加密算法.png","modified":1,"renderable":0},{"_id":"source/img/线程相关1.jpg","path":"img/线程相关1.jpg","modified":1,"renderable":0},{"_id":"source/img/数据库分布式ID生成.png","path":"img/数据库分布式ID生成.png","modified":1,"renderable":0},{"_id":"source/img/线程相关2.jpg","path":"img/线程相关2.jpg","modified":1,"renderable":0},{"_id":"source/img/线程相关3.jpg","path":"img/线程相关3.jpg","modified":1,"renderable":0},{"_id":"source/img/线程相关4.jpg","path":"img/线程相关4.jpg","modified":1,"renderable":0},{"_id":"source/img/线程相关5.jpg","path":"img/线程相关5.jpg","modified":1,"renderable":0},{"_id":"source/img/锁的创建.png","path":"img/锁的创建.png","modified":1,"renderable":0},{"_id":"source/img/阻塞IO.png","path":"img/阻塞IO.png","modified":1,"renderable":0},{"_id":"source/img/锁的创建2.png","path":"img/锁的创建2.png","modified":1,"renderable":0},{"_id":"source/img/雪花算法.png","path":"img/雪花算法.png","modified":1,"renderable":0},{"_id":"source/img/HTTPS2.png","path":"img/HTTPS2.png","modified":1,"renderable":0},{"_id":"source/img/HTTPS3.png","path":"img/HTTPS3.png","modified":1,"renderable":0},{"_id":"source/img/HTTPS4.png","path":"img/HTTPS4.png","modified":1,"renderable":0},{"_id":"source/img/HTTPS5.png","path":"img/HTTPS5.png","modified":1,"renderable":0},{"_id":"source/img/Spark.png","path":"img/Spark.png","modified":1,"renderable":0},{"_id":"source/img/IO复用select模型.png","path":"img/IO复用select模型.png","modified":1,"renderable":0},{"_id":"source/img/TCP协议通讯过程.png","path":"img/TCP协议通讯过程.png","modified":1,"renderable":0},{"_id":"source/img/clip_image004.png","path":"img/clip_image004.png","modified":1,"renderable":0},{"_id":"source/img/hdfs-read-file.png","path":"img/hdfs-read-file.png","modified":1,"renderable":0},{"_id":"source/img/mysql的ip存储.png","path":"img/mysql的ip存储.png","modified":1,"renderable":0},{"_id":"source/img/mysql时间存储.png","path":"img/mysql时间存储.png","modified":1,"renderable":0},{"_id":"source/img/wordcount-map.png","path":"img/wordcount-map.png","modified":1,"renderable":0},{"_id":"source/img/wordcount-split.png","path":"img/wordcount-split.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥1.png","path":"img/公钥私钥1.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥10.png","path":"img/公钥私钥10.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥11.png","path":"img/公钥私钥11.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥2.png","path":"img/公钥私钥2.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥13.png","path":"img/公钥私钥13.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥3.png","path":"img/公钥私钥3.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥4.png","path":"img/公钥私钥4.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥5.png","path":"img/公钥私钥5.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥7.png","path":"img/公钥私钥7.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥9.png","path":"img/公钥私钥9.png","modified":1,"renderable":0},{"_id":"source/img/指针压缩2.png","path":"img/指针压缩2.png","modified":1,"renderable":0},{"_id":"source/img/指针压缩4.png","path":"img/指针压缩4.png","modified":1,"renderable":0},{"_id":"source/img/指针压缩3.png","path":"img/指针压缩3.png","modified":1,"renderable":0},{"_id":"source/img/非对称加密算法.png","path":"img/非对称加密算法.png","modified":1,"renderable":0},{"_id":"source/img/HTTPS1.png","path":"img/HTTPS1.png","modified":1,"renderable":0},{"_id":"source/img/SpringBean3.png","path":"img/SpringBean3.png","modified":1,"renderable":0},{"_id":"source/img/TCP协议通讯过程2.png","path":"img/TCP协议通讯过程2.png","modified":1,"renderable":0},{"_id":"source/img/Yarn.png","path":"img/Yarn.png","modified":1,"renderable":0},{"_id":"source/img/mysql排序3.png","path":"img/mysql排序3.png","modified":1,"renderable":0},{"_id":"source/img/spark+hdfs.png","path":"img/spark+hdfs.png","modified":1,"renderable":0},{"_id":"source/img/椭圆曲线算法的基本原理.png","path":"img/椭圆曲线算法的基本原理.png","modified":1,"renderable":0},{"_id":"source/img/非阻塞IO.png","path":"img/非阻塞IO.png","modified":1,"renderable":0},{"_id":"themes/3-hexo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/img/school-book.png","path":"img/school-book.png","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","path":"img/article-list-background.jpeg","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/img/brown-papersq.png","path":"img/brown-papersq.png","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/mobile.styl","path":"css/mobile.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/tomorrow-night.scss","path":"css/tomorrow-night.scss","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","path":"js/jquery.autocomplete.min.js","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","path":"js/jquery.pjax.js","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/iconfont.js","path":"js/iconfont.js","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/search.js","path":"js/search.js","modified":1,"renderable":1},{"_id":"source/img/HTTPS6.png","path":"img/HTTPS6.png","modified":1,"renderable":0},{"_id":"source/img/hdfs.png","path":"img/hdfs.png","modified":1,"renderable":0},{"_id":"source/img/hdfs-write-file.png","path":"img/hdfs-write-file.png","modified":1,"renderable":0},{"_id":"source/img/spark-all.png","path":"img/spark-all.png","modified":1,"renderable":0},{"_id":"source/img/公钥私钥12.png","path":"img/公钥私钥12.png","modified":1,"renderable":0},{"_id":"source/img/指针压缩1.png","path":"img/指针压缩1.png","modified":1,"renderable":0},{"_id":"source/img/混合加密的方式.png","path":"img/混合加密的方式.png","modified":1,"renderable":0},{"_id":"themes/3-hexo/source/img/weixin.jpg","path":"img/weixin.jpg","modified":1,"renderable":1},{"_id":"source/img/TCP协议通讯过程1.png","path":"img/TCP协议通讯过程1.png","modified":1,"renderable":0},{"_id":"source/img/主动免疫可信架构信任链传递示意图.png","path":"img/主动免疫可信架构信任链传递示意图.png","modified":1,"renderable":0},{"_id":"source/img/可信在云平台的基础架构.png","path":"img/可信在云平台的基础架构.png","modified":1,"renderable":0},{"_id":"source/img/四次挥手协议.png","path":"img/四次挥手协议.png","modified":1,"renderable":0},{"_id":"source/img/读写锁.png","path":"img/读写锁.png","modified":1,"renderable":0},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","path":"css/fonts/icomoon.eot","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","path":"css/fonts/icomoon.woff","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","path":"css/fonts/iconfont.eot","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","path":"css/fonts/icomoon.ttf","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","path":"css/hl_theme/atom-dark.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","path":"css/fonts/iconfont.ttf","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/selection.json","path":"css/fonts/selection.json","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","path":"css/hl_theme/brown-paper.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","path":"css/fonts/iconfont.woff","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","path":"css/hl_theme/github-gist.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","path":"css/hl_theme/atom-light.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","path":"css/hl_theme/darcula.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","path":"css/hl_theme/kimbie-dark.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","path":"css/hl_theme/kimbie-light.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","path":"css/hl_theme/github.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","path":"css/hl_theme/gruvbox-dark.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","path":"css/hl_theme/railscasts.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","path":"css/hl_theme/gruvbox-light.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","path":"css/hl_theme/school-book.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","path":"css/hl_theme/rainbow.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","path":"css/hl_theme/sunburst.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","path":"css/hl_theme/sublime.styl","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","path":"css/hl_theme/zenbum.styl","modified":1,"renderable":1},{"_id":"source/img/wordcount-reduce.png","path":"img/wordcount-reduce.png","modified":1,"renderable":0},{"_id":"source/img/对象存储1.png","path":"img/对象存储1.png","modified":1,"renderable":0},{"_id":"source/img/阻塞与非阻塞调用对比.png","path":"img/阻塞与非阻塞调用对比.png","modified":1,"renderable":0},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","path":"css/fonts/icomoon.svg","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","path":"css/fonts/iconfont.svg","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/gitment.js","path":"js/gitment.js","modified":1,"renderable":1},{"_id":"themes/3-hexo/source/js/gitalk.js","path":"js/gitalk.js","modified":1,"renderable":1},{"_id":"source/img/Socket通讯模型.png","path":"img/Socket通讯模型.png","modified":1,"renderable":0},{"_id":"source/img/三次握手协议3.png","path":"img/三次握手协议3.png","modified":1,"renderable":0},{"_id":"source/img/select、epoll模型对比.png","path":"img/select、epoll模型对比.png","modified":1,"renderable":0},{"_id":"source/img/四次挥手协议2.png","path":"img/四次挥手协议2.png","modified":1,"renderable":0},{"_id":"source/img/网络连接模型.png","path":"img/网络连接模型.png","modified":1,"renderable":0}],"Cache":[{"_id":"themes/3-hexo/.DS_Store","hash":"0770f9d42bfdd8d420de48fed463015e001cf579","modified":1566357905093},{"_id":"themes/3-hexo/.gitignore","hash":"560a43fddfe4559ed1a17e7362874454519f189b","modified":1566357905094},{"_id":"themes/3-hexo/README.md","hash":"754d6f873d73f4a7faf5530fa4062e9a696a8fd4","modified":1571110367855},{"_id":"themes/3-hexo/_config.yml","hash":"2bd8fb1dcf031d97ec25251dcbd9f7f928b61334","modified":1571142777564},{"_id":"source/_discarded/hello-world.md","hash":"3de445ce428eb9d987b765b94bd6e0428eaebdbc","modified":1567305094926},{"_id":"source/_posts/MapReduce概述.md","hash":"e24632c1742518951c8b5bb2b378a54a7cc8dbac","modified":1576490842822},{"_id":"source/_posts/HDFS文件操作.md","hash":"02424d27fdab1eab02babaf246e4c4f09edf904a","modified":1576487061726},{"_id":"source/_posts/HDFS概述.md","hash":"f93a0a44dd6c86d661add6adb695ac900dad5e16","modified":1576482443395},{"_id":"source/_posts/Git梳理.md","hash":"d0a674882ec53bb07989a7f0dfaba94e0799342a","modified":1571142092785},{"_id":"source/_posts/Nacos配置中心使用.md","hash":"36f687e96443079769f0417538326b29b8c77510","modified":1574740644175},{"_id":"source/_posts/SimpleDateFormat引发的线程安全问题.md","hash":"d8c4c82a697598498aa98a78adab7cb0b0c383b6","modified":1570882111315},{"_id":"source/_posts/Spring-Bean生命周期.md","hash":"cce576cd1e7c9260398e5ce7dbbf93f78ad65fa3","modified":1573723161652},{"_id":"source/_posts/Spark相关概述.md","hash":"51e1ebe27a5fddc703347127dd8c172e6515fc64","modified":1576660372500},{"_id":"source/_posts/SpringCloud-Alibaba整合Nacos.md","hash":"e4ecde183bb14dec6b4fea7060757d8bb3674cd8","modified":1575357455263},{"_id":"source/_posts/SpringCloud-Alibaba整合Nacos服务注册发现.md","hash":"9421a39ea2426ef3f0d785148671b14f946bd332","modified":1575360178242},{"_id":"source/_posts/TCP握手、挥手协议.md","hash":"96dbca102e299efdb9666bb4d7d5c489c7f31c31","modified":1571134169423},{"_id":"source/_posts/TCP-IP四层网络模型.md","hash":"ad3086d71dd922d2a5fbf1e53d45ed848ebd16dd","modified":1571141979272},{"_id":"source/_posts/WordCount简析.md","hash":"ed975037b0341d6c16022e5914f000ac38f00a4d","modified":1576641550021},{"_id":"source/_posts/Yarn概述.md","hash":"b126a9351edb7982bb71c5a55d509408c6b51c84","modified":1576635779255},{"_id":"source/_posts/java8新特性.md","hash":"f4389eb1abf000d7ff97b9a8cedc1dac2030f4b7","modified":1573720237235},{"_id":"source/_posts/mysql排序.md","hash":"b4a56da0c4b2024b2bbe87c8450cd3076106282a","modified":1574753513949},{"_id":"source/_posts/maven梳理.md","hash":"a21cc6519d6d4afe06493568a44b07f9a536ac74","modified":1571141975470},{"_id":"source/_posts/公平锁、非公平锁.md","hash":"7d520324daf56a0c36885fef17f2366800438a0f","modified":1571133968660},{"_id":"source/_posts/偏向锁.md","hash":"5bb85337ff166be22f9619b09d9071e49e1f63ef","modified":1571144126116},{"_id":"source/_posts/互斥锁.md","hash":"a2a6a0b26fd73482c98c84867c93c02e851c9fb0","modified":1571134239998},{"_id":"source/_posts/mysql表设计及优化.md","hash":"1e592b36e153b129de094310283598e4694a75fa","modified":1571134218948},{"_id":"source/_posts/可信与可信计算.md","hash":"622f1a97783b9830838ec63f7eafd319107daf78","modified":1571134041402},{"_id":"source/_posts/分布式全局唯一ID生成策略.md","hash":"a060a38e0f2c4a5ef4633cc2be911bcd9a1bb64e","modified":1571133944357},{"_id":"source/_posts/加密解密.md","hash":"edf660583a53e0d44ba9a0a74785a3c5a98b6626","modified":1571143218778},{"_id":"source/_posts/可靠性和容错技术.md","hash":"a397449f53f9042cb8de56580572210a9d18ba2e","modified":1569998915455},{"_id":"source/_posts/可信基本概念.md","hash":"8e83f8be54cd21559f858755e6abb9ea577c487f","modified":1571134252269},{"_id":"source/_posts/对象存储与指针压缩.md","hash":"690c2453d97b741ffe8dcdfeb93d81d787c0bcfd","modified":1574251423218},{"_id":"source/_posts/可重入锁.md","hash":"a62dbbe3f15a6527490ea786371b62b31f782e79","modified":1571134060790},{"_id":"source/_posts/图解公钥与私钥.md","hash":"0a89b8fa785c291ff753fdfaa6bcc7668d80e733","modified":1569333117731},{"_id":"source/_posts/文件上传.md","hash":"b77879b87814fef9745a3a203e53c79db3c5cebe","modified":1571141394589},{"_id":"source/_posts/悲观锁、乐观锁.md","hash":"d18befc289385445e68c92be35441c0aaaf692c3","modified":1571141864237},{"_id":"source/_posts/理解IO阻塞与非阻塞.md","hash":"8aa3817b497cd4acc5559f9f811da0514abeaf13","modified":1567159309767},{"_id":"source/_posts/数字签名.md","hash":"bf07570f5afa7175d432492564c548654191a38e","modified":1571142533710},{"_id":"source/_posts/池化之线程池.md","hash":"c77f5acddf612ad5f2743864bf4edcc4a6dd6786","modified":1571133890697},{"_id":"source/_posts/自旋锁.md","hash":"d7fe8a130eba821be23ddb2c9e6aea2b0b2d2b67","modified":1567227561273},{"_id":"source/_posts/读写锁.md","hash":"3e17aded1f87f787910f807cf8696e0b2d428c3d","modified":1571133919181},{"_id":"source/_posts/重放攻击.md","hash":"b00712cae3ee556704f0f0163aba3a45da842264","modified":1567603483315},{"_id":"source/_posts/线程相关的知识.md","hash":"dae1ea9b088c4125eb2a0d41bae42c9d5bbdc94b","modified":1574250624878},{"_id":"source/_posts/轻量级锁.md","hash":"fbf5342b86be3b20dca77f472c390340256d49ec","modified":1567235430223},{"_id":"source/_posts/锁粗化.md","hash":"d96860384ca8bdd805950ce24cfb782282c6b178","modified":1571142931866},{"_id":"source/_posts/阻塞锁.md","hash":"bc39dd0b2789e9b4efaa084473dbbd7f0545ff26","modified":1567227873756},{"_id":"source/img/Git工作流程.png","hash":"13f5329292c5f0b42cb969b2981141981bc62c12","modified":1567048479116},{"_id":"source/img/TCPIP用户发送请求.png","hash":"f4428ca4bf21e4d067da5b944bb742892939d131","modified":1567149324326},{"_id":"source/img/TCPIP服务器接收请求.png","hash":"dd6986ec9df5f3ffe5ff743e97408b53147743fc","modified":1567149345292},{"_id":"source/img/java对象存储.png","hash":"78231e4a1c56b2078cdd4454d20593ba3e2b48e3","modified":1567229269140},{"_id":"source/img/java对象存储3.png","hash":"4b83f6c1accd8ea2753e0dc16f52820d52abb700","modified":1574250991794},{"_id":"source/img/clip_image002.png","hash":"773f0b16657a294e5b51f44c9adc7cf0d4813728","modified":1573721616774},{"_id":"source/img/maven配置.png","hash":"c966dcfb8e36138b51cbaa08a8e15bc73a615778","modified":1567045274281},{"_id":"source/img/java对象存储2.png","hash":"a5e540b6699183dcad89a9912c25c6a0c5eed9f3","modified":1574250903564},{"_id":"source/img/mysql排序2.png","hash":"0f0e1c1417f85b8e5f7bf1bb929ad63223569faf","modified":1574253839369},{"_id":"source/img/mysql排序1.png","hash":"09e8d6d507cd2b06ed4e6e9a76c832e226981ed0","modified":1574253764887},{"_id":"source/img/mysql排序4.png","hash":"9ef66bb2173d553fb58106a4959b3c0a5751d482","modified":1574254046965},{"_id":"source/img/mysql排序6.png","hash":"254e269dc8da6b5358e883e82a16c52243a4286e","modified":1574254481724},{"_id":"source/img/mysql排序5.png","hash":"044b6bc8c3b4d33f3a25598b9b99771efe75bccf","modified":1574254222538},{"_id":"source/img/nacos-springCloud1.png","hash":"afd0806eb1d72ed4988811e08d1c2e7cb621682b","modified":1574848818956},{"_id":"source/img/nacos1.png","hash":"07c9cfee060b4090c04d5a9d422b97e2dd1cbbd2","modified":1574671501527},{"_id":"source/img/nacos-producer.png","hash":"36eefd319d40a5a11e9343d3d817d66098d9d043","modified":1575358053823},{"_id":"source/img/secondaryNameNode.jpg","hash":"6186b1ee9e43435bafb7abefde1824d5f66e8f8b","modified":1576479793155},{"_id":"source/img/nacos-springCloud2.png","hash":"6ce7c90123f1a1eb0e3ebbe93ae50eded7392603","modified":1574848848065},{"_id":"source/img/pasted-0.png","hash":"d4f20b5880ebe1cd4114af86e182d3a8042f29b6","modified":1571142530740},{"_id":"source/img/三次握手协议1.png","hash":"b7cf27e8ba8b7e299c4e02519394600d0269ae84","modified":1567152263777},{"_id":"source/img/wordcount.png","hash":"78dbf6fe038d27891bb860321f1087fa9f642e3c","modified":1576488969747},{"_id":"source/img/信任链.png","hash":"23517850fc98c07ad66d80bac4556b77e0688214","modified":1569663179090},{"_id":"source/img/三次握手协议2.png","hash":"149fa2d315b1471325a89b68ee659409c709c10c","modified":1567152281871},{"_id":"source/img/使用协议进行通讯.png","hash":"fe93735a4d871a544feb31b0b713f98ab4c715fb","modified":1567157267759},{"_id":"source/img/公钥私钥6.png","hash":"c7104a322604a0b51de2d988bd9522b5deab2045","modified":1569332262735},{"_id":"source/img/公钥私钥8.png","hash":"6b13644b98068f7f44ddb51532f17030906031c0","modified":1569332306598},{"_id":"source/img/加密算法.png","hash":"5a0a4d8fbdc43f929dd5aa86aded45086ba38cbb","modified":1571142476298},{"_id":"source/img/可信根.png","hash":"875a1cdae0d77993f07a1df1dd968f907a2c1d1e","modified":1569664599137},{"_id":"source/img/对称加密算法.png","hash":"6a7ed179fb8b48e9054caba56308b1691b6ebe92","modified":1567425941515},{"_id":"source/img/线程相关1.jpg","hash":"cd2dfeb2b0a367d208e46d1fec4ed9241164256e","modified":1574250522288},{"_id":"source/img/数据库分布式ID生成.png","hash":"7376ea76ee62cc47d2e0389f90ca9fa1a3173f74","modified":1570600820250},{"_id":"source/img/线程相关2.jpg","hash":"2146aff9f267536a9a49fac7c34267380cb8dea5","modified":1574250550341},{"_id":"source/img/线程相关3.jpg","hash":"2146aff9f267536a9a49fac7c34267380cb8dea5","modified":1574250560177},{"_id":"source/img/线程相关4.jpg","hash":"3268689c6020136cda73d95d1553dfa6816aa60b","modified":1574250574158},{"_id":"source/img/线程相关5.jpg","hash":"54f4bd928b107b4da2faaa87fa74484b76900c0b","modified":1574250583745},{"_id":"source/img/锁的创建.png","hash":"ac72c945c263be025d83970d2cfdb6c240c38bbc","modified":1571144077063},{"_id":"source/img/阻塞IO.png","hash":"f5cfd961b871078b9b202d1e8d4810f3f126aaef","modified":1567157770850},{"_id":"source/img/锁的创建2.png","hash":"ebf05f8b81c02d9c880b9081e9ccc0b2b6c5e4ae","modified":1571144110083},{"_id":"source/img/雪花算法.png","hash":"522b23e1a5bc4bdf46b1d285233d815004847271","modified":1570600786906},{"_id":"themes/3-hexo/.git/FETCH_HEAD","hash":"d1870580b3e08daea5698a4cf75a6daaba7a25a1","modified":1574051434654},{"_id":"themes/3-hexo/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1566357905055},{"_id":"themes/3-hexo/.git/ORIG_HEAD","hash":"36e1610a86bddf4a3dd3b00a29a138d2168f7624","modified":1574051434764},{"_id":"themes/3-hexo/.git/config","hash":"e0bfd9b35852beab6bb3aa547e10d0805cbdf751","modified":1566357905068},{"_id":"themes/3-hexo/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1566357867204},{"_id":"themes/3-hexo/.git/index","hash":"3b1703f7df0df27d3fbd5572ce5ea06ca7000d91","modified":1575181306498},{"_id":"themes/3-hexo/.git/packed-refs","hash":"12c6a6c5d8c824d9777819513a9105d201be16c1","modified":1566357905044},{"_id":"themes/3-hexo/layout/index.ejs","hash":"a5c464897e7dc9d45d03d8b61e742b1ac4173a95","modified":1566357905106},{"_id":"themes/3-hexo/layout/post.ejs","hash":"aeda285031ba8d4e94225e82b364bcf5f79fce1d","modified":1566357905107},{"_id":"themes/3-hexo/layout/indexs.md","hash":"74f41909ea63fb6e9599a5d9bb3d164d9b2ea8d3","modified":1567325571619},{"_id":"themes/3-hexo/source/.DS_Store","hash":"fdcc907c46e093a14b153c5dc8c038461997ed3c","modified":1566357905108},{"_id":"source/img/HTTPS2.png","hash":"b792dee35f602f38fce149164dad4593c64a9650","modified":1569332481676},{"_id":"source/img/HTTPS3.png","hash":"e3e58b8e4961a4533ac2a63154aee3c49322e379","modified":1569332500332},{"_id":"source/img/HTTPS4.png","hash":"98c925d3de7c588950cb1ce2be36b3346a0ee848","modified":1569332518053},{"_id":"source/img/HTTPS5.png","hash":"7f96023634200693631288ec5047f024ee53f91c","modified":1569332538597},{"_id":"source/img/Spark.png","hash":"ab45bdfcdd54f893ab046360fea5ccd51b887b3f","modified":1576647742604},{"_id":"source/img/IO复用select模型.png","hash":"9f0c021b9b258025552f261e3ab8cbb2f96093ad","modified":1567157813191},{"_id":"source/img/TCP协议通讯过程.png","hash":"46efae085ca09e1445b9eac506c02c3462e2a16b","modified":1567157460145},{"_id":"source/img/clip_image004.png","hash":"762418fea78372f2c8b67fc6f4dffb7045e9d449","modified":1573721637689},{"_id":"source/img/hdfs-read-file.png","hash":"861f90f65c5c1eac3ffea16430c75833aff5e089","modified":1576482855424},{"_id":"source/img/mysql的ip存储.png","hash":"d06d3619438f57be43aa1236ec9ace4e1bf3d126","modified":1567298167198},{"_id":"source/img/mysql时间存储.png","hash":"1db17e59e7b6dad480009153803c159d5a97cbfe","modified":1567298126454},{"_id":"source/img/wordcount-map.png","hash":"a1c10dc70e0fdef09e3db7f305e16cd2fdf631a1","modified":1576489400587},{"_id":"source/img/wordcount-split.png","hash":"27610016538c3dca06409dcfbd57f8a805f86624","modified":1576489083300},{"_id":"source/img/公钥私钥1.png","hash":"498ea1f36ce52b0ff2964c9423bf5eb5ab0ae804","modified":1569332132500},{"_id":"source/img/公钥私钥10.png","hash":"767005c089b3be3b91213d12fab4e462718a7787","modified":1569332359302},{"_id":"source/img/公钥私钥11.png","hash":"10755e3bcfc39d9bf3c8b9b5060ec5682a18cad3","modified":1569332383529},{"_id":"source/img/公钥私钥2.png","hash":"c60ac4f1a39665d9a2b923f3a78541fc663b0e6b","modified":1569332150578},{"_id":"source/img/公钥私钥13.png","hash":"afd0297e43e61b9193b6dcbf9a71da610938dd2f","modified":1569332430586},{"_id":"source/img/公钥私钥3.png","hash":"63b5f3e415343c2a65d3274fe8d6e4ce4c26f490","modified":1569332201849},{"_id":"source/img/公钥私钥4.png","hash":"683543865f578ea89be62b1af374df4de0f42069","modified":1569332222890},{"_id":"source/img/公钥私钥5.png","hash":"b2721631bbbac0306b12e70466fa49531f8bae30","modified":1569332242107},{"_id":"source/img/公钥私钥7.png","hash":"e7f712acb8d5e47d717f18494d4c5e22ea9b5468","modified":1569332285257},{"_id":"source/img/公钥私钥9.png","hash":"4c4d25e78aea05b34ccf9cd0c5025cfcb7bf94e3","modified":1569332337273},{"_id":"source/img/指针压缩2.png","hash":"2db8b3b15563eedb0a35b192c37760fec8f9c8fa","modified":1574251229188},{"_id":"source/img/指针压缩4.png","hash":"945b359ce34488105eab6422d8f397d8c76b4ea0","modified":1574251320221},{"_id":"source/img/指针压缩3.png","hash":"f142f7d0e15d58e03d02d99c0eba541e51e30a7f","modified":1574251277019},{"_id":"source/img/非对称加密算法.png","hash":"260798ec83168388a70e55c60b1a7e5a47e78246","modified":1567425887927},{"_id":"source/img/HTTPS1.png","hash":"2cc9b05768fb05bd25da12dd3428e6f02dfe50ec","modified":1569332459290},{"_id":"source/img/SpringBean3.png","hash":"2b96172eecc1cbd1e41ab9756c0a12836ebad948","modified":1573721725755},{"_id":"source/img/TCP协议通讯过程2.png","hash":"9ae8696d16fd4ffdc46b6c005b598999dec3f9c1","modified":1567157484636},{"_id":"source/img/Yarn.png","hash":"8b15f23ee56b0f7e2e5aa00157c1de50a0979da7","modified":1576631940342},{"_id":"source/img/mysql排序3.png","hash":"a91f727d4c99fb6289678a86f64ddd1c246568c7","modified":1574253993339},{"_id":"source/img/spark+hdfs.png","hash":"5ea801d62e8a34b8f08c627826d7f71369c2b749","modified":1576649860216},{"_id":"source/img/椭圆曲线算法的基本原理.png","hash":"5f848a66630c6ba515286fa96dc36ed3a9a11106","modified":1567343921566},{"_id":"themes/3-hexo/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1566357867243},{"_id":"themes/3-hexo/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1566357867210},{"_id":"themes/3-hexo/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1566357867218},{"_id":"themes/3-hexo/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1566357867222},{"_id":"themes/3-hexo/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1566357867213},{"_id":"themes/3-hexo/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1566357867216},{"_id":"themes/3-hexo/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1566357867232},{"_id":"themes/3-hexo/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1566357867227},{"_id":"themes/3-hexo/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1566357867225},{"_id":"themes/3-hexo/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1566357867235},{"_id":"themes/3-hexo/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1566357867237},{"_id":"themes/3-hexo/.git/logs/HEAD","hash":"8b723d9f01348f811c9a75afbb7486873dc1d656","modified":1571110367864},{"_id":"themes/3-hexo/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1566357867229},{"_id":"source/img/非阻塞IO.png","hash":"58573268ff130afca209099ecda84d1c4eeff17f","modified":1567157791409},{"_id":"themes/3-hexo/layout/_partial/comment.ejs","hash":"d18f94e04ef0cf7abb432a8e707ccb3abc7fe435","modified":1566357905097},{"_id":"themes/3-hexo/layout/_partial/article.ejs","hash":"d3c928954057bcebdf3fc294b2123885b08396d3","modified":1571110367856},{"_id":"themes/3-hexo/layout/_partial/copyright.ejs","hash":"faffe25aec33936fa2ec9d8f0e34e16ef3d90c25","modified":1566357905100},{"_id":"themes/3-hexo/layout/_partial/article_copyright.ejs","hash":"05d3cddf5f3a53577452db4efa811bd361f7c0c4","modified":1566357905096},{"_id":"themes/3-hexo/layout/_partial/footer.ejs","hash":"311489fe2050ada8a0eaad3d0c57e5d5012f470e","modified":1571110367857},{"_id":"themes/3-hexo/layout/_partial/dashang.ejs","hash":"6eab1e5fae6bd60928325d026a1bed61c43d11a9","modified":1566357905100},{"_id":"themes/3-hexo/layout/_partial/friends.ejs","hash":"558a3d4bad578819fb07729fe1b50d9b81da8b93","modified":1566357905102},{"_id":"themes/3-hexo/layout/_partial/full-toc.ejs","hash":"0e976208d79b0396eb51ca1af5016c963c6e4618","modified":1566357905102},{"_id":"themes/3-hexo/layout/_partial/mathjax.ejs","hash":"e2be0e37f3d48e63e65a47d819bfb800b9aa3784","modified":1566357905103},{"_id":"themes/3-hexo/layout/_partial/header.ejs","hash":"915d5f10dd8f3dcd19cb75010e23689e8f385caf","modified":1571109509544},{"_id":"themes/3-hexo/layout/_partial/meta.ejs","hash":"ef387e80043b62e1925a068267f2377cac64adc7","modified":1566357905104},{"_id":"themes/3-hexo/layout/_partial/tag.ejs","hash":"87e932476754f27424f9ec397ed66a4ab8a59ad8","modified":1566357905105},{"_id":"themes/3-hexo/layout/_partial/toc-ref.ejs","hash":"33f7a4bfca1bb9835ec8f0d1e73188d1f56cc8b9","modified":1566357905106},{"_id":"themes/3-hexo/layout/_partial/nav-left.ejs","hash":"c14bc1393f779dff7854089621804dceea236d82","modified":1566357905104},{"_id":"themes/3-hexo/layout/_partial/nav-right.ejs","hash":"98326675546fc6828a45e8b95250899b4ee2d821","modified":1566357905105},{"_id":"themes/3-hexo/source/img/avatar.jpg","hash":"525dc2b6ef38fee9d4c66e554f928934eadd9117","modified":1567299464243},{"_id":"themes/3-hexo/source/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1566357905133},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1566357905132},{"_id":"themes/3-hexo/source/img/alipay.jpg","hash":"749a93e2c1925763846c18294cf0a27171f3a30f","modified":1567299308141},{"_id":"themes/3-hexo/source/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1566357905133},{"_id":"themes/3-hexo/source/css/gitalk.css","hash":"3dc58e9a3fd63a3144d5fe850eb55e3dc885c9fb","modified":1566357905121},{"_id":"themes/3-hexo/source/css/mobile.styl","hash":"d10bdd736aa343f38fe15cba4c81d45d3d259de4","modified":1566357905129},{"_id":"themes/3-hexo/source/css/style.styl","hash":"322abe325d5fe9ff37347bdd19e772315a8ebfed","modified":1566357905130},{"_id":"themes/3-hexo/source/css/tomorrow-night.scss","hash":"06db3e5b8a8320b325d5b48566108569c79115fb","modified":1571118552633},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","hash":"2462169ad7f4a8ae9f9f4063995cbe7fed45cd77","modified":1566357905140},{"_id":"themes/3-hexo/source/js/jquery.pjax.js","hash":"ca5d71e4a70ca0792ef26315b1b7263a01ab0d8d","modified":1571118258831},{"_id":"themes/3-hexo/source/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1566357905140},{"_id":"themes/3-hexo/source/js/script.js","hash":"eddf1fe782a3383a051aeccaf298cbe278a9a928","modified":1569334090626},{"_id":"themes/3-hexo/source/js/search.js","hash":"788c610149a5f9361295f9f0207c8523f37ddb8b","modified":1566357905141},{"_id":"source/img/HTTPS6.png","hash":"be9aa6a1578dd12e1970db4731f7c9727f9bc17e","modified":1569332587298},{"_id":"source/img/hdfs.png","hash":"c3be7dde1cdd24c4765a87ddf07c75c70148e970","modified":1576476667162},{"_id":"source/img/hdfs-write-file.png","hash":"3482163375f44f53c6ff7791e005d5ebc42bf0f8","modified":1576485576556},{"_id":"source/img/spark-all.png","hash":"d52bb136b90c8f63acaba9398811dbf1642de23f","modified":1576649188404},{"_id":"source/img/公钥私钥12.png","hash":"fdadf38dfcfd50d4afb6939f7403946ebcf1217b","modified":1569332408375},{"_id":"source/img/指针压缩1.png","hash":"d26943d292b23b4cf544cee8b1a73aa4172a8920","modified":1574251137573},{"_id":"source/img/混合加密的方式.png","hash":"45b8a92df2e3c57f6af2d483c444a96e59929843","modified":1567426174461},{"_id":"themes/3-hexo/source/img/weixin.jpg","hash":"59cf33d0f6ce9324dabe183f3d4551620959e987","modified":1567299346911},{"_id":"source/img/TCP协议通讯过程1.png","hash":"100f6ea49b8b585a10e0ac88e2486a902e221a5c","modified":1567157472656},{"_id":"source/img/主动免疫可信架构信任链传递示意图.png","hash":"ec45ff26518a046bd0f6274a8f7317222f05ea81","modified":1567337278597},{"_id":"source/img/可信在云平台的基础架构.png","hash":"b507acb0ecbe5f39f783b7a82340a30bb6fd42d4","modified":1567327147941},{"_id":"source/img/四次挥手协议.png","hash":"112d408966bbd5f77373bda95aaa07fd952e23d4","modified":1567152300617},{"_id":"source/img/读写锁.png","hash":"f5c76702b3a276fc48835d2ad1a02859a4767e08","modified":1567228164910},{"_id":"themes/3-hexo/.git/refs/heads/master","hash":"36e1610a86bddf4a3dd3b00a29a138d2168f7624","modified":1571110367863},{"_id":"themes/3-hexo/.git/objects/0a/6065aab85f97325dc2ffd41557ab3e2fa64f4d","hash":"b5d02c27f8136e2fd01773ff930a23c3a8edfaf9","modified":1571110367660},{"_id":"themes/3-hexo/.git/objects/19/6fe084360854de56b55c88f0e7e0c40760fdd6","hash":"4052161d8fee0878d9e806bb1624ef4f52e5f19f","modified":1571110367641},{"_id":"themes/3-hexo/.git/objects/25/7c60dffc50a203945c7fb81e03ac78aa540b2f","hash":"c19d68cc5d0903ef79a448e5eeab8605e1f916ef","modified":1571110367573},{"_id":"themes/3-hexo/.git/objects/08/f3f45718fbe8ad37fe1f939546529c1384b033","hash":"20e12e8a049dbe1c987dd181e4bfc359a5178aff","modified":1571110367636},{"_id":"themes/3-hexo/.git/objects/41/63bdeb30eb856080c33d91801fee699f8b098b","hash":"2024a45d3546f3dfe6336722dee5c7066b4b6358","modified":1571110367628},{"_id":"themes/3-hexo/.git/objects/12/4eb97ff9228afdf8e9094ba072b786a227763e","hash":"45e2cf84512bc83e73b5a39be6b783588cbca35f","modified":1574051405615},{"_id":"themes/3-hexo/.git/objects/42/6d029f7fe10004bd4a88ae2c89a1de4c7f1711","hash":"193a15faf669a332bd06ce253e0bf40b05debd3d","modified":1574051405622},{"_id":"themes/3-hexo/.git/objects/14/e027e912621a5083d6a8d200885d3dcc09d5e4","hash":"496982d736ba7b36a675a9b0c9986b75cc48eaa9","modified":1571110367646},{"_id":"themes/3-hexo/.git/objects/4c/ed9203eb27af55cf001c24111aaf6da9a2bc82","hash":"3905158769e19c42b844e1e6bd1d1d1cd5759084","modified":1574051405630},{"_id":"themes/3-hexo/.git/objects/4f/ed4680e7c8ef567fb0a96baf60e8416e492dc8","hash":"c4607a33444576c00d00b4c2cd4f9438926b0649","modified":1574051405654},{"_id":"themes/3-hexo/.git/objects/55/b7f9f95e210787ca22dc5cf4bbcde6462706c5","hash":"973bd6d0b9efeb2df7ef9b7222327d807b763827","modified":1574051405648},{"_id":"themes/3-hexo/.git/objects/53/0c7a5957ca41720c1486a0e798c1acbb1c40b7","hash":"4bfd824b0f9c32c015bea7a6960d2352496f819d","modified":1571110367658},{"_id":"themes/3-hexo/.git/objects/5e/669a1bcd5871f73c52baf4ce2fc4d728be009c","hash":"762dd70e5461baa2394d2e9debd0a11b6920fd97","modified":1571110367668},{"_id":"themes/3-hexo/.git/objects/5e/f2bf5cbb66ecf4d5757424128ab11237b1a8a5","hash":"e1cc02d212004518fc667b843a00d5ec472a8242","modified":1574051405626},{"_id":"themes/3-hexo/.git/objects/58/e1459f9ccf452bea04761d66ffd1d071cc0e46","hash":"1193491fff3769511ebbb4464d727e6280d7ef43","modified":1571110367663},{"_id":"themes/3-hexo/.git/objects/6d/b387e3375911f397b909bb52702f3515909311","hash":"3eb06f827bde44da887cfc6b436adeea56cf3861","modified":1574051405643},{"_id":"themes/3-hexo/.git/objects/71/79b850585450db8da132f02cee17233b1ef6e3","hash":"5f2b5f8de4aacdec25cca4086de9cabfa1fbe288","modified":1574051405637},{"_id":"themes/3-hexo/.git/objects/78/ce963b18628b6955ae36d0def0d89982aea752","hash":"e468b130e71f328dcb045fb05a567f3c7612f6f2","modified":1574051405610},{"_id":"themes/3-hexo/.git/objects/7d/8c7069fd6ba7171186d92d6fb02b7c214e5c88","hash":"43d7db05128009dfd4ed38c4a002d09f65b39fd9","modified":1571110367644},{"_id":"themes/3-hexo/.git/objects/7e/5afc2fa6d443053ad70da6ecd2fd19eaad2d48","hash":"3ad14d3445b8a8e07fd49238218bcb5ab850392d","modified":1574051405618},{"_id":"themes/3-hexo/.git/objects/83/f4796d5d05505b0913b4ec70309ad713803128","hash":"18faff62337f3885e90022b779f84b52f73bf31b","modified":1571110367656},{"_id":"themes/3-hexo/.git/objects/89/d2ae00dc60925bafe6df4786c793fc2b412d44","hash":"71964999e9873760272d5111d56a0299c34744ed","modified":1571110367622},{"_id":"themes/3-hexo/.git/objects/8b/7cba2780f2055549ea8d71bbc639184b194d4d","hash":"0609d0ba9ca4c5092a78f3b275f0005ffc435afa","modified":1574051405639},{"_id":"themes/3-hexo/.git/objects/76/119dc8b1a6e6227fc913495880c5a542cfd0be","hash":"7ed01208564e56f5f47039853c1dddc79ea0a695","modified":1571110367648},{"_id":"themes/3-hexo/.git/objects/96/8933ba48ce0bd43e65ee4124afeae4c209f691","hash":"36ca0028910ef3f98e52090149e7dd438bb3d43c","modified":1574051405628},{"_id":"themes/3-hexo/.git/objects/9d/a0b356deb7df7f74b371aa521bcd8dc07908e5","hash":"bc903f24a59c382559a28f52df2a2160de94cd78","modified":1574051405601},{"_id":"themes/3-hexo/.git/objects/a0/467959c08057b36c468b5c05c633db2aa74885","hash":"85ce56017287a4f3c55ac2f5475fb45dd590de9d","modified":1571110367666},{"_id":"themes/3-hexo/.git/objects/ae/42d951b20115e82d1df1a3a405e87881b55c1e","hash":"9affa9b6eea5470be405da63dd1cf5b09e1b16ff","modified":1571110367625},{"_id":"themes/3-hexo/.git/objects/9f/5b3752c384eebf3dad31c10781fc388d67a9a1","hash":"36fa2d53da9c62cc0867ed64b2670881ed29bca9","modified":1574051405650},{"_id":"themes/3-hexo/.git/objects/b0/884ae310196e8639d8f710906c76b1964b6414","hash":"added0f47c2f9298524950da24663cb5ff84a9a9","modified":1574051405641},{"_id":"themes/3-hexo/.git/objects/b2/e70f80fa64697689044677d0edf72a3a85e66e","hash":"3a7e236d5f56b9bec0412afdb8a91ecfa68ade05","modified":1571110367653},{"_id":"themes/3-hexo/.git/objects/c2/0e84895fac8aeef603ed8a07f705cba8f87b12","hash":"3c2fd85f436096666fddd05932938090b06b6f72","modified":1574051405632},{"_id":"themes/3-hexo/.git/objects/c9/e216642e2cfd5b8c75c818c3cf71946f056b66","hash":"f299dba79de7403509512de345098a1452bde3d9","modified":1571110367650},{"_id":"themes/3-hexo/.git/objects/cd/0e2e6dc99e22a7d01b16617e516e324e4bee52","hash":"28d15689a97be5a033914c3ba4ee86afc80400b7","modified":1571110367631},{"_id":"themes/3-hexo/.git/objects/dd/e4b0782a77d697afe7852ea59ea0ffdb3efbd6","hash":"ba583e42aafbc8587b9db7efe7da89666c87c9ca","modified":1571110367639},{"_id":"themes/3-hexo/.git/objects/de/d806239784cc24d162b5f17529deedd319abbf","hash":"e15db1216a30ee1b25f5ffbfa2a9c78e46a3d45e","modified":1574051405613},{"_id":"themes/3-hexo/.git/objects/e6/1c4e686f371037296bad61a0a0d6d6836e3a4e","hash":"6eb5fac0e5fa6b3cfc8a154ba6368ca2ee6e731c","modified":1574051405645},{"_id":"themes/3-hexo/.git/objects/e4/45c0be361ce735d5c7c36d4b341b9230126323","hash":"e98f245e7a9dbf741a7f7cac91d7edbe0240143e","modified":1574051405624},{"_id":"themes/3-hexo/.git/objects/fe/29eed9e715cda66839f260b03d8929289aad68","hash":"59645d6ee8981fc6141d250984bab86f76917597","modified":1574051405620},{"_id":"themes/3-hexo/.git/objects/e9/acab7802fd162cb889d62b47a7ca9b17a1ea1f","hash":"4bcfbfafa929d1ca035a315fce1e057f9cfe62ba","modified":1574051405652},{"_id":"themes/3-hexo/.git/objects/f3/374e0c06cbc5e69e50dfea606e96244e267f20","hash":"c4fbc21681e3825ae20277c198b112ed8d558bde","modified":1571110367633},{"_id":"themes/3-hexo/.git/objects/e6/f6e1573bf42a6268f889fe2ffd25d36f7ecabf","hash":"3db0915b8b2ecaee95f834e85efa0793220435bb","modified":1574051405635},{"_id":"themes/3-hexo/.git/objects/pack/pack-7043c5b8bc471239c47a8bb3fd601c77cd08e244.idx","hash":"4ebcc75525e02c7111f0ea164ec926f194a02838","modified":1566357904945},{"_id":"themes/3-hexo/layout/_partial/comments/gentie.ejs","hash":"908d9046502612d24780ca354bd9392a009b4d7b","modified":1566357905099},{"_id":"themes/3-hexo/layout/_partial/comments/disqus.ejs","hash":"32ce7b48d366b9c888ff2ceb911a3cd82f864537","modified":1566357905098},{"_id":"themes/3-hexo/layout/_partial/comments/click2show.ejs","hash":"8a3a175c2da956366ce91bfc4f4012a487f4bdfc","modified":1566357905098},{"_id":"themes/3-hexo/layout/_partial/comments/gitalk.ejs","hash":"01567e010cf4f2dd141fe2019490d3f0d5aa2529","modified":1566357905099},{"_id":"themes/3-hexo/layout/_partial/comments/gitment.ejs","hash":"eaf2b6f297282606b630ad55fb9e38af7e2829dc","modified":1566357905099},{"_id":"themes/3-hexo/source/css/_partial/dashang.styl","hash":"f0eac1dc1f5dbed1769d032bb5fd5f002faaee26","modified":1566357905111},{"_id":"themes/3-hexo/source/css/_partial/comment.styl","hash":"fe00fb1269b4fe1f3d5ab917891926222ce47275","modified":1566357905110},{"_id":"themes/3-hexo/source/css/_partial/fade.styl","hash":"02c7510a26f306e240f23ddbf772a69be2c890dd","modified":1566357905111},{"_id":"themes/3-hexo/source/css/_partial/autocomplete.styl","hash":"1ffe51e3b77afefcd94d386a718506d5b055ad94","modified":1566357905110},{"_id":"themes/3-hexo/source/css/_partial/nprogress.styl","hash":"2620a02169a6aeb75137fd368eac2c36423d8498","modified":1566357905113},{"_id":"themes/3-hexo/source/css/_partial/nav-left.styl","hash":"bf29eab9ea75fa191d678b6eefec440505ddf6e3","modified":1566357905112},{"_id":"themes/3-hexo/source/css/_partial/nav-right.styl","hash":"1d01247f974b059d9ef6a2178a724b4f72acd659","modified":1566357905113},{"_id":"themes/3-hexo/source/css/_partial/num-load.styl","hash":"f7ef35459ece22e1da950b86126be1c2bfe97fcf","modified":1566357905114},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1566357905115},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1566357905117},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","hash":"3dfe8e557d9dfaf39bca088a02b76deb82dbaa3d","modified":1566357905117},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1566357905116},{"_id":"themes/3-hexo/source/css/_partial/post.styl","hash":"8a462cf9b0b026e71eda9e704c0fbb952b4615c5","modified":1571110367858},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","hash":"f3eb4e5feda9cbd6242ccf44ca064e2979b5d719","modified":1566357905122},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","hash":"aa087561480fb9c2cfd541e33d1e99d5ac1a56bb","modified":1566357905119},{"_id":"themes/3-hexo/source/css/fonts/selection.json","hash":"b6456a4eabcffd95e822d1d7adce96da524d481a","modified":1566357905120},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","hash":"03af387edcc1cf8c18d12e9c440fd51b6cf425b6","modified":1566357905123},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","hash":"f8ed131ccf13f4bdd3ec11fc3e997339dd7b66ba","modified":1566357905119},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","hash":"5e05b19832c1099bd9d284bc3ed00dc8a3d7ee23","modified":1566357905124},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","hash":"69d184a682bcaeba2b180b437dc4431bc3be38aa","modified":1566357905122},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","hash":"2bfc14f27ccca108b4b3755782de8366e8bd001e","modified":1566357905123},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","hash":"e9c190f9ffc37a13cac430512e4e0c760205be4a","modified":1566357905126},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","hash":"0c3ccd0d64e7504c7061d246dc32737f502f64e4","modified":1566357905126},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","hash":"53276ff1f224f691dfe811e82c0af7f4476abf5d","modified":1566357905124},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","hash":"315ad610d303caba9eac80a7d51002193a15478a","modified":1566357905125},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","hash":"a6e8cfd2202afd7893f5268f3437421e35066e7b","modified":1566357905127},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","hash":"1bece084b1dbbbd4af064f05feffd8c332b96a48","modified":1566357905125},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","hash":"51659351b391a2be5c68728bb51b7ad467c5e0db","modified":1566357905127},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","hash":"e5c37646a9d9c1094f9aab7a7c65a4b242e8db00","modified":1566357905127},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","hash":"2aa9817e68fb2ed216781ea04b733039ebe18214","modified":1566357905128},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","hash":"501d75ef0f4385bea24d9b9b4cc434ba68d4be27","modified":1566357905128},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","hash":"92941a6ae73b74f44ad7c559c5548c44073c644a","modified":1566357905129},{"_id":"source/img/wordcount-reduce.png","hash":"99f7334d973e7a4ffaf5d34e7870b55d0016858b","modified":1576489761247},{"_id":"source/img/对象存储1.png","hash":"281b0b0c7d4c55df4000800b3f00888663e5ee25","modified":1574250820011},{"_id":"source/img/阻塞与非阻塞调用对比.png","hash":"cdee42373e7940d8f09575bf844ce08f49b4d1af","modified":1567157755596},{"_id":"themes/3-hexo/source/css/_partial/full-toc.styl","hash":"4102753dad0cc1ee9ed673f7253ba097a960c3b7","modified":1566357905112},{"_id":"themes/3-hexo/source/css/_partial/font.styl","hash":"c200f3fabcfe83f3e45746e186b4bb111e73ad47","modified":1566357905111},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","hash":"b5e7562c8494b0ddb3a70ecc5545ef7340d8e971","modified":1566357905116},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","hash":"7e54ae44c02faa319c4fe128e1e6bda38eae5c9d","modified":1566357905118},{"_id":"themes/3-hexo/source/js/gitment.js","hash":"67984b83cd46ff4300d4fd959bf6c17dd66b4136","modified":1566357905139},{"_id":"themes/3-hexo/.git/logs/refs/heads/master","hash":"8b723d9f01348f811c9a75afbb7486873dc1d656","modified":1571110367864},{"_id":"themes/3-hexo/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1566357905053},{"_id":"themes/3-hexo/.git/refs/remotes/origin/master","hash":"26d22e3aa2bcc2d6eb3c0e83ca4d2915ee607d25","modified":1574051405730},{"_id":"themes/3-hexo/source/js/gitalk.js","hash":"536f28c4354a13582af826d9d9b2cb27cec07dc6","modified":1566357905137},{"_id":"source/img/Socket通讯模型.png","hash":"2e260e5f30b7e17b7dba072e65ac7860e8d7e6ce","modified":1567156905642},{"_id":"themes/3-hexo/.git/logs/refs/remotes/origin/HEAD","hash":"36b1e76054f246c3ef309b294d31e9cf5a76d47c","modified":1566357905053},{"_id":"themes/3-hexo/.git/logs/refs/remotes/origin/master","hash":"c878c52013da84fae14ae548f6a41199653276ec","modified":1574051405732},{"_id":"source/img/三次握手协议3.png","hash":"e6fe59d8473f94be2b361f4bda5be7d791022eec","modified":1567152339366},{"_id":"source/img/select、epoll模型对比.png","hash":"cdc93cacbedcf65fb68878bd36da3929e6333e2b","modified":1567157832363},{"_id":"source/img/四次挥手协议2.png","hash":"1a4890549075feacfa4010df20911537fc726e4b","modified":1567152739865},{"_id":"source/img/网络连接模型.png","hash":"f2f48effb8cb134f597011fda639932ea0d2fac2","modified":1567149380436},{"_id":"themes/3-hexo/.git/objects/pack/pack-7043c5b8bc471239c47a8bb3fd601c77cd08e244.pack","hash":"8deb96fdf8557c2b51e4043fa4dca5e2ad8444bc","modified":1566357904942}],"Category":[{"name":"大数据","_id":"ck4hufm050002vguq45ltg04z"},{"name":"软件管理","_id":"ck4hufm0l000hvguqs23ergt4"},{"name":"java基础","_id":"ck4hufm0r000qvguqnhtyix16"},{"name":"SpringCloud","_id":"ck4hufm0v000wvguqvtwbncgw"},{"name":"网络","_id":"ck4hufm1b001ovguqd4tr4yc7"},{"name":"数据库","_id":"ck4hufm1l0023vguqh0igydis"},{"name":"分布式","_id":"ck4hufm1t002ivguqv9ku6r8s"},{"name":"可信","_id":"ck4hufm1x002ovguq6sejnhmb"}],"Data":[],"Page":[],"Post":[{"title":"MapReduce概述","author":"郑天祺","date":"2019-12-16T09:13:00.000Z","_content":"\n# 一、基本模型\n\n​\tMapReduce采取了分而治之的基本思想，将一个大的作业分解成若干小的任务，提交给集群的多台计算机处理，这样就大大提高了完成作业的效率。\n\n​\t在Hadoop平台上，MapReduce框架负责处理并行编程中分布式存储、工作调度、负载均衡、容错及网络通信等复杂工作，把处理过程高度抽象为两个函数：Map 和 Reduce。\n\n​\tMap负责把作业分解成多个任务，Reduce负责把分解后多任务处理的结果汇总起来。\n\n其中：\n\n​\t执行MapReduce作业的机器角色由两个：JobTracker 和 TaskTracker\n\n​\t（1）JobTracker用于调度作业（一个集群只有一个JobTracker）\n\n​\t（2）TaskTracker用于跟踪任务的执行情况。\n\n# 二、wordcount\n\n​\t统计所有文件中每一个单词出现的次数（频次）。\n\n​\t![image-20191216173559584](/img/wordcount.png)\n\n​\t所做的操作：\n\n## （1）拆分输入数据\n\n​\t拆分数据 属于 Map 的输入阶段，系统会逐行读取文件的数据，得到一系列的（key/value）\n\n![image-20191216173747383](/img/wordcount-split.png)\n\n​\t注意：如果只有一个文件，且很小，系统只分配一个Split；\n\n​\t\t\t\t如果由多个文件，或者文件很大，多个Split\n\n​\t\t\t\t上图 0、12为偏移量（包含回车）即：H是第0个字符   B是第12个字符\n\n## （2）执行Map方法\n\n​\t分割完成后，系统会将分割好的（key/value）对交给用户定义的 Map 方法进行处理，生成新的（key/value）对\n\n​\t![image-20191216174237035](/img/wordcount-map.png)\n\n​\t\t注意：后边这个1是个数\n\n## （3）排序与合并处理\n\n​\t系统得到Map方法输出的（key/value）对后，Mapper 会将它们按照 key 值进行排序，并执行Combine 过程，将 key 值相同的 value 值累加，得到 Mapper 的最终输出结果。\n\n即：先排序 后累加\n\n## （4）Reduce 阶段的排序与合并\n\n​\tReducer 先对从 Mapper 接收的数据进行排序，再交由用户自定义的 Reduce 方法进行处理，得到新的（key/value）对，并作为WordCount的结果输出\n\n![image-20191216174856510](/img/wordcount-reduce.png)\n\n简述上述过程：\n\n### （A）Map\n\n#### \t（a）Read：\n\n​\t\tMap Task 通过用户编写的 RecordReader，从输入 InputSplit 中解析出多个（key/value）\n\n#### \t（b）Map：\n\n​\t\t将解析出的（key/value）交给用户编写的Map函数处理，并产生一系列新的（key/value）\n\n#### \t（c）Collect：\n\n​\t\t在用户编写的Map函数中，数据处理完成后，一般会调用OutputCollector.collect()收集结果。在该函数内部，它会将生成（key/value）分片（通过Partitioner），并写入一个环形内存缓冲区中。（感觉像\n\n[disruptor]: https://blog.csdn.net/qq_23034755/article/details/90137103\n\n，log4j2用的队列）\n\n#### \t（d）Spill：\n\n​\t\t环形缓冲区填满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。将数据写入本地磁盘之前，先对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。\n\n#### \t（e）Combine：\n\n​\t\t当所有数据处理完成后，Map Task 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件\n\n### （B）Reduce\n\n#### \t（a）Shuffle：\n\n​\t\t也成为Copy。Reduce Task从各个Map Task上远程复制一片数据，并针对某一篇数据进行判断，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。\n\n#### \t（b）Merge：\n\n​\t\t在远程复制的同时，Reduce Task启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘上文件过多。（为啥要用两个线程呢？）\n\n#### \t（c）Sort：\n\n​\t\t按照MapReduce语义，用户编写的 Reduce 函数输入数据时按 key 进行聚集的一组数据。（采用基于排序的策略）。各个Map Task实现了局部排序，Reduce Task只需对所有的数据进行一次归并排序即可。\n\n#### \t（d）Reduce：\n\n​\t\tReduce Task将每组数据一次交给用户编写的 reduce()函数处理\n\n#### \t（e）Write：\n\n​\t\treduce()函数将计算结果写到HDFS\n\n","source":"_posts/MapReduce概述.md","raw":"title: MapReduce概述\nauthor: 郑天祺\ntags:\n  - HADOOP\ncategories:\n  - 大数据\ndate: 2019-12-16 17:13:00\n\n---\n\n# 一、基本模型\n\n​\tMapReduce采取了分而治之的基本思想，将一个大的作业分解成若干小的任务，提交给集群的多台计算机处理，这样就大大提高了完成作业的效率。\n\n​\t在Hadoop平台上，MapReduce框架负责处理并行编程中分布式存储、工作调度、负载均衡、容错及网络通信等复杂工作，把处理过程高度抽象为两个函数：Map 和 Reduce。\n\n​\tMap负责把作业分解成多个任务，Reduce负责把分解后多任务处理的结果汇总起来。\n\n其中：\n\n​\t执行MapReduce作业的机器角色由两个：JobTracker 和 TaskTracker\n\n​\t（1）JobTracker用于调度作业（一个集群只有一个JobTracker）\n\n​\t（2）TaskTracker用于跟踪任务的执行情况。\n\n# 二、wordcount\n\n​\t统计所有文件中每一个单词出现的次数（频次）。\n\n​\t![image-20191216173559584](/img/wordcount.png)\n\n​\t所做的操作：\n\n## （1）拆分输入数据\n\n​\t拆分数据 属于 Map 的输入阶段，系统会逐行读取文件的数据，得到一系列的（key/value）\n\n![image-20191216173747383](/img/wordcount-split.png)\n\n​\t注意：如果只有一个文件，且很小，系统只分配一个Split；\n\n​\t\t\t\t如果由多个文件，或者文件很大，多个Split\n\n​\t\t\t\t上图 0、12为偏移量（包含回车）即：H是第0个字符   B是第12个字符\n\n## （2）执行Map方法\n\n​\t分割完成后，系统会将分割好的（key/value）对交给用户定义的 Map 方法进行处理，生成新的（key/value）对\n\n​\t![image-20191216174237035](/img/wordcount-map.png)\n\n​\t\t注意：后边这个1是个数\n\n## （3）排序与合并处理\n\n​\t系统得到Map方法输出的（key/value）对后，Mapper 会将它们按照 key 值进行排序，并执行Combine 过程，将 key 值相同的 value 值累加，得到 Mapper 的最终输出结果。\n\n即：先排序 后累加\n\n## （4）Reduce 阶段的排序与合并\n\n​\tReducer 先对从 Mapper 接收的数据进行排序，再交由用户自定义的 Reduce 方法进行处理，得到新的（key/value）对，并作为WordCount的结果输出\n\n![image-20191216174856510](/img/wordcount-reduce.png)\n\n简述上述过程：\n\n### （A）Map\n\n#### \t（a）Read：\n\n​\t\tMap Task 通过用户编写的 RecordReader，从输入 InputSplit 中解析出多个（key/value）\n\n#### \t（b）Map：\n\n​\t\t将解析出的（key/value）交给用户编写的Map函数处理，并产生一系列新的（key/value）\n\n#### \t（c）Collect：\n\n​\t\t在用户编写的Map函数中，数据处理完成后，一般会调用OutputCollector.collect()收集结果。在该函数内部，它会将生成（key/value）分片（通过Partitioner），并写入一个环形内存缓冲区中。（感觉像\n\n[disruptor]: https://blog.csdn.net/qq_23034755/article/details/90137103\n\n，log4j2用的队列）\n\n#### \t（d）Spill：\n\n​\t\t环形缓冲区填满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。将数据写入本地磁盘之前，先对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。\n\n#### \t（e）Combine：\n\n​\t\t当所有数据处理完成后，Map Task 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件\n\n### （B）Reduce\n\n#### \t（a）Shuffle：\n\n​\t\t也成为Copy。Reduce Task从各个Map Task上远程复制一片数据，并针对某一篇数据进行判断，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。\n\n#### \t（b）Merge：\n\n​\t\t在远程复制的同时，Reduce Task启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘上文件过多。（为啥要用两个线程呢？）\n\n#### \t（c）Sort：\n\n​\t\t按照MapReduce语义，用户编写的 Reduce 函数输入数据时按 key 进行聚集的一组数据。（采用基于排序的策略）。各个Map Task实现了局部排序，Reduce Task只需对所有的数据进行一次归并排序即可。\n\n#### \t（d）Reduce：\n\n​\t\tReduce Task将每组数据一次交给用户编写的 reduce()函数处理\n\n#### \t（e）Write：\n\n​\t\treduce()函数将计算结果写到HDFS\n\n","slug":"MapReduce概述","published":1,"updated":"2019-12-16T10:07:22.822Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4huflzz0000vguqooxia2zy","content":"<h1>一、基本模型</h1>\n<p>​\tMapReduce采取了分而治之的基本思想，将一个大的作业分解成若干小的任务，提交给集群的多台计算机处理，这样就大大提高了完成作业的效率。</p>\n<p>​\t在Hadoop平台上，MapReduce框架负责处理并行编程中分布式存储、工作调度、负载均衡、容错及网络通信等复杂工作，把处理过程高度抽象为两个函数：Map 和 Reduce。</p>\n<p>​\tMap负责把作业分解成多个任务，Reduce负责把分解后多任务处理的结果汇总起来。</p>\n<p>其中：</p>\n<p>​\t执行MapReduce作业的机器角色由两个：JobTracker 和 TaskTracker</p>\n<p>​\t（1）JobTracker用于调度作业（一个集群只有一个JobTracker）</p>\n<p>​\t（2）TaskTracker用于跟踪任务的执行情况。</p>\n<h1>二、wordcount</h1>\n<p>​\t统计所有文件中每一个单词出现的次数（频次）。</p>\n<p>​\t<img src=\"/img/wordcount.png\" alt=\"image-20191216173559584\"></p>\n<p>​\t所做的操作：</p>\n<h2>（1）拆分输入数据</h2>\n<p>​\t拆分数据 属于 Map 的输入阶段，系统会逐行读取文件的数据，得到一系列的（key/value）</p>\n<p><img src=\"/img/wordcount-split.png\" alt=\"image-20191216173747383\"></p>\n<p>​\t注意：如果只有一个文件，且很小，系统只分配一个Split；</p>\n<p>​\t\t\t\t如果由多个文件，或者文件很大，多个Split</p>\n<p>​\t\t\t\t上图 0、12为偏移量（包含回车）即：H是第0个字符   B是第12个字符</p>\n<h2>（2）执行Map方法</h2>\n<p>​\t分割完成后，系统会将分割好的（key/value）对交给用户定义的 Map 方法进行处理，生成新的（key/value）对</p>\n<p>​\t<img src=\"/img/wordcount-map.png\" alt=\"image-20191216174237035\"></p>\n<p>​\t\t注意：后边这个1是个数</p>\n<h2>（3）排序与合并处理</h2>\n<p>​\t系统得到Map方法输出的（key/value）对后，Mapper 会将它们按照 key 值进行排序，并执行Combine 过程，将 key 值相同的 value 值累加，得到 Mapper 的最终输出结果。</p>\n<p>即：先排序 后累加</p>\n<h2>（4）Reduce 阶段的排序与合并</h2>\n<p>​\tReducer 先对从 Mapper 接收的数据进行排序，再交由用户自定义的 Reduce 方法进行处理，得到新的（key/value）对，并作为WordCount的结果输出</p>\n<p><img src=\"/img/wordcount-reduce.png\" alt=\"image-20191216174856510\"></p>\n<p>简述上述过程：</p>\n<h3>（A）Map</h3>\n<h4>（a）Read：</h4>\n<p>​\t\tMap Task 通过用户编写的 RecordReader，从输入 InputSplit 中解析出多个（key/value）</p>\n<h4>（b）Map：</h4>\n<p>​\t\t将解析出的（key/value）交给用户编写的Map函数处理，并产生一系列新的（key/value）</p>\n<h4>（c）Collect：</h4>\n<p>​\t\t在用户编写的Map函数中，数据处理完成后，一般会调用OutputCollector.collect()收集结果。在该函数内部，它会将生成（key/value）分片（通过Partitioner），并写入一个环形内存缓冲区中。（感觉像</p>\n<p>，log4j2用的队列）</p>\n<h4>（d）Spill：</h4>\n<p>​\t\t环形缓冲区填满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。将数据写入本地磁盘之前，先对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>\n<h4>（e）Combine：</h4>\n<p>​\t\t当所有数据处理完成后，Map Task 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件</p>\n<h3>（B）Reduce</h3>\n<h4>（a）Shuffle：</h4>\n<p>​\t\t也成为Copy。Reduce Task从各个Map Task上远程复制一片数据，并针对某一篇数据进行判断，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>\n<h4>（b）Merge：</h4>\n<p>​\t\t在远程复制的同时，Reduce Task启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘上文件过多。（为啥要用两个线程呢？）</p>\n<h4>（c）Sort：</h4>\n<p>​\t\t按照MapReduce语义，用户编写的 Reduce 函数输入数据时按 key 进行聚集的一组数据。（采用基于排序的策略）。各个Map Task实现了局部排序，Reduce Task只需对所有的数据进行一次归并排序即可。</p>\n<h4>（d）Reduce：</h4>\n<p>​\t\tReduce Task将每组数据一次交给用户编写的 reduce()函数处理</p>\n<h4>（e）Write：</h4>\n<p>​\t\treduce()函数将计算结果写到HDFS</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、基本模型</h1>\n<p>​\tMapReduce采取了分而治之的基本思想，将一个大的作业分解成若干小的任务，提交给集群的多台计算机处理，这样就大大提高了完成作业的效率。</p>\n<p>​\t在Hadoop平台上，MapReduce框架负责处理并行编程中分布式存储、工作调度、负载均衡、容错及网络通信等复杂工作，把处理过程高度抽象为两个函数：Map 和 Reduce。</p>\n<p>​\tMap负责把作业分解成多个任务，Reduce负责把分解后多任务处理的结果汇总起来。</p>\n<p>其中：</p>\n<p>​\t执行MapReduce作业的机器角色由两个：JobTracker 和 TaskTracker</p>\n<p>​\t（1）JobTracker用于调度作业（一个集群只有一个JobTracker）</p>\n<p>​\t（2）TaskTracker用于跟踪任务的执行情况。</p>\n<h1>二、wordcount</h1>\n<p>​\t统计所有文件中每一个单词出现的次数（频次）。</p>\n<p>​\t<img src=\"/img/wordcount.png\" alt=\"image-20191216173559584\"></p>\n<p>​\t所做的操作：</p>\n<h2>（1）拆分输入数据</h2>\n<p>​\t拆分数据 属于 Map 的输入阶段，系统会逐行读取文件的数据，得到一系列的（key/value）</p>\n<p><img src=\"/img/wordcount-split.png\" alt=\"image-20191216173747383\"></p>\n<p>​\t注意：如果只有一个文件，且很小，系统只分配一个Split；</p>\n<p>​\t\t\t\t如果由多个文件，或者文件很大，多个Split</p>\n<p>​\t\t\t\t上图 0、12为偏移量（包含回车）即：H是第0个字符   B是第12个字符</p>\n<h2>（2）执行Map方法</h2>\n<p>​\t分割完成后，系统会将分割好的（key/value）对交给用户定义的 Map 方法进行处理，生成新的（key/value）对</p>\n<p>​\t<img src=\"/img/wordcount-map.png\" alt=\"image-20191216174237035\"></p>\n<p>​\t\t注意：后边这个1是个数</p>\n<h2>（3）排序与合并处理</h2>\n<p>​\t系统得到Map方法输出的（key/value）对后，Mapper 会将它们按照 key 值进行排序，并执行Combine 过程，将 key 值相同的 value 值累加，得到 Mapper 的最终输出结果。</p>\n<p>即：先排序 后累加</p>\n<h2>（4）Reduce 阶段的排序与合并</h2>\n<p>​\tReducer 先对从 Mapper 接收的数据进行排序，再交由用户自定义的 Reduce 方法进行处理，得到新的（key/value）对，并作为WordCount的结果输出</p>\n<p><img src=\"/img/wordcount-reduce.png\" alt=\"image-20191216174856510\"></p>\n<p>简述上述过程：</p>\n<h3>（A）Map</h3>\n<h4>（a）Read：</h4>\n<p>​\t\tMap Task 通过用户编写的 RecordReader，从输入 InputSplit 中解析出多个（key/value）</p>\n<h4>（b）Map：</h4>\n<p>​\t\t将解析出的（key/value）交给用户编写的Map函数处理，并产生一系列新的（key/value）</p>\n<h4>（c）Collect：</h4>\n<p>​\t\t在用户编写的Map函数中，数据处理完成后，一般会调用OutputCollector.collect()收集结果。在该函数内部，它会将生成（key/value）分片（通过Partitioner），并写入一个环形内存缓冲区中。（感觉像</p>\n<p>，log4j2用的队列）</p>\n<h4>（d）Spill：</h4>\n<p>​\t\t环形缓冲区填满后，MapReduce会将数据写到本地磁盘上，生成一个临时文件。将数据写入本地磁盘之前，先对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p>\n<h4>（e）Combine：</h4>\n<p>​\t\t当所有数据处理完成后，Map Task 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件</p>\n<h3>（B）Reduce</h3>\n<h4>（a）Shuffle：</h4>\n<p>​\t\t也成为Copy。Reduce Task从各个Map Task上远程复制一片数据，并针对某一篇数据进行判断，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p>\n<h4>（b）Merge：</h4>\n<p>​\t\t在远程复制的同时，Reduce Task启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或者磁盘上文件过多。（为啥要用两个线程呢？）</p>\n<h4>（c）Sort：</h4>\n<p>​\t\t按照MapReduce语义，用户编写的 Reduce 函数输入数据时按 key 进行聚集的一组数据。（采用基于排序的策略）。各个Map Task实现了局部排序，Reduce Task只需对所有的数据进行一次归并排序即可。</p>\n<h4>（d）Reduce：</h4>\n<p>​\t\tReduce Task将每组数据一次交给用户编写的 reduce()函数处理</p>\n<h4>（e）Write：</h4>\n<p>​\t\treduce()函数将计算结果写到HDFS</p>\n"},{"title":"HDFS概述","author":"郑天祺","date":"2019-12-16T02:10:00.000Z","_content":"\n本文权威指南读书笔记\n\n# 一、HDFS的设计前提和目标\n\n​\t（1）存储大文件：HDFS支持GB级别大小的文件；\n\n​\t（2）流式数据访问：保证高吞吐量\n\n​\t（3）容错性：完善的冗余备份机制；\n\n​\t（4）简单的一致性模型：一次写入多次读取；\n\n​\t（5）移动计算优于移动数据：HDFS使应用计算移动到离他最近数据位置的接口；\n\n​\t（6）兼容各种硬件和软件平台。\n\n​\tHDFS不适合的场景：\n\n​\t（1）大量小文件：文件的元数据存储在NameNode内容中，大量小文件意味着元数据增加，会占用大量内存；\n\n​\t（2）低延迟数据访问：HDFS是专门针对吞吐量而不是用户低延迟；\n\n​\t（3）多用户写入：导致一致性维护困难。\n\n# 二、主要组件与架构\n\n​\t主要三个组件：NameNode、SecondaryNameNode 和 DataNode\n\n​\t（HDFS以主从模式运行，其中NameNode、SecondaryNameNode运行再Master节点，DataNode运行再Slave节点上）\n\n​\tNameNode负责信息维护者，DateNode负责存取数据。\n\n​\t![image-20191216141048512](/img/hdfs.png)\n\n## (1) NameNode\n\n​\tNameNode管理着文件系统的命名空间 , 它维护文件系统树及树中的所有文件和目录\n\n​\tNameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。\n\n​\t\ta. 文件名目录名及它们之间的层级关系\n\n​\t\tb. 文件目录的所有者及其权限\n\n​\t\tc.每个文件块的名及文件有哪些块组成\n\n​\tNameNode启动时加载到内存中，元信息会保存各个块的名称及文件由哪些块组成。\n\n​\tNameNode占用大量内存和I/O资源，对Name容错机制也十分重要\n\n## (2) DataNode\n\n​\tDataNode是HDFS中的Worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。\n\n​\t负责实际文件数据的保存于操作，与客户端直接交互。\n\n​\t例子：一条元信息记录会占用200B内存空间。 假设块大小为64MB，备份数量是3，那么一个1GB大小的文件将占用16*3=48个文件块。如果现在有1000个1MB大小的文件，则会占用1000*3=3000个文件块（多个文件不能放到一个块中）。\n\n​\t可以得出，如果文件越小，存储同等大小文件所需要的元信息就越多，所以，Hadoop更喜欢大文件。\n\n## （3）元信息的持久化\n\n​\t在NameNode中存放元信息的文件是fsimage。在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个edits中，并且edits文件和fsimage文件会SecondaryNameNode周期性地合并。\n\n## （4）SecondaryNameNode\n\n​\t在NameNode启动时，首先会加载fsimage到内存中，在系统运行期间，所有对NameNode的操作也都保存在内存中，同时为了防止数据丢失，这些操作又会不断的持久化到本地edits文件中。\n\n​\tedits文件的目的是为了提高系统的操作效率，NameNode在更新内存的元信息之前都会先将操作写入edits文件。在NameNode重启的过程中，edits会和fsimage合并到一起，但是合并的过程会影响到Hadoop重启的速度，SecondaryNameNode就是为了解决这个问题：\n\n![](/img/secondaryNameNode.jpg)\n\n​\tSecondaryNameNode的角色就是定期合并edits和fsimage文件：\n\n​\ta、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。\n\n​\tb、SecondaryNameNode从NameNode请求fsimage和edits文件。\n\n​\tc、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件。\n\n​\td、NameNode从SecondaryName获取合并好的新的fsimage并将旧的替换掉，并\n\n​\t使用的检查点：\n\n​\t\tfsimage：保存的是上个检查点的HDFS的元信息\n\n​\t\tedits：保存的是从上个检查点开始发生的HDFS元信息状态改变信息\n\n​\t\tfstime：保存了最后一个检查点的时间戳\n\n# 三、数据备份\n\n​\tHDFS通过备份数据块的形式来实现容错，除了文件的最后一个数据块外，其他所有数据块大小都是一样的，数据块的大小和备份银子都是可以配置的。\n\n​\tNmaeNode负责各个数据块的备份，DataNode会通过心跳的方式定期向NameNode发送自己节点上的Block报告，这个报告包含了DataNode节点上的所有数据块的列表。\n\n​\t写数据时候通过负载均衡，进行同步，但是会影响效率。当Hadoop的NameNode节点启动时，会进入安全模式。当副本数满足最小副本数，系统会退出安全模式。\n\n# 四、通信协议\n\n​\t所有的HDFS中的沟通协议都是基于TCP/IP协议的\n\n​\t（1）一个客户端通过指定的TCP端口与NameNode机器建立连接，并通过Client Protocol协议与NameNode交互。 NameNode只被动接受请求。\n\n​\t（2）DataNode则通过DataNode Protocol协议与NameNode进行沟通。\n\n​\t（3）HDFS的RPC对Client Protocol 和 DataNode Protocol做了封装。\n\n# 五、可靠性保证\n\n​\tHDFS可以允许DataNode失败。\n\n​\tDataNode会定期（默认3s）向NameNode发送心跳，若NameNode在指定时间间隔内没有收到心跳，它就认为此节点已经失败。此时NameNode把失败节点的数据备份到另一个健康的节点，这就保证了集群始终维持指定的副本数。\n\n​\tHDFS可以检测到数据块损坏。在读取数据块时，HDFS会对数据块和保存的校验和文件匹配，如果不匹配，NameNode会重新备份损坏的数据块。","source":"_posts/HDFS概述.md","raw":"title: HDFS概述\nauthor: 郑天祺\ntags:\n\n  - HDFS\n  - HADOOP\ncategories:\n  - 大数据\ndate: 2019-12-16 10:10:00\n\n---\n\n本文权威指南读书笔记\n\n# 一、HDFS的设计前提和目标\n\n​\t（1）存储大文件：HDFS支持GB级别大小的文件；\n\n​\t（2）流式数据访问：保证高吞吐量\n\n​\t（3）容错性：完善的冗余备份机制；\n\n​\t（4）简单的一致性模型：一次写入多次读取；\n\n​\t（5）移动计算优于移动数据：HDFS使应用计算移动到离他最近数据位置的接口；\n\n​\t（6）兼容各种硬件和软件平台。\n\n​\tHDFS不适合的场景：\n\n​\t（1）大量小文件：文件的元数据存储在NameNode内容中，大量小文件意味着元数据增加，会占用大量内存；\n\n​\t（2）低延迟数据访问：HDFS是专门针对吞吐量而不是用户低延迟；\n\n​\t（3）多用户写入：导致一致性维护困难。\n\n# 二、主要组件与架构\n\n​\t主要三个组件：NameNode、SecondaryNameNode 和 DataNode\n\n​\t（HDFS以主从模式运行，其中NameNode、SecondaryNameNode运行再Master节点，DataNode运行再Slave节点上）\n\n​\tNameNode负责信息维护者，DateNode负责存取数据。\n\n​\t![image-20191216141048512](/img/hdfs.png)\n\n## (1) NameNode\n\n​\tNameNode管理着文件系统的命名空间 , 它维护文件系统树及树中的所有文件和目录\n\n​\tNameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。\n\n​\t\ta. 文件名目录名及它们之间的层级关系\n\n​\t\tb. 文件目录的所有者及其权限\n\n​\t\tc.每个文件块的名及文件有哪些块组成\n\n​\tNameNode启动时加载到内存中，元信息会保存各个块的名称及文件由哪些块组成。\n\n​\tNameNode占用大量内存和I/O资源，对Name容错机制也十分重要\n\n## (2) DataNode\n\n​\tDataNode是HDFS中的Worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。\n\n​\t负责实际文件数据的保存于操作，与客户端直接交互。\n\n​\t例子：一条元信息记录会占用200B内存空间。 假设块大小为64MB，备份数量是3，那么一个1GB大小的文件将占用16*3=48个文件块。如果现在有1000个1MB大小的文件，则会占用1000*3=3000个文件块（多个文件不能放到一个块中）。\n\n​\t可以得出，如果文件越小，存储同等大小文件所需要的元信息就越多，所以，Hadoop更喜欢大文件。\n\n## （3）元信息的持久化\n\n​\t在NameNode中存放元信息的文件是fsimage。在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个edits中，并且edits文件和fsimage文件会SecondaryNameNode周期性地合并。\n\n## （4）SecondaryNameNode\n\n​\t在NameNode启动时，首先会加载fsimage到内存中，在系统运行期间，所有对NameNode的操作也都保存在内存中，同时为了防止数据丢失，这些操作又会不断的持久化到本地edits文件中。\n\n​\tedits文件的目的是为了提高系统的操作效率，NameNode在更新内存的元信息之前都会先将操作写入edits文件。在NameNode重启的过程中，edits会和fsimage合并到一起，但是合并的过程会影响到Hadoop重启的速度，SecondaryNameNode就是为了解决这个问题：\n\n![](/img/secondaryNameNode.jpg)\n\n​\tSecondaryNameNode的角色就是定期合并edits和fsimage文件：\n\n​\ta、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。\n\n​\tb、SecondaryNameNode从NameNode请求fsimage和edits文件。\n\n​\tc、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件。\n\n​\td、NameNode从SecondaryName获取合并好的新的fsimage并将旧的替换掉，并\n\n​\t使用的检查点：\n\n​\t\tfsimage：保存的是上个检查点的HDFS的元信息\n\n​\t\tedits：保存的是从上个检查点开始发生的HDFS元信息状态改变信息\n\n​\t\tfstime：保存了最后一个检查点的时间戳\n\n# 三、数据备份\n\n​\tHDFS通过备份数据块的形式来实现容错，除了文件的最后一个数据块外，其他所有数据块大小都是一样的，数据块的大小和备份银子都是可以配置的。\n\n​\tNmaeNode负责各个数据块的备份，DataNode会通过心跳的方式定期向NameNode发送自己节点上的Block报告，这个报告包含了DataNode节点上的所有数据块的列表。\n\n​\t写数据时候通过负载均衡，进行同步，但是会影响效率。当Hadoop的NameNode节点启动时，会进入安全模式。当副本数满足最小副本数，系统会退出安全模式。\n\n# 四、通信协议\n\n​\t所有的HDFS中的沟通协议都是基于TCP/IP协议的\n\n​\t（1）一个客户端通过指定的TCP端口与NameNode机器建立连接，并通过Client Protocol协议与NameNode交互。 NameNode只被动接受请求。\n\n​\t（2）DataNode则通过DataNode Protocol协议与NameNode进行沟通。\n\n​\t（3）HDFS的RPC对Client Protocol 和 DataNode Protocol做了封装。\n\n# 五、可靠性保证\n\n​\tHDFS可以允许DataNode失败。\n\n​\tDataNode会定期（默认3s）向NameNode发送心跳，若NameNode在指定时间间隔内没有收到心跳，它就认为此节点已经失败。此时NameNode把失败节点的数据备份到另一个健康的节点，这就保证了集群始终维持指定的副本数。\n\n​\tHDFS可以检测到数据块损坏。在读取数据块时，HDFS会对数据块和保存的校验和文件匹配，如果不匹配，NameNode会重新备份损坏的数据块。","slug":"HDFS概述","published":1,"updated":"2019-12-16T07:47:23.395Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm030001vguqt8wchv1b","content":"<p>本文权威指南读书笔记</p>\n<h1>一、HDFS的设计前提和目标</h1>\n<p>​\t（1）存储大文件：HDFS支持GB级别大小的文件；</p>\n<p>​\t（2）流式数据访问：保证高吞吐量</p>\n<p>​\t（3）容错性：完善的冗余备份机制；</p>\n<p>​\t（4）简单的一致性模型：一次写入多次读取；</p>\n<p>​\t（5）移动计算优于移动数据：HDFS使应用计算移动到离他最近数据位置的接口；</p>\n<p>​\t（6）兼容各种硬件和软件平台。</p>\n<p>​\tHDFS不适合的场景：</p>\n<p>​\t（1）大量小文件：文件的元数据存储在NameNode内容中，大量小文件意味着元数据增加，会占用大量内存；</p>\n<p>​\t（2）低延迟数据访问：HDFS是专门针对吞吐量而不是用户低延迟；</p>\n<p>​\t（3）多用户写入：导致一致性维护困难。</p>\n<h1>二、主要组件与架构</h1>\n<p>​\t主要三个组件：NameNode、SecondaryNameNode 和 DataNode</p>\n<p>​\t（HDFS以主从模式运行，其中NameNode、SecondaryNameNode运行再Master节点，DataNode运行再Slave节点上）</p>\n<p>​\tNameNode负责信息维护者，DateNode负责存取数据。</p>\n<p>​\t<img src=\"/img/hdfs.png\" alt=\"image-20191216141048512\"></p>\n<h2>(1) NameNode</h2>\n<p>​\tNameNode管理着文件系统的命名空间 , 它维护文件系统树及树中的所有文件和目录</p>\n<p>​\tNameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。</p>\n<p>​\t\ta. 文件名目录名及它们之间的层级关系</p>\n<p>​\t\tb. 文件目录的所有者及其权限</p>\n<p>​\t\tc.每个文件块的名及文件有哪些块组成</p>\n<p>​\tNameNode启动时加载到内存中，元信息会保存各个块的名称及文件由哪些块组成。</p>\n<p>​\tNameNode占用大量内存和I/O资源，对Name容错机制也十分重要</p>\n<h2>(2) DataNode</h2>\n<p>​\tDataNode是HDFS中的Worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。</p>\n<p>​\t负责实际文件数据的保存于操作，与客户端直接交互。</p>\n<p>​\t例子：一条元信息记录会占用200B内存空间。 假设块大小为64MB，备份数量是3，那么一个1GB大小的文件将占用16<em>3=48个文件块。如果现在有1000个1MB大小的文件，则会占用1000</em>3=3000个文件块（多个文件不能放到一个块中）。</p>\n<p>​\t可以得出，如果文件越小，存储同等大小文件所需要的元信息就越多，所以，Hadoop更喜欢大文件。</p>\n<h2>（3）元信息的持久化</h2>\n<p>​\t在NameNode中存放元信息的文件是fsimage。在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个edits中，并且edits文件和fsimage文件会SecondaryNameNode周期性地合并。</p>\n<h2>（4）SecondaryNameNode</h2>\n<p>​\t在NameNode启动时，首先会加载fsimage到内存中，在系统运行期间，所有对NameNode的操作也都保存在内存中，同时为了防止数据丢失，这些操作又会不断的持久化到本地edits文件中。</p>\n<p>​\tedits文件的目的是为了提高系统的操作效率，NameNode在更新内存的元信息之前都会先将操作写入edits文件。在NameNode重启的过程中，edits会和fsimage合并到一起，但是合并的过程会影响到Hadoop重启的速度，SecondaryNameNode就是为了解决这个问题：</p>\n<p><img src=\"/img/secondaryNameNode.jpg\" alt></p>\n<p>​\tSecondaryNameNode的角色就是定期合并edits和fsimage文件：</p>\n<p>​\ta、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。</p>\n<p>​\tb、SecondaryNameNode从NameNode请求fsimage和edits文件。</p>\n<p>​\tc、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件。</p>\n<p>​\td、NameNode从SecondaryName获取合并好的新的fsimage并将旧的替换掉，并</p>\n<p>​\t使用的检查点：</p>\n<p>​\t\tfsimage：保存的是上个检查点的HDFS的元信息</p>\n<p>​\t\tedits：保存的是从上个检查点开始发生的HDFS元信息状态改变信息</p>\n<p>​\t\tfstime：保存了最后一个检查点的时间戳</p>\n<h1>三、数据备份</h1>\n<p>​\tHDFS通过备份数据块的形式来实现容错，除了文件的最后一个数据块外，其他所有数据块大小都是一样的，数据块的大小和备份银子都是可以配置的。</p>\n<p>​\tNmaeNode负责各个数据块的备份，DataNode会通过心跳的方式定期向NameNode发送自己节点上的Block报告，这个报告包含了DataNode节点上的所有数据块的列表。</p>\n<p>​\t写数据时候通过负载均衡，进行同步，但是会影响效率。当Hadoop的NameNode节点启动时，会进入安全模式。当副本数满足最小副本数，系统会退出安全模式。</p>\n<h1>四、通信协议</h1>\n<p>​\t所有的HDFS中的沟通协议都是基于TCP/IP协议的</p>\n<p>​\t（1）一个客户端通过指定的TCP端口与NameNode机器建立连接，并通过Client Protocol协议与NameNode交互。 NameNode只被动接受请求。</p>\n<p>​\t（2）DataNode则通过DataNode Protocol协议与NameNode进行沟通。</p>\n<p>​\t（3）HDFS的RPC对Client Protocol 和 DataNode Protocol做了封装。</p>\n<h1>五、可靠性保证</h1>\n<p>​\tHDFS可以允许DataNode失败。</p>\n<p>​\tDataNode会定期（默认3s）向NameNode发送心跳，若NameNode在指定时间间隔内没有收到心跳，它就认为此节点已经失败。此时NameNode把失败节点的数据备份到另一个健康的节点，这就保证了集群始终维持指定的副本数。</p>\n<p>​\tHDFS可以检测到数据块损坏。在读取数据块时，HDFS会对数据块和保存的校验和文件匹配，如果不匹配，NameNode会重新备份损坏的数据块。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>本文权威指南读书笔记</p>\n<h1>一、HDFS的设计前提和目标</h1>\n<p>​\t（1）存储大文件：HDFS支持GB级别大小的文件；</p>\n<p>​\t（2）流式数据访问：保证高吞吐量</p>\n<p>​\t（3）容错性：完善的冗余备份机制；</p>\n<p>​\t（4）简单的一致性模型：一次写入多次读取；</p>\n<p>​\t（5）移动计算优于移动数据：HDFS使应用计算移动到离他最近数据位置的接口；</p>\n<p>​\t（6）兼容各种硬件和软件平台。</p>\n<p>​\tHDFS不适合的场景：</p>\n<p>​\t（1）大量小文件：文件的元数据存储在NameNode内容中，大量小文件意味着元数据增加，会占用大量内存；</p>\n<p>​\t（2）低延迟数据访问：HDFS是专门针对吞吐量而不是用户低延迟；</p>\n<p>​\t（3）多用户写入：导致一致性维护困难。</p>\n<h1>二、主要组件与架构</h1>\n<p>​\t主要三个组件：NameNode、SecondaryNameNode 和 DataNode</p>\n<p>​\t（HDFS以主从模式运行，其中NameNode、SecondaryNameNode运行再Master节点，DataNode运行再Slave节点上）</p>\n<p>​\tNameNode负责信息维护者，DateNode负责存取数据。</p>\n<p>​\t<img src=\"/img/hdfs.png\" alt=\"image-20191216141048512\"></p>\n<h2>(1) NameNode</h2>\n<p>​\tNameNode管理着文件系统的命名空间 , 它维护文件系统树及树中的所有文件和目录</p>\n<p>​\tNameNode也负责维护所有这些文件或目录的打开、关闭、移动、重命名等操作。</p>\n<p>​\t\ta. 文件名目录名及它们之间的层级关系</p>\n<p>​\t\tb. 文件目录的所有者及其权限</p>\n<p>​\t\tc.每个文件块的名及文件有哪些块组成</p>\n<p>​\tNameNode启动时加载到内存中，元信息会保存各个块的名称及文件由哪些块组成。</p>\n<p>​\tNameNode占用大量内存和I/O资源，对Name容错机制也十分重要</p>\n<h2>(2) DataNode</h2>\n<p>​\tDataNode是HDFS中的Worker节点，它负责存储数据块，也负责为系统客户端提供数据块的读写服务，同时还会根据NameNode的指示来进行创建、删除和复制等操作。此外，它还会通过心跳定期向NameNode发送所存储文件块列表信息。</p>\n<p>​\t负责实际文件数据的保存于操作，与客户端直接交互。</p>\n<p>​\t例子：一条元信息记录会占用200B内存空间。 假设块大小为64MB，备份数量是3，那么一个1GB大小的文件将占用16<em>3=48个文件块。如果现在有1000个1MB大小的文件，则会占用1000</em>3=3000个文件块（多个文件不能放到一个块中）。</p>\n<p>​\t可以得出，如果文件越小，存储同等大小文件所需要的元信息就越多，所以，Hadoop更喜欢大文件。</p>\n<h2>（3）元信息的持久化</h2>\n<p>​\t在NameNode中存放元信息的文件是fsimage。在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个edits中，并且edits文件和fsimage文件会SecondaryNameNode周期性地合并。</p>\n<h2>（4）SecondaryNameNode</h2>\n<p>​\t在NameNode启动时，首先会加载fsimage到内存中，在系统运行期间，所有对NameNode的操作也都保存在内存中，同时为了防止数据丢失，这些操作又会不断的持久化到本地edits文件中。</p>\n<p>​\tedits文件的目的是为了提高系统的操作效率，NameNode在更新内存的元信息之前都会先将操作写入edits文件。在NameNode重启的过程中，edits会和fsimage合并到一起，但是合并的过程会影响到Hadoop重启的速度，SecondaryNameNode就是为了解决这个问题：</p>\n<p><img src=\"/img/secondaryNameNode.jpg\" alt></p>\n<p>​\tSecondaryNameNode的角色就是定期合并edits和fsimage文件：</p>\n<p>​\ta、合并之前告知NameNode把所有的操作写到新的edites文件并将其命名为edits.new。</p>\n<p>​\tb、SecondaryNameNode从NameNode请求fsimage和edits文件。</p>\n<p>​\tc、SecondaryNameNode把fsimage和edits文件合并成新的fsimage文件。</p>\n<p>​\td、NameNode从SecondaryName获取合并好的新的fsimage并将旧的替换掉，并</p>\n<p>​\t使用的检查点：</p>\n<p>​\t\tfsimage：保存的是上个检查点的HDFS的元信息</p>\n<p>​\t\tedits：保存的是从上个检查点开始发生的HDFS元信息状态改变信息</p>\n<p>​\t\tfstime：保存了最后一个检查点的时间戳</p>\n<h1>三、数据备份</h1>\n<p>​\tHDFS通过备份数据块的形式来实现容错，除了文件的最后一个数据块外，其他所有数据块大小都是一样的，数据块的大小和备份银子都是可以配置的。</p>\n<p>​\tNmaeNode负责各个数据块的备份，DataNode会通过心跳的方式定期向NameNode发送自己节点上的Block报告，这个报告包含了DataNode节点上的所有数据块的列表。</p>\n<p>​\t写数据时候通过负载均衡，进行同步，但是会影响效率。当Hadoop的NameNode节点启动时，会进入安全模式。当副本数满足最小副本数，系统会退出安全模式。</p>\n<h1>四、通信协议</h1>\n<p>​\t所有的HDFS中的沟通协议都是基于TCP/IP协议的</p>\n<p>​\t（1）一个客户端通过指定的TCP端口与NameNode机器建立连接，并通过Client Protocol协议与NameNode交互。 NameNode只被动接受请求。</p>\n<p>​\t（2）DataNode则通过DataNode Protocol协议与NameNode进行沟通。</p>\n<p>​\t（3）HDFS的RPC对Client Protocol 和 DataNode Protocol做了封装。</p>\n<h1>五、可靠性保证</h1>\n<p>​\tHDFS可以允许DataNode失败。</p>\n<p>​\tDataNode会定期（默认3s）向NameNode发送心跳，若NameNode在指定时间间隔内没有收到心跳，它就认为此节点已经失败。此时NameNode把失败节点的数据备份到另一个健康的节点，这就保证了集群始终维持指定的副本数。</p>\n<p>​\tHDFS可以检测到数据块损坏。在读取数据块时，HDFS会对数据块和保存的校验和文件匹配，如果不匹配，NameNode会重新备份损坏的数据块。</p>\n"},{"title":"HDFS文件操作","author":"郑天祺","date":"2019-12-16T07:47:00.000Z","_content":"\n# \t一、读文件\n\n​\tHDFS有一个文件系统实例，客户端通过调用这个实例的open()方法就可以打开系统中希望读取的文件。\n\n​\tHDFS通过RPC调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回该块副本DataNode的节点地址。\n\n​\t另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就储存在客户端所在的节点上。\n\n​\t具体过程：\n\n​\t![image-20191216155358635](/img/hdfs-read-file.png)\n\n​\t（1）客户端发起请求\n\n​\t（2）客户端与NameNode得到文件的块及位置信息列表\n\n​\t（3）客户端直接和DataNode交互读取数据\n\n​\t（4）读取完成关闭连接\n\n​\t这样设计的巧妙之处有：\n\n​\t（1）在运行MapReduce任务时，每个客户端就是一个DataNode节点。\n\n​\t（2）NameNode 仅需要相应块的位置信息请求，否则随着客户端的增加，NameNode会很快成为瓶颈。\n\n​\tHadoop的网络拓扑。在海量数据处理过程中，主要限制因素时节点之间的带宽。衡量两个节点之间的带宽往往很难实现，在这里Hadoop采取了一个简单的方法，它把网络拓扑看成一棵树，两个节点的距离等于他们到最近共同祖先距离的综合，而树的层次可以这么划分：\n\n​\ta、同一个节点中的进程\n\n​\tb、同一机架上的不同节点\n\n​\tc、同一数据中心不同机架\n\n​\td、不同数据中心的节点\n\n例如：数据中心d1中有一个机架r1中一个节点n1表示为d1/r1/n1\n\n​\ta、distance(d1/r1/n1,d1/r1/n1)=0;\n\n​\tb、distance(d1/r1/n1,d1/r1/n2)=2;\n\n​\tc、distance(d1/r1/n1,d1/r2/n3)=4;\n\n​\td、distance(d1/r1/n1,d2/r3/n4)=6; \n\n# 二、写文件\n\nHDFS有一个分布式系统，客户端通过调用这个实例的create()方法就可以创建文件。\n\nDFS会发给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件。\n\n在创建文件前NameNode会做一些检查，看看文件是否存在，客户端是否有创建权限等。\n\n若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog；\n\n若不通过会向客户端抛出IOException。\n\n![image-20191216163905988](/img/hdfs-write-file.png)\n\n（1）首先，第一个DataNode是以数据包（4KB）的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的同时会向第二个DataNode（作为副本节点）传送数据。\n\n（2）在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包。\n\n（3）第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点。\n\n（4）传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK，最终 第一个DataNode会向客户端发回一个ACK。\n\n（感觉这个ACK和TCP/IP协议中的差不多：ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类[控制字符](https://baike.baidu.com/item/控制字符/6913704)。表示发来的数据已确认接收无误。）\n\n（5）当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点，然后客户端会向NameNode发送一个确认。\n\n（这里是最后一次ACK吗？还有有一个seq？因为上边说每次发送的数据包是4KB比较小，每次都有ACK吧应该，还是最后检验程序完整性？感觉和文件上传很类似，期待研究源码！）\n\n（6）如果管道中的任何一个DataNode失败，管道会被关闭，数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点。\n\n解答上述疑问：数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在HDFS中，供读取时进行完整性校验。\n\n# 三、删除文件\n\nHADOOP\t删除文件三部曲\n\n（1）NameNode只是重命名被删除的文件到 /trash 目录，因为重命名操作只是元信息的变动，所以整个过程非常快。在 /trash 中文件会被保留一定间隔的时间（默认6h）\n\n​\t（在这个期间文件可以恢复）；\n\n（2）当指定的时间到达，NameNode将会把文件从命名空间中删除；\n\n（3）标记删除的文件块释放空间，HDFS文件系统显示空间增加。\n\n# 四、修改文件\n\n想啥呢?\n\n","source":"_posts/HDFS文件操作.md","raw":"title: HDFS文件操作\nauthor: 郑天祺\ntags:\n  - HDFS\n  - HADOOP\ncategories:\n  - 大数据\ndate: 2019-12-16 15:47:00\n\n---\n\n# \t一、读文件\n\n​\tHDFS有一个文件系统实例，客户端通过调用这个实例的open()方法就可以打开系统中希望读取的文件。\n\n​\tHDFS通过RPC调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回该块副本DataNode的节点地址。\n\n​\t另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就储存在客户端所在的节点上。\n\n​\t具体过程：\n\n​\t![image-20191216155358635](/img/hdfs-read-file.png)\n\n​\t（1）客户端发起请求\n\n​\t（2）客户端与NameNode得到文件的块及位置信息列表\n\n​\t（3）客户端直接和DataNode交互读取数据\n\n​\t（4）读取完成关闭连接\n\n​\t这样设计的巧妙之处有：\n\n​\t（1）在运行MapReduce任务时，每个客户端就是一个DataNode节点。\n\n​\t（2）NameNode 仅需要相应块的位置信息请求，否则随着客户端的增加，NameNode会很快成为瓶颈。\n\n​\tHadoop的网络拓扑。在海量数据处理过程中，主要限制因素时节点之间的带宽。衡量两个节点之间的带宽往往很难实现，在这里Hadoop采取了一个简单的方法，它把网络拓扑看成一棵树，两个节点的距离等于他们到最近共同祖先距离的综合，而树的层次可以这么划分：\n\n​\ta、同一个节点中的进程\n\n​\tb、同一机架上的不同节点\n\n​\tc、同一数据中心不同机架\n\n​\td、不同数据中心的节点\n\n例如：数据中心d1中有一个机架r1中一个节点n1表示为d1/r1/n1\n\n​\ta、distance(d1/r1/n1,d1/r1/n1)=0;\n\n​\tb、distance(d1/r1/n1,d1/r1/n2)=2;\n\n​\tc、distance(d1/r1/n1,d1/r2/n3)=4;\n\n​\td、distance(d1/r1/n1,d2/r3/n4)=6; \n\n# 二、写文件\n\nHDFS有一个分布式系统，客户端通过调用这个实例的create()方法就可以创建文件。\n\nDFS会发给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件。\n\n在创建文件前NameNode会做一些检查，看看文件是否存在，客户端是否有创建权限等。\n\n若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog；\n\n若不通过会向客户端抛出IOException。\n\n![image-20191216163905988](/img/hdfs-write-file.png)\n\n（1）首先，第一个DataNode是以数据包（4KB）的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的同时会向第二个DataNode（作为副本节点）传送数据。\n\n（2）在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包。\n\n（3）第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点。\n\n（4）传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK，最终 第一个DataNode会向客户端发回一个ACK。\n\n（感觉这个ACK和TCP/IP协议中的差不多：ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类[控制字符](https://baike.baidu.com/item/控制字符/6913704)。表示发来的数据已确认接收无误。）\n\n（5）当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点，然后客户端会向NameNode发送一个确认。\n\n（这里是最后一次ACK吗？还有有一个seq？因为上边说每次发送的数据包是4KB比较小，每次都有ACK吧应该，还是最后检验程序完整性？感觉和文件上传很类似，期待研究源码！）\n\n（6）如果管道中的任何一个DataNode失败，管道会被关闭，数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点。\n\n解答上述疑问：数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在HDFS中，供读取时进行完整性校验。\n\n# 三、删除文件\n\nHADOOP\t删除文件三部曲\n\n（1）NameNode只是重命名被删除的文件到 /trash 目录，因为重命名操作只是元信息的变动，所以整个过程非常快。在 /trash 中文件会被保留一定间隔的时间（默认6h）\n\n​\t（在这个期间文件可以恢复）；\n\n（2）当指定的时间到达，NameNode将会把文件从命名空间中删除；\n\n（3）标记删除的文件块释放空间，HDFS文件系统显示空间增加。\n\n# 四、修改文件\n\n想啥呢?\n\n","slug":"HDFS文件操作","published":1,"updated":"2019-12-16T09:04:21.726Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm070004vguq41gihsf1","content":"<h1>一、读文件</h1>\n<p>​\tHDFS有一个文件系统实例，客户端通过调用这个实例的open()方法就可以打开系统中希望读取的文件。</p>\n<p>​\tHDFS通过RPC调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回该块副本DataNode的节点地址。</p>\n<p>​\t另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就储存在客户端所在的节点上。</p>\n<p>​\t具体过程：</p>\n<p>​\t<img src=\"/img/hdfs-read-file.png\" alt=\"image-20191216155358635\"></p>\n<p>​\t（1）客户端发起请求</p>\n<p>​\t（2）客户端与NameNode得到文件的块及位置信息列表</p>\n<p>​\t（3）客户端直接和DataNode交互读取数据</p>\n<p>​\t（4）读取完成关闭连接</p>\n<p>​\t这样设计的巧妙之处有：</p>\n<p>​\t（1）在运行MapReduce任务时，每个客户端就是一个DataNode节点。</p>\n<p>​\t（2）NameNode 仅需要相应块的位置信息请求，否则随着客户端的增加，NameNode会很快成为瓶颈。</p>\n<p>​\tHadoop的网络拓扑。在海量数据处理过程中，主要限制因素时节点之间的带宽。衡量两个节点之间的带宽往往很难实现，在这里Hadoop采取了一个简单的方法，它把网络拓扑看成一棵树，两个节点的距离等于他们到最近共同祖先距离的综合，而树的层次可以这么划分：</p>\n<p>​\ta、同一个节点中的进程</p>\n<p>​\tb、同一机架上的不同节点</p>\n<p>​\tc、同一数据中心不同机架</p>\n<p>​\td、不同数据中心的节点</p>\n<p>例如：数据中心d1中有一个机架r1中一个节点n1表示为d1/r1/n1</p>\n<p>​\ta、distance(d1/r1/n1,d1/r1/n1)=0;</p>\n<p>​\tb、distance(d1/r1/n1,d1/r1/n2)=2;</p>\n<p>​\tc、distance(d1/r1/n1,d1/r2/n3)=4;</p>\n<p>​\td、distance(d1/r1/n1,d2/r3/n4)=6;</p>\n<h1>二、写文件</h1>\n<p>HDFS有一个分布式系统，客户端通过调用这个实例的create()方法就可以创建文件。</p>\n<p>DFS会发给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件。</p>\n<p>在创建文件前NameNode会做一些检查，看看文件是否存在，客户端是否有创建权限等。</p>\n<p>若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog；</p>\n<p>若不通过会向客户端抛出IOException。</p>\n<p><img src=\"/img/hdfs-write-file.png\" alt=\"image-20191216163905988\"></p>\n<p>（1）首先，第一个DataNode是以数据包（4KB）的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的同时会向第二个DataNode（作为副本节点）传送数据。</p>\n<p>（2）在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包。</p>\n<p>（3）第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点。</p>\n<p>（4）传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK，最终 第一个DataNode会向客户端发回一个ACK。</p>\n<p>（感觉这个ACK和TCP/IP协议中的差不多：ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类<a href=\"https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6/6913704\" target=\"_blank\" rel=\"noopener\">控制字符</a>。表示发来的数据已确认接收无误。）</p>\n<p>（5）当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点，然后客户端会向NameNode发送一个确认。</p>\n<p>（这里是最后一次ACK吗？还有有一个seq？因为上边说每次发送的数据包是4KB比较小，每次都有ACK吧应该，还是最后检验程序完整性？感觉和文件上传很类似，期待研究源码！）</p>\n<p>（6）如果管道中的任何一个DataNode失败，管道会被关闭，数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点。</p>\n<p>解答上述疑问：数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在HDFS中，供读取时进行完整性校验。</p>\n<h1>三、删除文件</h1>\n<p>HADOOP\t删除文件三部曲</p>\n<p>（1）NameNode只是重命名被删除的文件到 /trash 目录，因为重命名操作只是元信息的变动，所以整个过程非常快。在 /trash 中文件会被保留一定间隔的时间（默认6h）</p>\n<p>​\t（在这个期间文件可以恢复）；</p>\n<p>（2）当指定的时间到达，NameNode将会把文件从命名空间中删除；</p>\n<p>（3）标记删除的文件块释放空间，HDFS文件系统显示空间增加。</p>\n<h1>四、修改文件</h1>\n<p>想啥呢?</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、读文件</h1>\n<p>​\tHDFS有一个文件系统实例，客户端通过调用这个实例的open()方法就可以打开系统中希望读取的文件。</p>\n<p>​\tHDFS通过RPC调用NameNode获取文件块的位置信息，对于文件的每一个块，NameNode会返回该块副本DataNode的节点地址。</p>\n<p>​\t另外，客户端还会根据网络拓扑来确定它与每一个DataNode的位置信息，从离它最近的那个DataNode获取数据块的副本，最理想的情况是数据块就储存在客户端所在的节点上。</p>\n<p>​\t具体过程：</p>\n<p>​\t<img src=\"/img/hdfs-read-file.png\" alt=\"image-20191216155358635\"></p>\n<p>​\t（1）客户端发起请求</p>\n<p>​\t（2）客户端与NameNode得到文件的块及位置信息列表</p>\n<p>​\t（3）客户端直接和DataNode交互读取数据</p>\n<p>​\t（4）读取完成关闭连接</p>\n<p>​\t这样设计的巧妙之处有：</p>\n<p>​\t（1）在运行MapReduce任务时，每个客户端就是一个DataNode节点。</p>\n<p>​\t（2）NameNode 仅需要相应块的位置信息请求，否则随着客户端的增加，NameNode会很快成为瓶颈。</p>\n<p>​\tHadoop的网络拓扑。在海量数据处理过程中，主要限制因素时节点之间的带宽。衡量两个节点之间的带宽往往很难实现，在这里Hadoop采取了一个简单的方法，它把网络拓扑看成一棵树，两个节点的距离等于他们到最近共同祖先距离的综合，而树的层次可以这么划分：</p>\n<p>​\ta、同一个节点中的进程</p>\n<p>​\tb、同一机架上的不同节点</p>\n<p>​\tc、同一数据中心不同机架</p>\n<p>​\td、不同数据中心的节点</p>\n<p>例如：数据中心d1中有一个机架r1中一个节点n1表示为d1/r1/n1</p>\n<p>​\ta、distance(d1/r1/n1,d1/r1/n1)=0;</p>\n<p>​\tb、distance(d1/r1/n1,d1/r1/n2)=2;</p>\n<p>​\tc、distance(d1/r1/n1,d1/r2/n3)=4;</p>\n<p>​\td、distance(d1/r1/n1,d2/r3/n4)=6;</p>\n<h1>二、写文件</h1>\n<p>HDFS有一个分布式系统，客户端通过调用这个实例的create()方法就可以创建文件。</p>\n<p>DFS会发给NameNode一个RPC调用，在文件系统的命名空间创建一个新文件。</p>\n<p>在创建文件前NameNode会做一些检查，看看文件是否存在，客户端是否有创建权限等。</p>\n<p>若检查通过，NameNode会为创建文件写一条记录到本地磁盘的EditLog；</p>\n<p>若不通过会向客户端抛出IOException。</p>\n<p><img src=\"/img/hdfs-write-file.png\" alt=\"image-20191216163905988\"></p>\n<p>（1）首先，第一个DataNode是以数据包（4KB）的形式从客户端接收数据的，DataNode在把数据包写入到本地磁盘的同时会向第二个DataNode（作为副本节点）传送数据。</p>\n<p>（2）在第二个DataNode把接收到的数据包写入本地磁盘时会向第三个DataNode发送数据包。</p>\n<p>（3）第三个DataNode开始向本地磁盘写入数据包。此时，数据包以流水线的形式被写入和备份到所有DataNode节点。</p>\n<p>（4）传送管道中的每个DataNode节点在收到数据后都会向前面那个DataNode发送一个ACK，最终 第一个DataNode会向客户端发回一个ACK。</p>\n<p>（感觉这个ACK和TCP/IP协议中的差不多：ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类<a href=\"https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6/6913704\" target=\"_blank\" rel=\"noopener\">控制字符</a>。表示发来的数据已确认接收无误。）</p>\n<p>（5）当客户端收到数据块的确认之后，数据块被认为已经持久化到所有节点，然后客户端会向NameNode发送一个确认。</p>\n<p>（这里是最后一次ACK吗？还有有一个seq？因为上边说每次发送的数据包是4KB比较小，每次都有ACK吧应该，还是最后检验程序完整性？感觉和文件上传很类似，期待研究源码！）</p>\n<p>（6）如果管道中的任何一个DataNode失败，管道会被关闭，数据将会继续写到剩余的DataNode中。同时NameNode会被告知待备份状态，NameNode会继续备份数据到新的可用的节点。</p>\n<p>解答上述疑问：数据块都会通过计算校验和来检测数据的完整性，校验和以隐藏文件的形式被单独存放在HDFS中，供读取时进行完整性校验。</p>\n<h1>三、删除文件</h1>\n<p>HADOOP\t删除文件三部曲</p>\n<p>（1）NameNode只是重命名被删除的文件到 /trash 目录，因为重命名操作只是元信息的变动，所以整个过程非常快。在 /trash 中文件会被保留一定间隔的时间（默认6h）</p>\n<p>​\t（在这个期间文件可以恢复）；</p>\n<p>（2）当指定的时间到达，NameNode将会把文件从命名空间中删除；</p>\n<p>（3）标记删除的文件块释放空间，HDFS文件系统显示空间增加。</p>\n<h1>四、修改文件</h1>\n<p>想啥呢?</p>\n"},{"title":"Git梳理","author":"郑天祺","date":"2019-08-29T02:28:00.000Z","_content":"## 1、Git介绍：\n\n​\tGit是目前世界上最先进的分布式版本控制系统。gitlab是公司搭建的代码版本控制平台，使用方法与github类似，项目负责人在gitlab上新建一个项目，并分享URL给开发人员。开发人员在负责人的gitlab项目页面上点\n\n​\t击“fork”按钮，将此项目fork到自己的gitlab上，这相当于是从负责人那拷贝了一份项目副本，无论开发人员如何修改代码都不会影响负责人那master分支上的代码。然后开发人员可以根据自己的项目分工，像对待普通项\n\n​\t目一样做clone、add、commit、push等操作。如果开发人员人为一个小模块做好了，可以点击“pull request”按钮，向负责人发送代码合并请求，要合并的代码文件也会以列表的形式同时发送给负责人，此时负责人会看到\n\n开发人员的请求，经审核如果代码没问题则会合并模块，并向开发人员发送确认合并的通知。\n\n## 2、为什么用GitLab？\n\n​\t清晰的项目管理和责任明确\n​\t清晰的看到产品迭代，为产品研发提供参考\n​\t能够形成项目管理课程，为我们的后续产品做准备，同时课程设计过程完全公开，降低产品和运营不匹配的问题。\n\n## 3、Git 工作区、暂存区和版本库\n\n工作区：就是你在电脑里能看到的目录。\n\n暂存区：英文叫stage, 或index。一般存放在 \".git目录下\" 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。\n\n版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。\n\n## 4、Git工作流程\n\n###     1、一个分支\n\n克隆 Git 资源作为工作目录。\n\n在克隆的资源上添加或修改文件。\n\n如果其他人修改了，你可以更新资源。\n\n在提交前查看修改。\n\n提交修改。\n\n###     2、多个分支\n\nfork项目，建立自己的分支[name]（直接git网页操作）\n\n将master分支clone 下来（git clone）\n\n修改当前分支为fork 的分支（git      checkoout [name]）\n\n代码的修改(commit and push)\n\n如果需要合并到主分支：pull request merge\n\n![](\\img\\Git工作流程.png)\n\n## 5、Git配置及使用：\n\n###     1）配置用户信息\n\n​    配置个人的用户名称和电子邮件地址：\n\n​    右键打开git bash命令行（如果设置了git的系统环境变量，就可以直接使用cmd命令行进行git操作）\n\n​        a）设置Git端上的用户名和用户邮箱（公司邮箱）\n\n```java\n$ git config --global user.name \"yourname\"\n$ git config --global user.email       \"yourname@xxxx.com\"\n```\n\n​        b）生成ssh公钥和私钥\n\n```java\n$ ssh -keygen -t rsa -C       \"yourname@xxxx.com\"\n一路回车\nC:/Users/admin/.ssh会生成一个id_rsa.pub公钥文件\nword打开id_rsa.pub将公钥添加进GitLab -> Profile Settings -> SSH Keys\n添加成功钉邮中会收到SSH key was added to your account邮件\n```\n\n\n\n###     2）查看配置\n\n```java\n        $ git config --list \n```\n\n###     3）创建仓库\n\n​        a）$ git clone：这是一种较为简单的初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份。 \n\n 例：$ git  clone  http://zzzzz.git   // 'http://zzzzzz.git'  这个URL地址的远程版本库，完全克隆到本地demo目录下 \n\n​\t注：git clone 时，可以所用不同的协议，包括 ssh, git, https 等，其中最常用的是 ssh，因为速度较快，还可以配置公钥免输入密码。 \n\n​        b）$ git init 和 $  git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用'git init'命令进行初始化；Git以后就会对该目录下的文件进行版本控制， \n\n​\t这时候如果你需要将它放到远程服务器上，可以在远程服务器gitlab上创建一个目录，并把可访问的URL记录下来，此时你就可以利用'git remote add'命令来增加一个远程服务器端。 \n\n```java\n例：\n$ git init   // 该命令执行完后会在当前目录生成一个 .git 目录。 \n$ git add .   // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步 \n$ touch README.md   // 初始化一个README.md文件 \n$ git commit -m \"初始化项目版本\"   // 提交当前工作空间的修改内容 \n$ git remote add origin  git@git.gag.cn:yourname/demo.git   // 关联远程仓库 \n$ git push -u origin master   // 将操作提交到gitlab \n$ git log   // 查看历史日志 \n```\n\n###     4）基本操作\n\n####         a）远程仓库相关命令 \n\n检出仓库： $ git clone http:/zzzzzzzz.git\n\n查看远程仓库：$ git remote -v\n\n添加远程仓库：$ git remote add [name] [url]\n\n删除远程仓库：$ git remote rm [name]\n\n修改远程仓库：$ git remote set-url --push       [name] [newUrl]\n\n拉取远程仓库：$ git pull [remoteName]       [localBranchName]   // 从其他的版本库（既可以是远程的也可以是本地的）将代码更新到本地，例如：'git pull origin master'就是将origin这个版本库的代码更新到本地的master主枝\n\n推送远程仓库：$ git push [remoteName]       [localBranchName]    // 将本地commit的代码更新到远程版本库中，例如'git push origin'就会将本地的代码更新到名为orgin的远程版本库中\n\n如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，如下：\n\n```java\n$git push origin test:master    // 提交本地test分支作为远程的master分支 \n\n$git push origin test:test    // 提交本地test分支作为远程的test分支 \n```\n\n####         b）分支(branch)操作相关命令 \n\n查看本地分支：$ git branch          // 列出本地所有的分支 对分支的增、删、查等操作，例如'git branch       new_branch'会从当前的工作版本创建一个叫做new_branch的新分支，'git branch -D new_branch'就会强制删除叫做new_branch的分支\n\n查看远程分支：$ git branch -r\n\n创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支\n\n切换分支：$ git checkout [name]    // Git的checkout有两个作用，其一是在不同的branch之间进行切换，例如'git checkout       new_branch'就会切换到new_branch的分支上去；另一个功能是还原代码的作用，例如'git checkout app/model/user.rb'就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚。\n\n创建新分支并立即切换到新分支：$ git checkout -b       [name]\n\n删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项\n\n合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并\n\n创建远程分支(本地分支push到远程)：$ git push origin [name]\n\n删除远程分支：$ git push origin       :heads/[name] 或 $ gitpush origin :[name] \n\n创建空的分支：(执行命令之前记得先提交你当前分支的修改，否则会被强制删干净)\n    $git symbolic-ref HEAD refs/heads/[name]\n    $rm .git/index\n    $git clean -fdx\n\n####         c）版本(tag)操作相关命令\n\n查看版本：$ git tag\n\n创建版本：$ git tag [name]          // 可以将某个具体的版本打上一个标签，这样你就不需要记忆复杂的版本号哈希值了，例如你可以使用'git tag revert_version       bbaf6fb5060b4875b18ff9ff637ce118256d6f20'来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了\n\n删除版本：$ git tag -d [name]\n\n查看远程版本：$ git tag -r\n\n创建远程版本(本地版本push到远程)：$ git push origin [name]\n\n删除远程版本：$ git push origin       :refs/tags/[name]\n\n合并远程仓库的tag到本地：$ git pull origin --tags\n\n上传本地tag到远程仓库：$ git push origin --tags\n\n创建带注释的tag：$       git tag -a [name] -m 'yourMessage' \n\n####         d）子模块(submodule)相关操作命令\n\n添加子模块：$ git submodule add [url]       [path]\n\n​                如：$git submodule add git://github.com/soberh/ui-libs.git src/main/webapp/ui-libs\n\n初始化子模块：$ git submodule init        ----只在首次检出仓库时运行一次就行\n\n更新子模块：$ git submodule update ----每次更新或切换分支后都需要运行一下\n\n删除子模块：（分4步走） \n\n```java\n\t1)$ git rm --cached [path]\n\n\t2)编辑“.gitmodules”文件，将子模块的相关配置节点删除掉\n\n\t3)编辑“ .git/config”文件，将子模块的相关配置节点删除掉\n\n\t4)手动删除子模块残留的目录\n```\n\n\n\n####         e）补充\n\n更改或者新增的文件：$ git add          // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步，例如'git       add app/model/user.rb'就会增加app/model/user.rb文件到Git的索引中\n\n删除文件：$ git rm    // 从当前的工作空间中和索引中删除文件，例如'git rm app/model/user.rb'\n\n查看历史日志：$ git log\n\n还原：$ git revert          // 还原一个版本的修改，必须提供一个具体的Git版本号，例如'git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20'，Git的版本号都是生成的一个哈希值\n\n提交：$ git commit    //       当前工作空间的修改内容\n\n强制pull \n\n```java\ngit fetch --all \ngit reset --hard origin/master\ngit pull\n```\n\n强制push       \n\npush -u [url]         \n\n####         f）忽略一些文件、文件夹不提交\n\n​              在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如\n\n```java\ntarget\nbin\n*.db\n```\n\n###     5)解决冲突\n\n​        IDEA  ->   VCS  -> git  ->  Branches  ->   选中需要合并的远程分支  - >  Rebase current onto selected","source":"_posts/Git梳理.md","raw":"title: Git梳理\ntags:\n  - git\ncategories:\n  - 软件管理\nauthor: 郑天祺\ndate: 2019-08-29 10:28:00\n---\n## 1、Git介绍：\n\n​\tGit是目前世界上最先进的分布式版本控制系统。gitlab是公司搭建的代码版本控制平台，使用方法与github类似，项目负责人在gitlab上新建一个项目，并分享URL给开发人员。开发人员在负责人的gitlab项目页面上点\n\n​\t击“fork”按钮，将此项目fork到自己的gitlab上，这相当于是从负责人那拷贝了一份项目副本，无论开发人员如何修改代码都不会影响负责人那master分支上的代码。然后开发人员可以根据自己的项目分工，像对待普通项\n\n​\t目一样做clone、add、commit、push等操作。如果开发人员人为一个小模块做好了，可以点击“pull request”按钮，向负责人发送代码合并请求，要合并的代码文件也会以列表的形式同时发送给负责人，此时负责人会看到\n\n开发人员的请求，经审核如果代码没问题则会合并模块，并向开发人员发送确认合并的通知。\n\n## 2、为什么用GitLab？\n\n​\t清晰的项目管理和责任明确\n​\t清晰的看到产品迭代，为产品研发提供参考\n​\t能够形成项目管理课程，为我们的后续产品做准备，同时课程设计过程完全公开，降低产品和运营不匹配的问题。\n\n## 3、Git 工作区、暂存区和版本库\n\n工作区：就是你在电脑里能看到的目录。\n\n暂存区：英文叫stage, 或index。一般存放在 \".git目录下\" 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。\n\n版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。\n\n## 4、Git工作流程\n\n###     1、一个分支\n\n克隆 Git 资源作为工作目录。\n\n在克隆的资源上添加或修改文件。\n\n如果其他人修改了，你可以更新资源。\n\n在提交前查看修改。\n\n提交修改。\n\n###     2、多个分支\n\nfork项目，建立自己的分支[name]（直接git网页操作）\n\n将master分支clone 下来（git clone）\n\n修改当前分支为fork 的分支（git      checkoout [name]）\n\n代码的修改(commit and push)\n\n如果需要合并到主分支：pull request merge\n\n![](\\img\\Git工作流程.png)\n\n## 5、Git配置及使用：\n\n###     1）配置用户信息\n\n​    配置个人的用户名称和电子邮件地址：\n\n​    右键打开git bash命令行（如果设置了git的系统环境变量，就可以直接使用cmd命令行进行git操作）\n\n​        a）设置Git端上的用户名和用户邮箱（公司邮箱）\n\n```java\n$ git config --global user.name \"yourname\"\n$ git config --global user.email       \"yourname@xxxx.com\"\n```\n\n​        b）生成ssh公钥和私钥\n\n```java\n$ ssh -keygen -t rsa -C       \"yourname@xxxx.com\"\n一路回车\nC:/Users/admin/.ssh会生成一个id_rsa.pub公钥文件\nword打开id_rsa.pub将公钥添加进GitLab -> Profile Settings -> SSH Keys\n添加成功钉邮中会收到SSH key was added to your account邮件\n```\n\n\n\n###     2）查看配置\n\n```java\n        $ git config --list \n```\n\n###     3）创建仓库\n\n​        a）$ git clone：这是一种较为简单的初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份。 \n\n 例：$ git  clone  http://zzzzz.git   // 'http://zzzzzz.git'  这个URL地址的远程版本库，完全克隆到本地demo目录下 \n\n​\t注：git clone 时，可以所用不同的协议，包括 ssh, git, https 等，其中最常用的是 ssh，因为速度较快，还可以配置公钥免输入密码。 \n\n​        b）$ git init 和 $  git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用'git init'命令进行初始化；Git以后就会对该目录下的文件进行版本控制， \n\n​\t这时候如果你需要将它放到远程服务器上，可以在远程服务器gitlab上创建一个目录，并把可访问的URL记录下来，此时你就可以利用'git remote add'命令来增加一个远程服务器端。 \n\n```java\n例：\n$ git init   // 该命令执行完后会在当前目录生成一个 .git 目录。 \n$ git add .   // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步 \n$ touch README.md   // 初始化一个README.md文件 \n$ git commit -m \"初始化项目版本\"   // 提交当前工作空间的修改内容 \n$ git remote add origin  git@git.gag.cn:yourname/demo.git   // 关联远程仓库 \n$ git push -u origin master   // 将操作提交到gitlab \n$ git log   // 查看历史日志 \n```\n\n###     4）基本操作\n\n####         a）远程仓库相关命令 \n\n检出仓库： $ git clone http:/zzzzzzzz.git\n\n查看远程仓库：$ git remote -v\n\n添加远程仓库：$ git remote add [name] [url]\n\n删除远程仓库：$ git remote rm [name]\n\n修改远程仓库：$ git remote set-url --push       [name] [newUrl]\n\n拉取远程仓库：$ git pull [remoteName]       [localBranchName]   // 从其他的版本库（既可以是远程的也可以是本地的）将代码更新到本地，例如：'git pull origin master'就是将origin这个版本库的代码更新到本地的master主枝\n\n推送远程仓库：$ git push [remoteName]       [localBranchName]    // 将本地commit的代码更新到远程版本库中，例如'git push origin'就会将本地的代码更新到名为orgin的远程版本库中\n\n如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，如下：\n\n```java\n$git push origin test:master    // 提交本地test分支作为远程的master分支 \n\n$git push origin test:test    // 提交本地test分支作为远程的test分支 \n```\n\n####         b）分支(branch)操作相关命令 \n\n查看本地分支：$ git branch          // 列出本地所有的分支 对分支的增、删、查等操作，例如'git branch       new_branch'会从当前的工作版本创建一个叫做new_branch的新分支，'git branch -D new_branch'就会强制删除叫做new_branch的分支\n\n查看远程分支：$ git branch -r\n\n创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支\n\n切换分支：$ git checkout [name]    // Git的checkout有两个作用，其一是在不同的branch之间进行切换，例如'git checkout       new_branch'就会切换到new_branch的分支上去；另一个功能是还原代码的作用，例如'git checkout app/model/user.rb'就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚。\n\n创建新分支并立即切换到新分支：$ git checkout -b       [name]\n\n删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项\n\n合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并\n\n创建远程分支(本地分支push到远程)：$ git push origin [name]\n\n删除远程分支：$ git push origin       :heads/[name] 或 $ gitpush origin :[name] \n\n创建空的分支：(执行命令之前记得先提交你当前分支的修改，否则会被强制删干净)\n    $git symbolic-ref HEAD refs/heads/[name]\n    $rm .git/index\n    $git clean -fdx\n\n####         c）版本(tag)操作相关命令\n\n查看版本：$ git tag\n\n创建版本：$ git tag [name]          // 可以将某个具体的版本打上一个标签，这样你就不需要记忆复杂的版本号哈希值了，例如你可以使用'git tag revert_version       bbaf6fb5060b4875b18ff9ff637ce118256d6f20'来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了\n\n删除版本：$ git tag -d [name]\n\n查看远程版本：$ git tag -r\n\n创建远程版本(本地版本push到远程)：$ git push origin [name]\n\n删除远程版本：$ git push origin       :refs/tags/[name]\n\n合并远程仓库的tag到本地：$ git pull origin --tags\n\n上传本地tag到远程仓库：$ git push origin --tags\n\n创建带注释的tag：$       git tag -a [name] -m 'yourMessage' \n\n####         d）子模块(submodule)相关操作命令\n\n添加子模块：$ git submodule add [url]       [path]\n\n​                如：$git submodule add git://github.com/soberh/ui-libs.git src/main/webapp/ui-libs\n\n初始化子模块：$ git submodule init        ----只在首次检出仓库时运行一次就行\n\n更新子模块：$ git submodule update ----每次更新或切换分支后都需要运行一下\n\n删除子模块：（分4步走） \n\n```java\n\t1)$ git rm --cached [path]\n\n\t2)编辑“.gitmodules”文件，将子模块的相关配置节点删除掉\n\n\t3)编辑“ .git/config”文件，将子模块的相关配置节点删除掉\n\n\t4)手动删除子模块残留的目录\n```\n\n\n\n####         e）补充\n\n更改或者新增的文件：$ git add          // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步，例如'git       add app/model/user.rb'就会增加app/model/user.rb文件到Git的索引中\n\n删除文件：$ git rm    // 从当前的工作空间中和索引中删除文件，例如'git rm app/model/user.rb'\n\n查看历史日志：$ git log\n\n还原：$ git revert          // 还原一个版本的修改，必须提供一个具体的Git版本号，例如'git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20'，Git的版本号都是生成的一个哈希值\n\n提交：$ git commit    //       当前工作空间的修改内容\n\n强制pull \n\n```java\ngit fetch --all \ngit reset --hard origin/master\ngit pull\n```\n\n强制push       \n\npush -u [url]         \n\n####         f）忽略一些文件、文件夹不提交\n\n​              在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如\n\n```java\ntarget\nbin\n*.db\n```\n\n###     5)解决冲突\n\n​        IDEA  ->   VCS  -> git  ->  Branches  ->   选中需要合并的远程分支  - >  Rebase current onto selected","slug":"Git梳理","published":1,"updated":"2019-10-15T12:21:32.785Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm080005vguqmglnnrjn","content":"<h2>1、Git介绍：</h2>\n<p>​\tGit是目前世界上最先进的分布式版本控制系统。gitlab是公司搭建的代码版本控制平台，使用方法与github类似，项目负责人在gitlab上新建一个项目，并分享URL给开发人员。开发人员在负责人的gitlab项目页面上点</p>\n<p>​\t击“fork”按钮，将此项目fork到自己的gitlab上，这相当于是从负责人那拷贝了一份项目副本，无论开发人员如何修改代码都不会影响负责人那master分支上的代码。然后开发人员可以根据自己的项目分工，像对待普通项</p>\n<p>​\t目一样做clone、add、commit、push等操作。如果开发人员人为一个小模块做好了，可以点击“pull request”按钮，向负责人发送代码合并请求，要合并的代码文件也会以列表的形式同时发送给负责人，此时负责人会看到</p>\n<p>开发人员的请求，经审核如果代码没问题则会合并模块，并向开发人员发送确认合并的通知。</p>\n<h2>2、为什么用GitLab？</h2>\n<p>​\t清晰的项目管理和责任明确\n​\t清晰的看到产品迭代，为产品研发提供参考\n​\t能够形成项目管理课程，为我们的后续产品做准备，同时课程设计过程完全公开，降低产品和运营不匹配的问题。</p>\n<h2>3、Git 工作区、暂存区和版本库</h2>\n<p>工作区：就是你在电脑里能看到的目录。</p>\n<p>暂存区：英文叫stage, 或index。一般存放在 &quot;.git目录下&quot; 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。</p>\n<p>版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。</p>\n<h2>4、Git工作流程</h2>\n<h3>1、一个分支</h3>\n<p>克隆 Git 资源作为工作目录。</p>\n<p>在克隆的资源上添加或修改文件。</p>\n<p>如果其他人修改了，你可以更新资源。</p>\n<p>在提交前查看修改。</p>\n<p>提交修改。</p>\n<h3>2、多个分支</h3>\n<p>fork项目，建立自己的分支[name]（直接git网页操作）</p>\n<p>将master分支clone 下来（git clone）</p>\n<p>修改当前分支为fork 的分支（git      checkoout [name]）</p>\n<p>代码的修改(commit and push)</p>\n<p>如果需要合并到主分支：pull request merge</p>\n<p><img src=\"%5Cimg%5CGit%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png\" alt></p>\n<h2>5、Git配置及使用：</h2>\n<h3>1）配置用户信息</h3>\n<p>​    配置个人的用户名称和电子邮件地址：</p>\n<p>​    右键打开git bash命令行（如果设置了git的系统环境变量，就可以直接使用cmd命令行进行git操作）</p>\n<p>​        a）设置Git端上的用户名和用户邮箱（公司邮箱）</p>\n<pre><code class=\"language-java\">$ git config --global user.name &quot;yourname&quot;\n$ git config --global user.email       &quot;yourname@xxxx.com&quot;\n</code></pre>\n<p>​        b）生成ssh公钥和私钥</p>\n<pre><code class=\"language-java\">$ ssh -keygen -t rsa -C       &quot;yourname@xxxx.com&quot;\n一路回车\nC:/Users/admin/.ssh会生成一个id_rsa.pub公钥文件\nword打开id_rsa.pub将公钥添加进GitLab -&gt; Profile Settings -&gt; SSH Keys\n添加成功钉邮中会收到SSH key was added to your account邮件\n</code></pre>\n<h3>2）查看配置</h3>\n<pre><code class=\"language-java\">        $ git config --list \n</code></pre>\n<h3>3）创建仓库</h3>\n<p>​        a）$ git clone：这是一种较为简单的初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份。</p>\n<p>例：$ git  clone  http://zzzzz.git   // 'http://zzzzzz.git'  这个URL地址的远程版本库，完全克隆到本地demo目录下</p>\n<p>​\t注：git clone 时，可以所用不同的协议，包括 ssh, git, https 等，其中最常用的是 ssh，因为速度较快，还可以配置公钥免输入密码。</p>\n<p>​        b）$ git init 和 $  git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用'git init'命令进行初始化；Git以后就会对该目录下的文件进行版本控制，</p>\n<p>​\t这时候如果你需要将它放到远程服务器上，可以在远程服务器gitlab上创建一个目录，并把可访问的URL记录下来，此时你就可以利用'git remote add'命令来增加一个远程服务器端。</p>\n<pre><code class=\"language-java\">例：\n$ git init   // 该命令执行完后会在当前目录生成一个 .git 目录。 \n$ git add .   // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步 \n$ touch README.md   // 初始化一个README.md文件 \n$ git commit -m &quot;初始化项目版本&quot;   // 提交当前工作空间的修改内容 \n$ git remote add origin  git@git.gag.cn:yourname/demo.git   // 关联远程仓库 \n$ git push -u origin master   // 将操作提交到gitlab \n$ git log   // 查看历史日志 \n</code></pre>\n<h3>4）基本操作</h3>\n<h4>a）远程仓库相关命令</h4>\n<p>检出仓库： $ git clone http:/zzzzzzzz.git</p>\n<p>查看远程仓库：$ git remote -v</p>\n<p>添加远程仓库：$ git remote add [name] [url]</p>\n<p>删除远程仓库：$ git remote rm [name]</p>\n<p>修改远程仓库：$ git remote set-url --push       [name] [newUrl]</p>\n<p>拉取远程仓库：$ git pull [remoteName]       [localBranchName]   // 从其他的版本库（既可以是远程的也可以是本地的）将代码更新到本地，例如：'git pull origin master'就是将origin这个版本库的代码更新到本地的master主枝</p>\n<p>推送远程仓库：$ git push [remoteName]       [localBranchName]    // 将本地commit的代码更新到远程版本库中，例如'git push origin'就会将本地的代码更新到名为orgin的远程版本库中</p>\n<p>如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，如下：</p>\n<pre><code class=\"language-java\">$git push origin test:master    // 提交本地test分支作为远程的master分支 \n\n$git push origin test:test    // 提交本地test分支作为远程的test分支 \n</code></pre>\n<h4>b）分支(branch)操作相关命令</h4>\n<p>查看本地分支：$ git branch          // 列出本地所有的分支 对分支的增、删、查等操作，例如'git branch       new_branch'会从当前的工作版本创建一个叫做new_branch的新分支，'git branch -D new_branch'就会强制删除叫做new_branch的分支</p>\n<p>查看远程分支：$ git branch -r</p>\n<p>创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支</p>\n<p>切换分支：$ git checkout [name]    // Git的checkout有两个作用，其一是在不同的branch之间进行切换，例如'git checkout       new_branch'就会切换到new_branch的分支上去；另一个功能是还原代码的作用，例如'git checkout app/model/user.rb'就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚。</p>\n<p>创建新分支并立即切换到新分支：$ git checkout -b       [name]</p>\n<p>删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项</p>\n<p>合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并</p>\n<p>创建远程分支(本地分支push到远程)：$ git push origin [name]</p>\n<p>删除远程分支：$ git push origin       :heads/[name] 或 $ gitpush origin :[name]</p>\n<p>创建空的分支：(执行命令之前记得先提交你当前分支的修改，否则会被强制删干净)\n$git symbolic-ref HEAD refs/heads/[name]\n$rm .git/index\n$git clean -fdx</p>\n<h4>c）版本(tag)操作相关命令</h4>\n<p>查看版本：$ git tag</p>\n<p>创建版本：$ git tag [name]          // 可以将某个具体的版本打上一个标签，这样你就不需要记忆复杂的版本号哈希值了，例如你可以使用'git tag revert_version       bbaf6fb5060b4875b18ff9ff637ce118256d6f20'来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了</p>\n<p>删除版本：$ git tag -d [name]</p>\n<p>查看远程版本：$ git tag -r</p>\n<p>创建远程版本(本地版本push到远程)：$ git push origin [name]</p>\n<p>删除远程版本：$ git push origin       :refs/tags/[name]</p>\n<p>合并远程仓库的tag到本地：$ git pull origin --tags</p>\n<p>上传本地tag到远程仓库：$ git push origin --tags</p>\n<p>创建带注释的tag：$       git tag -a [name] -m 'yourMessage'</p>\n<h4>d）子模块(submodule)相关操作命令</h4>\n<p>添加子模块：$ git submodule add [url]       [path]</p>\n<p>​                如：$git submodule add git://github.com/soberh/ui-libs.git src/main/webapp/ui-libs</p>\n<p>初始化子模块：$ git submodule init        ----只在首次检出仓库时运行一次就行</p>\n<p>更新子模块：$ git submodule update ----每次更新或切换分支后都需要运行一下</p>\n<p>删除子模块：（分4步走）</p>\n<pre><code class=\"language-java\">\t1)$ git rm --cached [path]\n\n\t2)编辑“.gitmodules”文件，将子模块的相关配置节点删除掉\n\n\t3)编辑“ .git/config”文件，将子模块的相关配置节点删除掉\n\n\t4)手动删除子模块残留的目录\n</code></pre>\n<h4>e）补充</h4>\n<p>更改或者新增的文件：$ git add          // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步，例如'git       add app/model/user.rb'就会增加app/model/user.rb文件到Git的索引中</p>\n<p>删除文件：$ git rm    // 从当前的工作空间中和索引中删除文件，例如'git rm app/model/user.rb'</p>\n<p>查看历史日志：$ git log</p>\n<p>还原：$ git revert          // 还原一个版本的修改，必须提供一个具体的Git版本号，例如'git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20'，Git的版本号都是生成的一个哈希值</p>\n<p>提交：$ git commit    //       当前工作空间的修改内容</p>\n<p>强制pull</p>\n<pre><code class=\"language-java\">git fetch --all \ngit reset --hard origin/master\ngit pull\n</code></pre>\n<p>强制push</p>\n<p>push -u [url]</p>\n<h4>f）忽略一些文件、文件夹不提交</h4>\n<p>​              在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如</p>\n<pre><code class=\"language-java\">target\nbin\n*.db\n</code></pre>\n<h3>5)解决冲突</h3>\n<p>​        IDEA  -&gt;   VCS  -&gt; git  -&gt;  Branches  -&gt;   选中需要合并的远程分支  - &gt;  Rebase current onto selected</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、Git介绍：</h2>\n<p>​\tGit是目前世界上最先进的分布式版本控制系统。gitlab是公司搭建的代码版本控制平台，使用方法与github类似，项目负责人在gitlab上新建一个项目，并分享URL给开发人员。开发人员在负责人的gitlab项目页面上点</p>\n<p>​\t击“fork”按钮，将此项目fork到自己的gitlab上，这相当于是从负责人那拷贝了一份项目副本，无论开发人员如何修改代码都不会影响负责人那master分支上的代码。然后开发人员可以根据自己的项目分工，像对待普通项</p>\n<p>​\t目一样做clone、add、commit、push等操作。如果开发人员人为一个小模块做好了，可以点击“pull request”按钮，向负责人发送代码合并请求，要合并的代码文件也会以列表的形式同时发送给负责人，此时负责人会看到</p>\n<p>开发人员的请求，经审核如果代码没问题则会合并模块，并向开发人员发送确认合并的通知。</p>\n<h2>2、为什么用GitLab？</h2>\n<p>​\t清晰的项目管理和责任明确\n​\t清晰的看到产品迭代，为产品研发提供参考\n​\t能够形成项目管理课程，为我们的后续产品做准备，同时课程设计过程完全公开，降低产品和运营不匹配的问题。</p>\n<h2>3、Git 工作区、暂存区和版本库</h2>\n<p>工作区：就是你在电脑里能看到的目录。</p>\n<p>暂存区：英文叫stage, 或index。一般存放在 &quot;.git目录下&quot; 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。</p>\n<p>版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。</p>\n<h2>4、Git工作流程</h2>\n<h3>1、一个分支</h3>\n<p>克隆 Git 资源作为工作目录。</p>\n<p>在克隆的资源上添加或修改文件。</p>\n<p>如果其他人修改了，你可以更新资源。</p>\n<p>在提交前查看修改。</p>\n<p>提交修改。</p>\n<h3>2、多个分支</h3>\n<p>fork项目，建立自己的分支[name]（直接git网页操作）</p>\n<p>将master分支clone 下来（git clone）</p>\n<p>修改当前分支为fork 的分支（git      checkoout [name]）</p>\n<p>代码的修改(commit and push)</p>\n<p>如果需要合并到主分支：pull request merge</p>\n<p><img src=\"%5Cimg%5CGit%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png\" alt></p>\n<h2>5、Git配置及使用：</h2>\n<h3>1）配置用户信息</h3>\n<p>​    配置个人的用户名称和电子邮件地址：</p>\n<p>​    右键打开git bash命令行（如果设置了git的系统环境变量，就可以直接使用cmd命令行进行git操作）</p>\n<p>​        a）设置Git端上的用户名和用户邮箱（公司邮箱）</p>\n<pre><code class=\"language-java\">$ git config --global user.name &quot;yourname&quot;\n$ git config --global user.email       &quot;yourname@xxxx.com&quot;\n</code></pre>\n<p>​        b）生成ssh公钥和私钥</p>\n<pre><code class=\"language-java\">$ ssh -keygen -t rsa -C       &quot;yourname@xxxx.com&quot;\n一路回车\nC:/Users/admin/.ssh会生成一个id_rsa.pub公钥文件\nword打开id_rsa.pub将公钥添加进GitLab -&gt; Profile Settings -&gt; SSH Keys\n添加成功钉邮中会收到SSH key was added to your account邮件\n</code></pre>\n<h3>2）查看配置</h3>\n<pre><code class=\"language-java\">        $ git config --list \n</code></pre>\n<h3>3）创建仓库</h3>\n<p>​        a）$ git clone：这是一种较为简单的初始化方式，当你已经有一个远程的Git版本库，只需要在本地克隆一份。</p>\n<p>例：$ git  clone  http://zzzzz.git   // 'http://zzzzzz.git'  这个URL地址的远程版本库，完全克隆到本地demo目录下</p>\n<p>​\t注：git clone 时，可以所用不同的协议，包括 ssh, git, https 等，其中最常用的是 ssh，因为速度较快，还可以配置公钥免输入密码。</p>\n<p>​        b）$ git init 和 $  git remote：这种方式稍微复杂一些，当你本地创建了一个工作目录，你可以进入这个目录，使用'git init'命令进行初始化；Git以后就会对该目录下的文件进行版本控制，</p>\n<p>​\t这时候如果你需要将它放到远程服务器上，可以在远程服务器gitlab上创建一个目录，并把可访问的URL记录下来，此时你就可以利用'git remote add'命令来增加一个远程服务器端。</p>\n<pre><code class=\"language-java\">例：\n$ git init   // 该命令执行完后会在当前目录生成一个 .git 目录。 \n$ git add .   // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步 \n$ touch README.md   // 初始化一个README.md文件 \n$ git commit -m &quot;初始化项目版本&quot;   // 提交当前工作空间的修改内容 \n$ git remote add origin  git@git.gag.cn:yourname/demo.git   // 关联远程仓库 \n$ git push -u origin master   // 将操作提交到gitlab \n$ git log   // 查看历史日志 \n</code></pre>\n<h3>4）基本操作</h3>\n<h4>a）远程仓库相关命令</h4>\n<p>检出仓库： $ git clone http:/zzzzzzzz.git</p>\n<p>查看远程仓库：$ git remote -v</p>\n<p>添加远程仓库：$ git remote add [name] [url]</p>\n<p>删除远程仓库：$ git remote rm [name]</p>\n<p>修改远程仓库：$ git remote set-url --push       [name] [newUrl]</p>\n<p>拉取远程仓库：$ git pull [remoteName]       [localBranchName]   // 从其他的版本库（既可以是远程的也可以是本地的）将代码更新到本地，例如：'git pull origin master'就是将origin这个版本库的代码更新到本地的master主枝</p>\n<p>推送远程仓库：$ git push [remoteName]       [localBranchName]    // 将本地commit的代码更新到远程版本库中，例如'git push origin'就会将本地的代码更新到名为orgin的远程版本库中</p>\n<p>如果想把本地的某个分支test提交到远程仓库，并作为远程仓库的master分支，或者作为另外一个名叫test的分支，如下：</p>\n<pre><code class=\"language-java\">$git push origin test:master    // 提交本地test分支作为远程的master分支 \n\n$git push origin test:test    // 提交本地test分支作为远程的test分支 \n</code></pre>\n<h4>b）分支(branch)操作相关命令</h4>\n<p>查看本地分支：$ git branch          // 列出本地所有的分支 对分支的增、删、查等操作，例如'git branch       new_branch'会从当前的工作版本创建一个叫做new_branch的新分支，'git branch -D new_branch'就会强制删除叫做new_branch的分支</p>\n<p>查看远程分支：$ git branch -r</p>\n<p>创建本地分支：$ git branch [name] ----注意新分支创建后不会自动切换为当前分支</p>\n<p>切换分支：$ git checkout [name]    // Git的checkout有两个作用，其一是在不同的branch之间进行切换，例如'git checkout       new_branch'就会切换到new_branch的分支上去；另一个功能是还原代码的作用，例如'git checkout app/model/user.rb'就会将user.rb文件从上一个已提交的版本中更新回来，未提交的内容全部会回滚。</p>\n<p>创建新分支并立即切换到新分支：$ git checkout -b       [name]</p>\n<p>删除分支：$ git branch -d [name] ---- -d选项只能删除已经参与了合并的分支，对于未有合并的分支是无法删除的。如果想强制删除一个分支，可以使用-D选项</p>\n<p>合并分支：$ git merge [name] ----将名称为[name]的分支与当前分支合并</p>\n<p>创建远程分支(本地分支push到远程)：$ git push origin [name]</p>\n<p>删除远程分支：$ git push origin       :heads/[name] 或 $ gitpush origin :[name]</p>\n<p>创建空的分支：(执行命令之前记得先提交你当前分支的修改，否则会被强制删干净)\n$git symbolic-ref HEAD refs/heads/[name]\n$rm .git/index\n$git clean -fdx</p>\n<h4>c）版本(tag)操作相关命令</h4>\n<p>查看版本：$ git tag</p>\n<p>创建版本：$ git tag [name]          // 可以将某个具体的版本打上一个标签，这样你就不需要记忆复杂的版本号哈希值了，例如你可以使用'git tag revert_version       bbaf6fb5060b4875b18ff9ff637ce118256d6f20'来标记这个被你还原的版本，那么以后你想查看该版本时，就可以使用 revert_version标签名，而不是哈希值了</p>\n<p>删除版本：$ git tag -d [name]</p>\n<p>查看远程版本：$ git tag -r</p>\n<p>创建远程版本(本地版本push到远程)：$ git push origin [name]</p>\n<p>删除远程版本：$ git push origin       :refs/tags/[name]</p>\n<p>合并远程仓库的tag到本地：$ git pull origin --tags</p>\n<p>上传本地tag到远程仓库：$ git push origin --tags</p>\n<p>创建带注释的tag：$       git tag -a [name] -m 'yourMessage'</p>\n<h4>d）子模块(submodule)相关操作命令</h4>\n<p>添加子模块：$ git submodule add [url]       [path]</p>\n<p>​                如：$git submodule add git://github.com/soberh/ui-libs.git src/main/webapp/ui-libs</p>\n<p>初始化子模块：$ git submodule init        ----只在首次检出仓库时运行一次就行</p>\n<p>更新子模块：$ git submodule update ----每次更新或切换分支后都需要运行一下</p>\n<p>删除子模块：（分4步走）</p>\n<pre><code class=\"language-java\">\t1)$ git rm --cached [path]\n\n\t2)编辑“.gitmodules”文件，将子模块的相关配置节点删除掉\n\n\t3)编辑“ .git/config”文件，将子模块的相关配置节点删除掉\n\n\t4)手动删除子模块残留的目录\n</code></pre>\n<h4>e）补充</h4>\n<p>更改或者新增的文件：$ git add          // 是将当前更改或者新增的文件加入到Git的索引中，加入到Git的索引中就表示记入了版本历史中，这也是提交之前所需要执行的一步，例如'git       add app/model/user.rb'就会增加app/model/user.rb文件到Git的索引中</p>\n<p>删除文件：$ git rm    // 从当前的工作空间中和索引中删除文件，例如'git rm app/model/user.rb'</p>\n<p>查看历史日志：$ git log</p>\n<p>还原：$ git revert          // 还原一个版本的修改，必须提供一个具体的Git版本号，例如'git revert bbaf6fb5060b4875b18ff9ff637ce118256d6f20'，Git的版本号都是生成的一个哈希值</p>\n<p>提交：$ git commit    //       当前工作空间的修改内容</p>\n<p>强制pull</p>\n<pre><code class=\"language-java\">git fetch --all \ngit reset --hard origin/master\ngit pull\n</code></pre>\n<p>强制push</p>\n<p>push -u [url]</p>\n<h4>f）忽略一些文件、文件夹不提交</h4>\n<p>​              在仓库根目录下创建名称为“.gitignore”的文件，写入不需要的文件夹名或文件，每个元素占一行即可，如</p>\n<pre><code class=\"language-java\">target\nbin\n*.db\n</code></pre>\n<h3>5)解决冲突</h3>\n<p>​        IDEA  -&gt;   VCS  -&gt; git  -&gt;  Branches  -&gt;   选中需要合并的远程分支  - &gt;  Rebase current onto selected</p>\n"},{"title":"SimpleDateFormat引发的线程安全问题","author":"郑天祺","date":"2019-10-12T10:42:00.000Z","_content":"\n# \t一、问题产生\n\n​\t在写java程序时，有时间戳转换的操作。\n\n```java\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\n/**\n * @author zhengtianqi\n * @date 2019/10/12\n */\npublic class DateTrans {\n\n    public static void main(String[] args) {\n\n        // 将2019-10-12 18:50:30 改成 2019年10月12日\n        String inDate = \"2019-10-12 18:50:30\";\n\n        SimpleDateFormat inPut = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        SimpleDateFormat outPut = new SimpleDateFormat(\"yyyy年MM月dd日\");\n\n        try {\n            Date temp = inPut.parse(inDate);\n            String outDate = outPut.format(temp);\n\n            System.out.println(outDate);\n\n        } catch (ParseException e) {\n            System.out.println(\"时间转换出错，出错信息为 ={}\" + e);\n        }\n\n    }\n}\n\n```\n\n\n\n涉及时间戳转换时，每次我们都new一个SimpleDateFormat对象，用起来很麻烦。\n\n我们就把它们放到了一个常量类里，随时用随时取。\n\n```java\n/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\tpublic static final SimpleDateFormat IN_FORMAT = new SimpleDateFormat(\"yyyyMMddHHmmssSSS\");\n\tpublic static final SimpleDateFormat OUT_FORMAT = new SimpleDateFormat(\"yyyy-MM-dd\");\n\tpublic static final SimpleDateFormat VIEW_FORMAT = new SimpleDateFormat(\"yyyy年MM月\");\n\tpublic static final SimpleDateFormat INNER_FORMAT = new SimpleDateFormat(\"yyyy-MM\");\n\tpublic static final SimpleDateFormat RECALL_FORMAT = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n}\n```\n\n可是你想省事，麻烦就随之而来了！\n\n先看看错误：\n\n```java\n[2019-10-12 17:45:35,468][locallog][ERROR][TID: N/A][../filters/GlobalExeption.exceptionHandler:18][10.7.5.22][] - 服务器内部错误!\njava.lang.NumberFormatException: For input string: \".220188E.4220188\"\n        at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[?:1.8.0_221]\n        at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[?:1.8.0_221]\n        at java.lang.Double.parseDouble(Double.java:538) ~[?:1.8.0_221]\n        at java.text.DigitList.getDouble(DigitList.java:169) ~[?:1.8.0_221]\n        at java.text.DecimalFormat.parse(DecimalFormat.java:2089) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) ~[?:1.8.0_221]\n        at java.text.DateFormat.parse(DateFormat.java:364) ~[?:1.8.0_221]\n```\n\n# 二、问题查找\n\ndebug发现传出的参数不是自己想要的参数。可是为什么呢？\n\n​\t因为它是线程不安全的，当并发环境下，如果考虑不周使用SimpleDateFormat方法可以会出现线程安全方面的问题。原因当问我们使用parse方法时，使用CalendarBuilder日历创建者类创建日期，其中calendar实例因为cpu时间片切换时共享变量进行clear操作，导致数据不一致。\n\n具体原因：https://blog.csdn.net/lululove19870526/article/details/83684568\n\n# 三、解决方案\n\n​\t1、临时创建：对于每个转换都new一个实例，有背与我们代码简洁的初衷，放弃。\n\n​\t2、synchronized：阻塞，让线程不在并发，对效率影响很大，放弃。\n\n​\t3、ThreadLocal：线程隔离机制，代码量减少了，和1一样也牺牲了部分空间，还是个不错的解决方法。\n\n​\t\thttps://www.jianshu.com/p/3c5d7f09dfbd\n\n​\t4、Apache的 DateFormatUtils 与 FastDateFormat：线程安全，但是木有parse()方法\n\n​\t5、Joda-Time：感觉不错，就是源码有点多没敢用，github目前2.4K star。\n\n# 四、部分代码\n\n​\t用了ThreadLocal\n\n```java\n/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\n    public static final ThreadLocal<SimpleDateFormat> IN_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyyMMddHHmmssSSS\"));\n    public static final ThreadLocal<SimpleDateFormat> VIEW_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyy-MM-dd\"));\n    public static final ThreadLocal<SimpleDateFormat> OUT_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"));\n}\n```\n\n```java\n// 调用\nConstantUtils.IN_FORMAT.get().format(requestParams.getReleaseTime())\n```\n\n","source":"_posts/SimpleDateFormat引发的线程安全问题.md","raw":"title: SimpleDateFormat引发的线程安全问题\nauthor: 郑天祺\ntags:\n  - 并发\n  - 线程安全\ncategories:\n  - java基础\ndate: 2019-10-12 18:42:00\n\n---\n\n# \t一、问题产生\n\n​\t在写java程序时，有时间戳转换的操作。\n\n```java\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\n/**\n * @author zhengtianqi\n * @date 2019/10/12\n */\npublic class DateTrans {\n\n    public static void main(String[] args) {\n\n        // 将2019-10-12 18:50:30 改成 2019年10月12日\n        String inDate = \"2019-10-12 18:50:30\";\n\n        SimpleDateFormat inPut = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n        SimpleDateFormat outPut = new SimpleDateFormat(\"yyyy年MM月dd日\");\n\n        try {\n            Date temp = inPut.parse(inDate);\n            String outDate = outPut.format(temp);\n\n            System.out.println(outDate);\n\n        } catch (ParseException e) {\n            System.out.println(\"时间转换出错，出错信息为 ={}\" + e);\n        }\n\n    }\n}\n\n```\n\n\n\n涉及时间戳转换时，每次我们都new一个SimpleDateFormat对象，用起来很麻烦。\n\n我们就把它们放到了一个常量类里，随时用随时取。\n\n```java\n/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\tpublic static final SimpleDateFormat IN_FORMAT = new SimpleDateFormat(\"yyyyMMddHHmmssSSS\");\n\tpublic static final SimpleDateFormat OUT_FORMAT = new SimpleDateFormat(\"yyyy-MM-dd\");\n\tpublic static final SimpleDateFormat VIEW_FORMAT = new SimpleDateFormat(\"yyyy年MM月\");\n\tpublic static final SimpleDateFormat INNER_FORMAT = new SimpleDateFormat(\"yyyy-MM\");\n\tpublic static final SimpleDateFormat RECALL_FORMAT = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n}\n```\n\n可是你想省事，麻烦就随之而来了！\n\n先看看错误：\n\n```java\n[2019-10-12 17:45:35,468][locallog][ERROR][TID: N/A][../filters/GlobalExeption.exceptionHandler:18][10.7.5.22][] - 服务器内部错误!\njava.lang.NumberFormatException: For input string: \".220188E.4220188\"\n        at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[?:1.8.0_221]\n        at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[?:1.8.0_221]\n        at java.lang.Double.parseDouble(Double.java:538) ~[?:1.8.0_221]\n        at java.text.DigitList.getDouble(DigitList.java:169) ~[?:1.8.0_221]\n        at java.text.DecimalFormat.parse(DecimalFormat.java:2089) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) ~[?:1.8.0_221]\n        at java.text.DateFormat.parse(DateFormat.java:364) ~[?:1.8.0_221]\n```\n\n# 二、问题查找\n\ndebug发现传出的参数不是自己想要的参数。可是为什么呢？\n\n​\t因为它是线程不安全的，当并发环境下，如果考虑不周使用SimpleDateFormat方法可以会出现线程安全方面的问题。原因当问我们使用parse方法时，使用CalendarBuilder日历创建者类创建日期，其中calendar实例因为cpu时间片切换时共享变量进行clear操作，导致数据不一致。\n\n具体原因：https://blog.csdn.net/lululove19870526/article/details/83684568\n\n# 三、解决方案\n\n​\t1、临时创建：对于每个转换都new一个实例，有背与我们代码简洁的初衷，放弃。\n\n​\t2、synchronized：阻塞，让线程不在并发，对效率影响很大，放弃。\n\n​\t3、ThreadLocal：线程隔离机制，代码量减少了，和1一样也牺牲了部分空间，还是个不错的解决方法。\n\n​\t\thttps://www.jianshu.com/p/3c5d7f09dfbd\n\n​\t4、Apache的 DateFormatUtils 与 FastDateFormat：线程安全，但是木有parse()方法\n\n​\t5、Joda-Time：感觉不错，就是源码有点多没敢用，github目前2.4K star。\n\n# 四、部分代码\n\n​\t用了ThreadLocal\n\n```java\n/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\n    public static final ThreadLocal<SimpleDateFormat> IN_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyyMMddHHmmssSSS\"));\n    public static final ThreadLocal<SimpleDateFormat> VIEW_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyy-MM-dd\"));\n    public static final ThreadLocal<SimpleDateFormat> OUT_FORMAT = ThreadLocal.withInitial(() -> new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"));\n}\n```\n\n```java\n// 调用\nConstantUtils.IN_FORMAT.get().format(requestParams.getReleaseTime())\n```\n\n","slug":"SimpleDateFormat引发的线程安全问题","published":1,"updated":"2019-10-12T12:08:31.315Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0a0006vguq02p6g923","content":"<h1>一、问题产生</h1>\n<p>​\t在写java程序时，有时间戳转换的操作。</p>\n<pre><code class=\"language-java\">import java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\n/**\n * @author zhengtianqi\n * @date 2019/10/12\n */\npublic class DateTrans {\n\n    public static void main(String[] args) {\n\n        // 将2019-10-12 18:50:30 改成 2019年10月12日\n        String inDate = &quot;2019-10-12 18:50:30&quot;;\n\n        SimpleDateFormat inPut = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        SimpleDateFormat outPut = new SimpleDateFormat(&quot;yyyy年MM月dd日&quot;);\n\n        try {\n            Date temp = inPut.parse(inDate);\n            String outDate = outPut.format(temp);\n\n            System.out.println(outDate);\n\n        } catch (ParseException e) {\n            System.out.println(&quot;时间转换出错，出错信息为 ={}&quot; + e);\n        }\n\n    }\n}\n\n</code></pre>\n<p>涉及时间戳转换时，每次我们都new一个SimpleDateFormat对象，用起来很麻烦。</p>\n<p>我们就把它们放到了一个常量类里，随时用随时取。</p>\n<pre><code class=\"language-java\">/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\tpublic static final SimpleDateFormat IN_FORMAT = new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;);\n\tpublic static final SimpleDateFormat OUT_FORMAT = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);\n\tpublic static final SimpleDateFormat VIEW_FORMAT = new SimpleDateFormat(&quot;yyyy年MM月&quot;);\n\tpublic static final SimpleDateFormat INNER_FORMAT = new SimpleDateFormat(&quot;yyyy-MM&quot;);\n\tpublic static final SimpleDateFormat RECALL_FORMAT = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n}\n</code></pre>\n<p>可是你想省事，麻烦就随之而来了！</p>\n<p>先看看错误：</p>\n<pre><code class=\"language-java\">[2019-10-12 17:45:35,468][locallog][ERROR][TID: N/A][../filters/GlobalExeption.exceptionHandler:18][10.7.5.22][] - 服务器内部错误!\njava.lang.NumberFormatException: For input string: &quot;.220188E.4220188&quot;\n        at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[?:1.8.0_221]\n        at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[?:1.8.0_221]\n        at java.lang.Double.parseDouble(Double.java:538) ~[?:1.8.0_221]\n        at java.text.DigitList.getDouble(DigitList.java:169) ~[?:1.8.0_221]\n        at java.text.DecimalFormat.parse(DecimalFormat.java:2089) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) ~[?:1.8.0_221]\n        at java.text.DateFormat.parse(DateFormat.java:364) ~[?:1.8.0_221]\n</code></pre>\n<h1>二、问题查找</h1>\n<p>debug发现传出的参数不是自己想要的参数。可是为什么呢？</p>\n<p>​\t因为它是线程不安全的，当并发环境下，如果考虑不周使用SimpleDateFormat方法可以会出现线程安全方面的问题。原因当问我们使用parse方法时，使用CalendarBuilder日历创建者类创建日期，其中calendar实例因为cpu时间片切换时共享变量进行clear操作，导致数据不一致。</p>\n<p>具体原因：https://blog.csdn.net/lululove19870526/article/details/83684568</p>\n<h1>三、解决方案</h1>\n<p>​\t1、临时创建：对于每个转换都new一个实例，有背与我们代码简洁的初衷，放弃。</p>\n<p>​\t2、synchronized：阻塞，让线程不在并发，对效率影响很大，放弃。</p>\n<p>​\t3、ThreadLocal：线程隔离机制，代码量减少了，和1一样也牺牲了部分空间，还是个不错的解决方法。</p>\n<p>​\t\thttps://www.jianshu.com/p/3c5d7f09dfbd</p>\n<p>​\t4、Apache的 DateFormatUtils 与 FastDateFormat：线程安全，但是木有parse()方法</p>\n<p>​\t5、Joda-Time：感觉不错，就是源码有点多没敢用，github目前2.4K star。</p>\n<h1>四、部分代码</h1>\n<p>​\t用了ThreadLocal</p>\n<pre><code class=\"language-java\">/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; IN_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;));\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; VIEW_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyy-MM-dd&quot;));\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; OUT_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;));\n}\n</code></pre>\n<pre><code class=\"language-java\">// 调用\nConstantUtils.IN_FORMAT.get().format(requestParams.getReleaseTime())\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、问题产生</h1>\n<p>​\t在写java程序时，有时间戳转换的操作。</p>\n<pre><code class=\"language-java\">import java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Date;\n\n/**\n * @author zhengtianqi\n * @date 2019/10/12\n */\npublic class DateTrans {\n\n    public static void main(String[] args) {\n\n        // 将2019-10-12 18:50:30 改成 2019年10月12日\n        String inDate = &quot;2019-10-12 18:50:30&quot;;\n\n        SimpleDateFormat inPut = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n        SimpleDateFormat outPut = new SimpleDateFormat(&quot;yyyy年MM月dd日&quot;);\n\n        try {\n            Date temp = inPut.parse(inDate);\n            String outDate = outPut.format(temp);\n\n            System.out.println(outDate);\n\n        } catch (ParseException e) {\n            System.out.println(&quot;时间转换出错，出错信息为 ={}&quot; + e);\n        }\n\n    }\n}\n\n</code></pre>\n<p>涉及时间戳转换时，每次我们都new一个SimpleDateFormat对象，用起来很麻烦。</p>\n<p>我们就把它们放到了一个常量类里，随时用随时取。</p>\n<pre><code class=\"language-java\">/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\tpublic static final SimpleDateFormat IN_FORMAT = new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;);\n\tpublic static final SimpleDateFormat OUT_FORMAT = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;);\n\tpublic static final SimpleDateFormat VIEW_FORMAT = new SimpleDateFormat(&quot;yyyy年MM月&quot;);\n\tpublic static final SimpleDateFormat INNER_FORMAT = new SimpleDateFormat(&quot;yyyy-MM&quot;);\n\tpublic static final SimpleDateFormat RECALL_FORMAT = new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;);\n}\n</code></pre>\n<p>可是你想省事，麻烦就随之而来了！</p>\n<p>先看看错误：</p>\n<pre><code class=\"language-java\">[2019-10-12 17:45:35,468][locallog][ERROR][TID: N/A][../filters/GlobalExeption.exceptionHandler:18][10.7.5.22][] - 服务器内部错误!\njava.lang.NumberFormatException: For input string: &quot;.220188E.4220188&quot;\n        at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) ~[?:1.8.0_221]\n        at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) ~[?:1.8.0_221]\n        at java.lang.Double.parseDouble(Double.java:538) ~[?:1.8.0_221]\n        at java.text.DigitList.getDouble(DigitList.java:169) ~[?:1.8.0_221]\n        at java.text.DecimalFormat.parse(DecimalFormat.java:2089) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) ~[?:1.8.0_221]\n        at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) ~[?:1.8.0_221]\n        at java.text.DateFormat.parse(DateFormat.java:364) ~[?:1.8.0_221]\n</code></pre>\n<h1>二、问题查找</h1>\n<p>debug发现传出的参数不是自己想要的参数。可是为什么呢？</p>\n<p>​\t因为它是线程不安全的，当并发环境下，如果考虑不周使用SimpleDateFormat方法可以会出现线程安全方面的问题。原因当问我们使用parse方法时，使用CalendarBuilder日历创建者类创建日期，其中calendar实例因为cpu时间片切换时共享变量进行clear操作，导致数据不一致。</p>\n<p>具体原因：https://blog.csdn.net/lululove19870526/article/details/83684568</p>\n<h1>三、解决方案</h1>\n<p>​\t1、临时创建：对于每个转换都new一个实例，有背与我们代码简洁的初衷，放弃。</p>\n<p>​\t2、synchronized：阻塞，让线程不在并发，对效率影响很大，放弃。</p>\n<p>​\t3、ThreadLocal：线程隔离机制，代码量减少了，和1一样也牺牲了部分空间，还是个不错的解决方法。</p>\n<p>​\t\thttps://www.jianshu.com/p/3c5d7f09dfbd</p>\n<p>​\t4、Apache的 DateFormatUtils 与 FastDateFormat：线程安全，但是木有parse()方法</p>\n<p>​\t5、Joda-Time：感觉不错，就是源码有点多没敢用，github目前2.4K star。</p>\n<h1>四、部分代码</h1>\n<p>​\t用了ThreadLocal</p>\n<pre><code class=\"language-java\">/**\n * 枚举类 常量类\n *\n * @author zhengtianqi\n * @date 2019/8/16\n */\npublic enum ConstantUtils {\n    \n\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; IN_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyyMMddHHmmssSSS&quot;));\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; VIEW_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyy-MM-dd&quot;));\n    public static final ThreadLocal&lt;SimpleDateFormat&gt; OUT_FORMAT = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;));\n}\n</code></pre>\n<pre><code class=\"language-java\">// 调用\nConstantUtils.IN_FORMAT.get().format(requestParams.getReleaseTime())\n</code></pre>\n"},{"title":"Nacos配置中心使用","author":"郑天祺","date":"2019-11-25T08:38:00.000Z","_content":"\n# 一、启动Nacos Server\n\n1、启动方式可见 [Nacos 官网](https://nacos.io/zh-cn/docs/quick-start.html) \n\n2、在配置列表里配置自己的配置，按照规范填写各项。\n\n```java\nuser.name=zhengtianqi\nuser.password=123456\n```\n\n配置后的图：\n\n![image-20191125164448760](/img/nacos1.png)\n\n# 二、客户端编写\n\n1）常量类\n\n```java\npublic class Constants {\n    /**\n     * 配置中心url\n     */\n    public static final String URL_NACOS = \"127.0.0.1\";\n\n    public static final String NACOS_DATAID = \"test-nacos-config.yml\";\n    public static final String NACOS_Group = \"DEFAULT_GROUP\";\n}\n\n```\n\n2）客户端工具\n\n```java\nimport com.alibaba.nacos.api.NacosFactory;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Properties;\nimport java.util.concurrent.Executor;\n\npublic class NacosUtils {\n    private static ConfigService configService;\n\n    /**\n     * 读取配置超时时间，单位 ms\n     */\n    private static final int TIMEOUT = 1000 * 3;\n    /**\n     * 获取配置文件内容\n     */\n    private static String content = \"\";\n\n    static {\n        try {\n            Properties properties = new Properties();\n            properties.put(PropertyKeyConst.SERVER_ADDR, Constants.URL_NACOS);\n            configService = NacosFactory.createConfigService(properties);\n        } catch (NacosException e) {\n            LocalLog.error(\"连接配置中心失败!\", e);\n            System.exit(1);\n        }\n    }\n\n    /**\n     * 获取配置中心配置内容\n     *\n     * @param group  命名空间\n     * @param dataId 数据库\n     * @return Properties\n     */\n    public static Properties getConfig(String group, String dataId) {\n        Properties properties = null;\n        try {\n            String config = configService.getConfig(dataId, group, 3000);\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(config.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (Exception e) {\n            LocalLog.error(\"\", \"从配置中心获取配置失败，group={},dataId={}\", group, dataId, e);\n        }\n        if (null == properties) {\n            LocalLog.info(\"\", \"从配置中心获取配置失败，group={},dataId={}\", group, dataId);\n        }\n        return properties;\n    }\n\n    /**\n     * 动态读取nocas配置内容\n     *\n     * @param dataId 配置ID\n     * @param group  分组\n     * @return\n     */\n    public static Properties getConfigProperties(String dataId, String group) {\n        Properties properties = null;\n        try {\n            content = configService.getConfig(dataId, group, TIMEOUT);\n            configService.addListener(dataId, group, new Listener() {\n                @Override\n                public void receiveConfigInfo(String configInfo) {\n                    content = configInfo;\n                    LocalLog.info(\"修改后的配置ID是：[\" + dataId + \"]，配置分组是：[\" + group + \"]获取的配置信息是\" + content);\n                }\n\n                @Override\n                public Executor getExecutor() {\n                    return null;\n                }\n            });\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (NacosException e) {\n            LocalLog.error(\"Nacos读取配置超时或网络异常\", e);\n        } catch (IOException e) {\n            LocalLog.error(\"加载到properties对象出现IO异常\", e);\n        }\n        return properties;\n    }\n\n}\n\n```\n\n3）配置文件\n\n```java\nspring:\n  application:\n    name: nacos-config-example\n    group: sa\n    developer: zhengtianqi<郑天祺>\n  cloud:\n    nacos:\n      config:\n        server-addr: http://localhost:8848\n\nserver:\n  port: 8080\n```\n\n4）启动类\n\n```java\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\nimport com.sy.sa.nacos.common.utils.NacosUtils;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\n@SpringBootApplication\npublic class NacosConfigExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosConfigExampleApplication.class, args);\n        // 测试动态加载配置\n        Properties properties = NacosUtils.getConfigProperties(Constants.NACOS_DATAID, Constants.NACOS_Group);\n        System.out.println(properties.getProperty(\"user.name\") + \":\" + properties.getProperty(\"user.password\"));\n    }\n\n}\n```\n\n# 三、引入的依赖\n\n```java\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n        <java.version>1.8</java.version>\n\n        <spring-cloud-alibaba.version>2.1.1.RELEASE</spring-cloud-alibaba.version>\n        <spring-cloud-greenwich.version>0.9.0.RELEASE</spring-cloud-greenwich.version>\n    </properties>\n        \n    <dependencies>\n\t\t<!--nacos-->\n        <dependency>\n            <groupId>com.alibaba.nacos</groupId>\n            <artifactId>nacos-client</artifactId>\n            <version>1.1.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n    </dependencies>\n        \n<dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>${spring-cloud-greenwich.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>${spring-cloud-alibaba.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n    \n```\n\n\n\n# 四、效果\n\n```java\n2019-11-25 16:48:12.276  INFO 444 --- [-127.0.0.1_8848] locallog                                 : [../utils/NacosUtils$1.receiveConfigInfo:81][192.168.116.1][] - 修改后的配置ID是：[test-nacos-config.yml]，配置分组是：[DEFAULT_GROUP]获取的配置信息是user.name=zhengtianqi\nuser.password=12345678\n```\n\n解释：\n\n上述代码中没有用到SpringCloud，只用到了nacos的客户端。因为 如果使用SpringCloud读取多个配置文件（a.properties, b.properties），a中是user.name=123，b中是user.name=1234； 会有覆盖的情况\n\n```java\n  ConfigurableApplicationContext applicationContext = SpringApplication.run(ConfigApplication.class, args);\n        String userName = applicationContext.getEnvironment().getProperty(\"user.name\");\n        String userPassword = applicationContext.getEnvironment().getProperty(\"user.password\");\n```\n\n如果多人开发没有注意到这种情况，会引起配置文件的key冲突导致出现问题","source":"_posts/Nacos配置中心使用.md","raw":"title: Nacos配置中心使用\nauthor: 郑天祺\ntags:\n  - nacos-config\n  - SpringCloud\ncategories:\n  - SpringCloud\ndate: 2019-11-25 16:38:00\n---\n\n# 一、启动Nacos Server\n\n1、启动方式可见 [Nacos 官网](https://nacos.io/zh-cn/docs/quick-start.html) \n\n2、在配置列表里配置自己的配置，按照规范填写各项。\n\n```java\nuser.name=zhengtianqi\nuser.password=123456\n```\n\n配置后的图：\n\n![image-20191125164448760](/img/nacos1.png)\n\n# 二、客户端编写\n\n1）常量类\n\n```java\npublic class Constants {\n    /**\n     * 配置中心url\n     */\n    public static final String URL_NACOS = \"127.0.0.1\";\n\n    public static final String NACOS_DATAID = \"test-nacos-config.yml\";\n    public static final String NACOS_Group = \"DEFAULT_GROUP\";\n}\n\n```\n\n2）客户端工具\n\n```java\nimport com.alibaba.nacos.api.NacosFactory;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Properties;\nimport java.util.concurrent.Executor;\n\npublic class NacosUtils {\n    private static ConfigService configService;\n\n    /**\n     * 读取配置超时时间，单位 ms\n     */\n    private static final int TIMEOUT = 1000 * 3;\n    /**\n     * 获取配置文件内容\n     */\n    private static String content = \"\";\n\n    static {\n        try {\n            Properties properties = new Properties();\n            properties.put(PropertyKeyConst.SERVER_ADDR, Constants.URL_NACOS);\n            configService = NacosFactory.createConfigService(properties);\n        } catch (NacosException e) {\n            LocalLog.error(\"连接配置中心失败!\", e);\n            System.exit(1);\n        }\n    }\n\n    /**\n     * 获取配置中心配置内容\n     *\n     * @param group  命名空间\n     * @param dataId 数据库\n     * @return Properties\n     */\n    public static Properties getConfig(String group, String dataId) {\n        Properties properties = null;\n        try {\n            String config = configService.getConfig(dataId, group, 3000);\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(config.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (Exception e) {\n            LocalLog.error(\"\", \"从配置中心获取配置失败，group={},dataId={}\", group, dataId, e);\n        }\n        if (null == properties) {\n            LocalLog.info(\"\", \"从配置中心获取配置失败，group={},dataId={}\", group, dataId);\n        }\n        return properties;\n    }\n\n    /**\n     * 动态读取nocas配置内容\n     *\n     * @param dataId 配置ID\n     * @param group  分组\n     * @return\n     */\n    public static Properties getConfigProperties(String dataId, String group) {\n        Properties properties = null;\n        try {\n            content = configService.getConfig(dataId, group, TIMEOUT);\n            configService.addListener(dataId, group, new Listener() {\n                @Override\n                public void receiveConfigInfo(String configInfo) {\n                    content = configInfo;\n                    LocalLog.info(\"修改后的配置ID是：[\" + dataId + \"]，配置分组是：[\" + group + \"]获取的配置信息是\" + content);\n                }\n\n                @Override\n                public Executor getExecutor() {\n                    return null;\n                }\n            });\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (NacosException e) {\n            LocalLog.error(\"Nacos读取配置超时或网络异常\", e);\n        } catch (IOException e) {\n            LocalLog.error(\"加载到properties对象出现IO异常\", e);\n        }\n        return properties;\n    }\n\n}\n\n```\n\n3）配置文件\n\n```java\nspring:\n  application:\n    name: nacos-config-example\n    group: sa\n    developer: zhengtianqi<郑天祺>\n  cloud:\n    nacos:\n      config:\n        server-addr: http://localhost:8848\n\nserver:\n  port: 8080\n```\n\n4）启动类\n\n```java\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\nimport com.sy.sa.nacos.common.utils.NacosUtils;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\n@SpringBootApplication\npublic class NacosConfigExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosConfigExampleApplication.class, args);\n        // 测试动态加载配置\n        Properties properties = NacosUtils.getConfigProperties(Constants.NACOS_DATAID, Constants.NACOS_Group);\n        System.out.println(properties.getProperty(\"user.name\") + \":\" + properties.getProperty(\"user.password\"));\n    }\n\n}\n```\n\n# 三、引入的依赖\n\n```java\n    <properties>\n        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n        <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n        <java.version>1.8</java.version>\n\n        <spring-cloud-alibaba.version>2.1.1.RELEASE</spring-cloud-alibaba.version>\n        <spring-cloud-greenwich.version>0.9.0.RELEASE</spring-cloud-greenwich.version>\n    </properties>\n        \n    <dependencies>\n\t\t<!--nacos-->\n        <dependency>\n            <groupId>com.alibaba.nacos</groupId>\n            <artifactId>nacos-client</artifactId>\n            <version>1.1.0</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n    </dependencies>\n        \n<dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>${spring-cloud-greenwich.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n\n            <dependency>\n                <groupId>com.alibaba.cloud</groupId>\n                <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n                <version>${spring-cloud-alibaba.version}</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n    \n```\n\n\n\n# 四、效果\n\n```java\n2019-11-25 16:48:12.276  INFO 444 --- [-127.0.0.1_8848] locallog                                 : [../utils/NacosUtils$1.receiveConfigInfo:81][192.168.116.1][] - 修改后的配置ID是：[test-nacos-config.yml]，配置分组是：[DEFAULT_GROUP]获取的配置信息是user.name=zhengtianqi\nuser.password=12345678\n```\n\n解释：\n\n上述代码中没有用到SpringCloud，只用到了nacos的客户端。因为 如果使用SpringCloud读取多个配置文件（a.properties, b.properties），a中是user.name=123，b中是user.name=1234； 会有覆盖的情况\n\n```java\n  ConfigurableApplicationContext applicationContext = SpringApplication.run(ConfigApplication.class, args);\n        String userName = applicationContext.getEnvironment().getProperty(\"user.name\");\n        String userPassword = applicationContext.getEnvironment().getProperty(\"user.password\");\n```\n\n如果多人开发没有注意到这种情况，会引起配置文件的key冲突导致出现问题","slug":"Nacos配置中心使用","published":1,"updated":"2019-11-26T03:57:24.175Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0d000avguqti2evtso","content":"<h1>一、启动Nacos Server</h1>\n<p>1、启动方式可见 <a href=\"https://nacos.io/zh-cn/docs/quick-start.html\" target=\"_blank\" rel=\"noopener\">Nacos 官网</a></p>\n<p>2、在配置列表里配置自己的配置，按照规范填写各项。</p>\n<pre><code class=\"language-java\">user.name=zhengtianqi\nuser.password=123456\n</code></pre>\n<p>配置后的图：</p>\n<p><img src=\"/img/nacos1.png\" alt=\"image-20191125164448760\"></p>\n<h1>二、客户端编写</h1>\n<p>1）常量类</p>\n<pre><code class=\"language-java\">public class Constants {\n    /**\n     * 配置中心url\n     */\n    public static final String URL_NACOS = &quot;127.0.0.1&quot;;\n\n    public static final String NACOS_DATAID = &quot;test-nacos-config.yml&quot;;\n    public static final String NACOS_Group = &quot;DEFAULT_GROUP&quot;;\n}\n\n</code></pre>\n<p>2）客户端工具</p>\n<pre><code class=\"language-java\">import com.alibaba.nacos.api.NacosFactory;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Properties;\nimport java.util.concurrent.Executor;\n\npublic class NacosUtils {\n    private static ConfigService configService;\n\n    /**\n     * 读取配置超时时间，单位 ms\n     */\n    private static final int TIMEOUT = 1000 * 3;\n    /**\n     * 获取配置文件内容\n     */\n    private static String content = &quot;&quot;;\n\n    static {\n        try {\n            Properties properties = new Properties();\n            properties.put(PropertyKeyConst.SERVER_ADDR, Constants.URL_NACOS);\n            configService = NacosFactory.createConfigService(properties);\n        } catch (NacosException e) {\n            LocalLog.error(&quot;连接配置中心失败!&quot;, e);\n            System.exit(1);\n        }\n    }\n\n    /**\n     * 获取配置中心配置内容\n     *\n     * @param group  命名空间\n     * @param dataId 数据库\n     * @return Properties\n     */\n    public static Properties getConfig(String group, String dataId) {\n        Properties properties = null;\n        try {\n            String config = configService.getConfig(dataId, group, 3000);\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(config.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (Exception e) {\n            LocalLog.error(&quot;&quot;, &quot;从配置中心获取配置失败，group={},dataId={}&quot;, group, dataId, e);\n        }\n        if (null == properties) {\n            LocalLog.info(&quot;&quot;, &quot;从配置中心获取配置失败，group={},dataId={}&quot;, group, dataId);\n        }\n        return properties;\n    }\n\n    /**\n     * 动态读取nocas配置内容\n     *\n     * @param dataId 配置ID\n     * @param group  分组\n     * @return\n     */\n    public static Properties getConfigProperties(String dataId, String group) {\n        Properties properties = null;\n        try {\n            content = configService.getConfig(dataId, group, TIMEOUT);\n            configService.addListener(dataId, group, new Listener() {\n                @Override\n                public void receiveConfigInfo(String configInfo) {\n                    content = configInfo;\n                    LocalLog.info(&quot;修改后的配置ID是：[&quot; + dataId + &quot;]，配置分组是：[&quot; + group + &quot;]获取的配置信息是&quot; + content);\n                }\n\n                @Override\n                public Executor getExecutor() {\n                    return null;\n                }\n            });\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (NacosException e) {\n            LocalLog.error(&quot;Nacos读取配置超时或网络异常&quot;, e);\n        } catch (IOException e) {\n            LocalLog.error(&quot;加载到properties对象出现IO异常&quot;, e);\n        }\n        return properties;\n    }\n\n}\n\n</code></pre>\n<p>3）配置文件</p>\n<pre><code class=\"language-java\">spring:\n  application:\n    name: nacos-config-example\n    group: sa\n    developer: zhengtianqi&lt;郑天祺&gt;\n  cloud:\n    nacos:\n      config:\n        server-addr: http://localhost:8848\n\nserver:\n  port: 8080\n</code></pre>\n<p>4）启动类</p>\n<pre><code class=\"language-java\">import com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\nimport com.sy.sa.nacos.common.utils.NacosUtils;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\n@SpringBootApplication\npublic class NacosConfigExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosConfigExampleApplication.class, args);\n        // 测试动态加载配置\n        Properties properties = NacosUtils.getConfigProperties(Constants.NACOS_DATAID, Constants.NACOS_Group);\n        System.out.println(properties.getProperty(&quot;user.name&quot;) + &quot;:&quot; + properties.getProperty(&quot;user.password&quot;));\n    }\n\n}\n</code></pre>\n<h1>三、引入的依赖</h1>\n<pre><code class=\"language-java\">    &lt;properties&gt;\n        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;\n        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;\n        &lt;java.version&gt;1.8&lt;/java.version&gt;\n\n        &lt;spring-cloud-alibaba.version&gt;2.1.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;\n        &lt;spring-cloud-greenwich.version&gt;0.9.0.RELEASE&lt;/spring-cloud-greenwich.version&gt;\n    &lt;/properties&gt;\n        \n    &lt;dependencies&gt;\n\t\t&lt;!--nacos--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt;\n            &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;\n            &lt;version&gt;1.1.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n        \n&lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-greenwich.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n\n            &lt;dependency&gt;\n                &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n    \n</code></pre>\n<h1>四、效果</h1>\n<pre><code class=\"language-java\">2019-11-25 16:48:12.276  INFO 444 --- [-127.0.0.1_8848] locallog                                 : [../utils/NacosUtils$1.receiveConfigInfo:81][192.168.116.1][] - 修改后的配置ID是：[test-nacos-config.yml]，配置分组是：[DEFAULT_GROUP]获取的配置信息是user.name=zhengtianqi\nuser.password=12345678\n</code></pre>\n<p>解释：</p>\n<p>上述代码中没有用到SpringCloud，只用到了nacos的客户端。因为 如果使用SpringCloud读取多个配置文件（a.properties, b.properties），a中是user.name=123，b中是user.name=1234； 会有覆盖的情况</p>\n<pre><code class=\"language-java\">  ConfigurableApplicationContext applicationContext = SpringApplication.run(ConfigApplication.class, args);\n        String userName = applicationContext.getEnvironment().getProperty(&quot;user.name&quot;);\n        String userPassword = applicationContext.getEnvironment().getProperty(&quot;user.password&quot;);\n</code></pre>\n<p>如果多人开发没有注意到这种情况，会引起配置文件的key冲突导致出现问题</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、启动Nacos Server</h1>\n<p>1、启动方式可见 <a href=\"https://nacos.io/zh-cn/docs/quick-start.html\" target=\"_blank\" rel=\"noopener\">Nacos 官网</a></p>\n<p>2、在配置列表里配置自己的配置，按照规范填写各项。</p>\n<pre><code class=\"language-java\">user.name=zhengtianqi\nuser.password=123456\n</code></pre>\n<p>配置后的图：</p>\n<p><img src=\"/img/nacos1.png\" alt=\"image-20191125164448760\"></p>\n<h1>二、客户端编写</h1>\n<p>1）常量类</p>\n<pre><code class=\"language-java\">public class Constants {\n    /**\n     * 配置中心url\n     */\n    public static final String URL_NACOS = &quot;127.0.0.1&quot;;\n\n    public static final String NACOS_DATAID = &quot;test-nacos-config.yml&quot;;\n    public static final String NACOS_Group = &quot;DEFAULT_GROUP&quot;;\n}\n\n</code></pre>\n<p>2）客户端工具</p>\n<pre><code class=\"language-java\">import com.alibaba.nacos.api.NacosFactory;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\n\nimport java.io.ByteArrayInputStream;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.util.Properties;\nimport java.util.concurrent.Executor;\n\npublic class NacosUtils {\n    private static ConfigService configService;\n\n    /**\n     * 读取配置超时时间，单位 ms\n     */\n    private static final int TIMEOUT = 1000 * 3;\n    /**\n     * 获取配置文件内容\n     */\n    private static String content = &quot;&quot;;\n\n    static {\n        try {\n            Properties properties = new Properties();\n            properties.put(PropertyKeyConst.SERVER_ADDR, Constants.URL_NACOS);\n            configService = NacosFactory.createConfigService(properties);\n        } catch (NacosException e) {\n            LocalLog.error(&quot;连接配置中心失败!&quot;, e);\n            System.exit(1);\n        }\n    }\n\n    /**\n     * 获取配置中心配置内容\n     *\n     * @param group  命名空间\n     * @param dataId 数据库\n     * @return Properties\n     */\n    public static Properties getConfig(String group, String dataId) {\n        Properties properties = null;\n        try {\n            String config = configService.getConfig(dataId, group, 3000);\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(config.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (Exception e) {\n            LocalLog.error(&quot;&quot;, &quot;从配置中心获取配置失败，group={},dataId={}&quot;, group, dataId, e);\n        }\n        if (null == properties) {\n            LocalLog.info(&quot;&quot;, &quot;从配置中心获取配置失败，group={},dataId={}&quot;, group, dataId);\n        }\n        return properties;\n    }\n\n    /**\n     * 动态读取nocas配置内容\n     *\n     * @param dataId 配置ID\n     * @param group  分组\n     * @return\n     */\n    public static Properties getConfigProperties(String dataId, String group) {\n        Properties properties = null;\n        try {\n            content = configService.getConfig(dataId, group, TIMEOUT);\n            configService.addListener(dataId, group, new Listener() {\n                @Override\n                public void receiveConfigInfo(String configInfo) {\n                    content = configInfo;\n                    LocalLog.info(&quot;修改后的配置ID是：[&quot; + dataId + &quot;]，配置分组是：[&quot; + group + &quot;]获取的配置信息是&quot; + content);\n                }\n\n                @Override\n                public Executor getExecutor() {\n                    return null;\n                }\n            });\n            ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8));\n            properties = new Properties();\n            properties.load(byteArrayInputStream);\n        } catch (NacosException e) {\n            LocalLog.error(&quot;Nacos读取配置超时或网络异常&quot;, e);\n        } catch (IOException e) {\n            LocalLog.error(&quot;加载到properties对象出现IO异常&quot;, e);\n        }\n        return properties;\n    }\n\n}\n\n</code></pre>\n<p>3）配置文件</p>\n<pre><code class=\"language-java\">spring:\n  application:\n    name: nacos-config-example\n    group: sa\n    developer: zhengtianqi&lt;郑天祺&gt;\n  cloud:\n    nacos:\n      config:\n        server-addr: http://localhost:8848\n\nserver:\n  port: 8080\n</code></pre>\n<p>4）启动类</p>\n<pre><code class=\"language-java\">import com.sy.log.LocalLog;\nimport com.sy.sa.nacos.common.constant.Constants;\nimport com.sy.sa.nacos.common.utils.NacosUtils;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\nimport java.util.Properties;\nimport java.util.concurrent.TimeUnit;\n\n@SpringBootApplication\npublic class NacosConfigExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosConfigExampleApplication.class, args);\n        // 测试动态加载配置\n        Properties properties = NacosUtils.getConfigProperties(Constants.NACOS_DATAID, Constants.NACOS_Group);\n        System.out.println(properties.getProperty(&quot;user.name&quot;) + &quot;:&quot; + properties.getProperty(&quot;user.password&quot;));\n    }\n\n}\n</code></pre>\n<h1>三、引入的依赖</h1>\n<pre><code class=\"language-java\">    &lt;properties&gt;\n        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;\n        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;\n        &lt;java.version&gt;1.8&lt;/java.version&gt;\n\n        &lt;spring-cloud-alibaba.version&gt;2.1.1.RELEASE&lt;/spring-cloud-alibaba.version&gt;\n        &lt;spring-cloud-greenwich.version&gt;0.9.0.RELEASE&lt;/spring-cloud-greenwich.version&gt;\n    &lt;/properties&gt;\n        \n    &lt;dependencies&gt;\n\t\t&lt;!--nacos--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.nacos&lt;/groupId&gt;\n            &lt;artifactId&gt;nacos-client&lt;/artifactId&gt;\n            &lt;version&gt;1.1.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n        \n&lt;dependencyManagement&gt;\n        &lt;dependencies&gt;\n            &lt;dependency&gt;\n                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-greenwich.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n\n            &lt;dependency&gt;\n                &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;\n                &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;\n                &lt;version&gt;${spring-cloud-alibaba.version}&lt;/version&gt;\n                &lt;type&gt;pom&lt;/type&gt;\n                &lt;scope&gt;import&lt;/scope&gt;\n            &lt;/dependency&gt;\n        &lt;/dependencies&gt;\n    &lt;/dependencyManagement&gt;\n    \n</code></pre>\n<h1>四、效果</h1>\n<pre><code class=\"language-java\">2019-11-25 16:48:12.276  INFO 444 --- [-127.0.0.1_8848] locallog                                 : [../utils/NacosUtils$1.receiveConfigInfo:81][192.168.116.1][] - 修改后的配置ID是：[test-nacos-config.yml]，配置分组是：[DEFAULT_GROUP]获取的配置信息是user.name=zhengtianqi\nuser.password=12345678\n</code></pre>\n<p>解释：</p>\n<p>上述代码中没有用到SpringCloud，只用到了nacos的客户端。因为 如果使用SpringCloud读取多个配置文件（a.properties, b.properties），a中是user.name=123，b中是user.name=1234； 会有覆盖的情况</p>\n<pre><code class=\"language-java\">  ConfigurableApplicationContext applicationContext = SpringApplication.run(ConfigApplication.class, args);\n        String userName = applicationContext.getEnvironment().getProperty(&quot;user.name&quot;);\n        String userPassword = applicationContext.getEnvironment().getProperty(&quot;user.password&quot;);\n</code></pre>\n<p>如果多人开发没有注意到这种情况，会引起配置文件的key冲突导致出现问题</p>\n"},{"title":"Spark相关概述","author":"郑天祺","date":"2019-12-18T05:41:00.000Z","_content":"\n# 一、Spark的核心组件是：\n\n​\t\t\t\t集群资源管理服务（Cluster Manager）\t\t\n\n​\t\t\t\t运行作业任务的节点（WorkerNode），\n\n​\t\t\t\t每个应用的任务控制节点 Driver 和 每个机器节点上有具有任务的执行进程（Executor）\n\n![image-20191218134210879](/img/Spark.png)\n\n说明：\n\n![image-20191218140600902](/img/spark-all.png)\n\n# 二、关键概念\n\n（1）RDD\n\n​\t\tSpark 的核心概念是弹性分布式数据集。RDD 是一个只读且不可变的分布式对象集合，创建、转化即调用 RDD 操作者一系列过程贯穿于 Spark 大数据处理的始终。\n\n（2）DAG\n\n​\t\tSpark使用有向无环图进行任务调度。\n\n（3）Spark SQL\n\n​\t\t用于结构化数据的计算。\n\n（4）DataFrame\n\n​\t\t分布式的、按照名名列的形式组织的数据集合。\n\n（5）SQLContext\n\n​\t\tSpark SQL 提供 SQLContext 封装 Spark 中的所有关系型功能，可以用前面提到的SparkContext创建SQLContext。\n\n（6）JDBC数据源\n\n三、Spark 和 HDFS 的配合关系\n\n​\t\t![image-20191218141731121](/img/spark+hdfs.png)\n\n- （1）读取文件的详细步骤：\n- SparkScheduler 与 HDFS 交互获取 File A 的文件信息。\n- HDFS返回该文件具体的 Block 信息\n- SparkScheduler 根据具体的 Block 数据量，决定一个并行度，创建多个 Task 去读取这些文件Block\n- Executor 端执行 Task 并读取具体的 Block，作为 RDD（弹性分部数据集）的一部分\n- （2）HDFS文件写入的详细步骤：\n- SparkScheduler 创建要写入文件的目录\n- 根据 RDD 分区分块情况，计算写出数据的 Task 数，并下发这些任务到 Executor\n- Executor 执行这些 Task，将具体 RDD 的数据写入到第一步创建的目录下","source":"_posts/Spark相关概述.md","raw":"title: Spark相关概述\nauthor: 郑天祺\ntags:\n\n  - Spark\ncategories:\n  - 大数据\ndate: 2019-12-18 13:41:00\n\n---\n\n# 一、Spark的核心组件是：\n\n​\t\t\t\t集群资源管理服务（Cluster Manager）\t\t\n\n​\t\t\t\t运行作业任务的节点（WorkerNode），\n\n​\t\t\t\t每个应用的任务控制节点 Driver 和 每个机器节点上有具有任务的执行进程（Executor）\n\n![image-20191218134210879](/img/Spark.png)\n\n说明：\n\n![image-20191218140600902](/img/spark-all.png)\n\n# 二、关键概念\n\n（1）RDD\n\n​\t\tSpark 的核心概念是弹性分布式数据集。RDD 是一个只读且不可变的分布式对象集合，创建、转化即调用 RDD 操作者一系列过程贯穿于 Spark 大数据处理的始终。\n\n（2）DAG\n\n​\t\tSpark使用有向无环图进行任务调度。\n\n（3）Spark SQL\n\n​\t\t用于结构化数据的计算。\n\n（4）DataFrame\n\n​\t\t分布式的、按照名名列的形式组织的数据集合。\n\n（5）SQLContext\n\n​\t\tSpark SQL 提供 SQLContext 封装 Spark 中的所有关系型功能，可以用前面提到的SparkContext创建SQLContext。\n\n（6）JDBC数据源\n\n三、Spark 和 HDFS 的配合关系\n\n​\t\t![image-20191218141731121](/img/spark+hdfs.png)\n\n- （1）读取文件的详细步骤：\n- SparkScheduler 与 HDFS 交互获取 File A 的文件信息。\n- HDFS返回该文件具体的 Block 信息\n- SparkScheduler 根据具体的 Block 数据量，决定一个并行度，创建多个 Task 去读取这些文件Block\n- Executor 端执行 Task 并读取具体的 Block，作为 RDD（弹性分部数据集）的一部分\n- （2）HDFS文件写入的详细步骤：\n- SparkScheduler 创建要写入文件的目录\n- 根据 RDD 分区分块情况，计算写出数据的 Task 数，并下发这些任务到 Executor\n- Executor 执行这些 Task，将具体 RDD 的数据写入到第一步创建的目录下","slug":"Spark相关概述","published":1,"updated":"2019-12-18T09:12:52.500Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0f000bvguqxfx25e7w","content":"<h1>一、Spark的核心组件是：</h1>\n<p>​\t\t\t\t集群资源管理服务（Cluster Manager）</p>\n<p>​\t\t\t\t运行作业任务的节点（WorkerNode），</p>\n<p>​\t\t\t\t每个应用的任务控制节点 Driver 和 每个机器节点上有具有任务的执行进程（Executor）</p>\n<p><img src=\"/img/Spark.png\" alt=\"image-20191218134210879\"></p>\n<p>说明：</p>\n<p><img src=\"/img/spark-all.png\" alt=\"image-20191218140600902\"></p>\n<h1>二、关键概念</h1>\n<p>（1）RDD</p>\n<p>​\t\tSpark 的核心概念是弹性分布式数据集。RDD 是一个只读且不可变的分布式对象集合，创建、转化即调用 RDD 操作者一系列过程贯穿于 Spark 大数据处理的始终。</p>\n<p>（2）DAG</p>\n<p>​\t\tSpark使用有向无环图进行任务调度。</p>\n<p>（3）Spark SQL</p>\n<p>​\t\t用于结构化数据的计算。</p>\n<p>（4）DataFrame</p>\n<p>​\t\t分布式的、按照名名列的形式组织的数据集合。</p>\n<p>（5）SQLContext</p>\n<p>​\t\tSpark SQL 提供 SQLContext 封装 Spark 中的所有关系型功能，可以用前面提到的SparkContext创建SQLContext。</p>\n<p>（6）JDBC数据源</p>\n<p>三、Spark 和 HDFS 的配合关系</p>\n<p>​\t\t<img src=\"/img/spark+hdfs.png\" alt=\"image-20191218141731121\"></p>\n<ul>\n<li>（1）读取文件的详细步骤：</li>\n<li>SparkScheduler 与 HDFS 交互获取 File A 的文件信息。</li>\n<li>HDFS返回该文件具体的 Block 信息</li>\n<li>SparkScheduler 根据具体的 Block 数据量，决定一个并行度，创建多个 Task 去读取这些文件Block</li>\n<li>Executor 端执行 Task 并读取具体的 Block，作为 RDD（弹性分部数据集）的一部分</li>\n<li>（2）HDFS文件写入的详细步骤：</li>\n<li>SparkScheduler 创建要写入文件的目录</li>\n<li>根据 RDD 分区分块情况，计算写出数据的 Task 数，并下发这些任务到 Executor</li>\n<li>Executor 执行这些 Task，将具体 RDD 的数据写入到第一步创建的目录下</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、Spark的核心组件是：</h1>\n<p>​\t\t\t\t集群资源管理服务（Cluster Manager）</p>\n<p>​\t\t\t\t运行作业任务的节点（WorkerNode），</p>\n<p>​\t\t\t\t每个应用的任务控制节点 Driver 和 每个机器节点上有具有任务的执行进程（Executor）</p>\n<p><img src=\"/img/Spark.png\" alt=\"image-20191218134210879\"></p>\n<p>说明：</p>\n<p><img src=\"/img/spark-all.png\" alt=\"image-20191218140600902\"></p>\n<h1>二、关键概念</h1>\n<p>（1）RDD</p>\n<p>​\t\tSpark 的核心概念是弹性分布式数据集。RDD 是一个只读且不可变的分布式对象集合，创建、转化即调用 RDD 操作者一系列过程贯穿于 Spark 大数据处理的始终。</p>\n<p>（2）DAG</p>\n<p>​\t\tSpark使用有向无环图进行任务调度。</p>\n<p>（3）Spark SQL</p>\n<p>​\t\t用于结构化数据的计算。</p>\n<p>（4）DataFrame</p>\n<p>​\t\t分布式的、按照名名列的形式组织的数据集合。</p>\n<p>（5）SQLContext</p>\n<p>​\t\tSpark SQL 提供 SQLContext 封装 Spark 中的所有关系型功能，可以用前面提到的SparkContext创建SQLContext。</p>\n<p>（6）JDBC数据源</p>\n<p>三、Spark 和 HDFS 的配合关系</p>\n<p>​\t\t<img src=\"/img/spark+hdfs.png\" alt=\"image-20191218141731121\"></p>\n<ul>\n<li>（1）读取文件的详细步骤：</li>\n<li>SparkScheduler 与 HDFS 交互获取 File A 的文件信息。</li>\n<li>HDFS返回该文件具体的 Block 信息</li>\n<li>SparkScheduler 根据具体的 Block 数据量，决定一个并行度，创建多个 Task 去读取这些文件Block</li>\n<li>Executor 端执行 Task 并读取具体的 Block，作为 RDD（弹性分部数据集）的一部分</li>\n<li>（2）HDFS文件写入的详细步骤：</li>\n<li>SparkScheduler 创建要写入文件的目录</li>\n<li>根据 RDD 分区分块情况，计算写出数据的 Task 数，并下发这些任务到 Executor</li>\n<li>Executor 执行这些 Task，将具体 RDD 的数据写入到第一步创建的目录下</li>\n</ul>\n"},{"title":"Spring Bean作用域与生命周期","author":"郑天祺","date":"2019-11-14T08:52:00.000Z","_content":"\n# 一、Spring Bean生命周期\n\n![img](/img/clip_image002.png)\n\n解释：\n\n- Spring 通过我们的配置，如 @ComponentScan 定义的扫描路径去找到带有 @Component     的类，这个过程就是一个资源定位的过程。\n- 一旦找到了资源，那么它就开始解析，并且将定义的信息保存起来。注意，此时还没有初始化 Bean ，也就没有 Bean 实例，它有的仅仅是 Bean 的定义。\n- 然后就会把 Bean 定义发布到 Spring IoC 容器中，此时，IoC容器也只有 Bean 的定义，还是没有 Bean 的实例生成。\n\n  在默认的情况下，Spring会继续去完成Bean的实例化和依赖注入， 这样从IoC容器中就可以得到一个依赖注入完成的Bean。但是，有些Bean会在取的时候才初始化和依赖注入。如下图：\n\n ![img](/img/clip_image004.png)\n\n解释：\n\n- 其中流程节点针对于单个Bean，BeanPostProcessor是针对所有Bean而言。\n- 即使你定义了ApplicationContextAware接口，但是有时候并不会调用，这要根据你的IoC容器来决定。\n- Spring IoC     容器的最低要求是实现 BeanFactory 接口，而不是实现 ApplicationContext 接口。对于那些没有实现     ApplicationContext 接口的容器，对生命周期对应的 ApplicationContextAware     定义的方法也是不会被调用的，只有实现了 ApplicationContext 接口的容器，才会在生命周期调用 ApplicationContextAware 所定义的     setApplicationContext 方法。\n\n\n\n# 二、Spring Bean作用域\n\n## 1、使用@Profile\n\n#### 1）假设存在dev_spring_boot 和 test_spring_boot两个数据库，使用注解@Profile定义两个Bean\n\n​    ![img](/img/SpringBean3.png)\n\n#### 2）在 Java 启动项目中，我们只需要如下配置就能启动Profile机制：\n\n​\t-Dspring.profiles.active=dev\n\n​\t注：Spring 会先判定是否存在 spring.profiles.active 配置后，再去查找 spring.profiles.default 配置的，所以 spring.profiles.active 的优先级要大于 spring.profiles.default\n\n#### 3）按照 springboot 的规则\n\n​\t-Dspring.profiles.active 配置的值记为 {profile} ，则它会用 application-{profiles}.properties 文件去代替原来默认的 application.properties文件\n\n## 2、使用 Spring EL\n\n####   1）读取属性文件的值，如：\n\n```java\n// ${......} 代表占位符\n@Value(\"${database.driverName}\")   \nString driver\n```\n\n \n\n####   2）记录一个Bean初始化事件，如：\n\n```java\n// #{......} 代表启用 Spring表达式，它将具有运算功能；T(......)代表的是引入类\n@Value(\"#{T(System).currentTimeMillis()}\")  \nprivate Long initTime = null;\n//直接赋值： 赋值字符串\n@Value(\"#{‘使用 Spring EL 赋值字符串’}\")\nprivate String str = null;\n// 科学计数法赋值\n@Value(\"#{9.3E3}\")\nprivate double d;\n// 其他Spring Bean属性赋值当前的Bean\n@Value(\"#{beanName.str}\")\nprivate String otherBeanProp = null;\n```\n\n还可以进行计算、三元运算、比较等。\n\n \n\n ","source":"_posts/Spring-Bean生命周期.md","raw":"title: Spring Bean作用域与生命周期\nauthor: 郑天祺\ntags:\n\n  - spring\ncategories:\n  - java基础\ndate: 2019-11-14 16:52:00\n\n---\n\n# 一、Spring Bean生命周期\n\n![img](/img/clip_image002.png)\n\n解释：\n\n- Spring 通过我们的配置，如 @ComponentScan 定义的扫描路径去找到带有 @Component     的类，这个过程就是一个资源定位的过程。\n- 一旦找到了资源，那么它就开始解析，并且将定义的信息保存起来。注意，此时还没有初始化 Bean ，也就没有 Bean 实例，它有的仅仅是 Bean 的定义。\n- 然后就会把 Bean 定义发布到 Spring IoC 容器中，此时，IoC容器也只有 Bean 的定义，还是没有 Bean 的实例生成。\n\n  在默认的情况下，Spring会继续去完成Bean的实例化和依赖注入， 这样从IoC容器中就可以得到一个依赖注入完成的Bean。但是，有些Bean会在取的时候才初始化和依赖注入。如下图：\n\n ![img](/img/clip_image004.png)\n\n解释：\n\n- 其中流程节点针对于单个Bean，BeanPostProcessor是针对所有Bean而言。\n- 即使你定义了ApplicationContextAware接口，但是有时候并不会调用，这要根据你的IoC容器来决定。\n- Spring IoC     容器的最低要求是实现 BeanFactory 接口，而不是实现 ApplicationContext 接口。对于那些没有实现     ApplicationContext 接口的容器，对生命周期对应的 ApplicationContextAware     定义的方法也是不会被调用的，只有实现了 ApplicationContext 接口的容器，才会在生命周期调用 ApplicationContextAware 所定义的     setApplicationContext 方法。\n\n\n\n# 二、Spring Bean作用域\n\n## 1、使用@Profile\n\n#### 1）假设存在dev_spring_boot 和 test_spring_boot两个数据库，使用注解@Profile定义两个Bean\n\n​    ![img](/img/SpringBean3.png)\n\n#### 2）在 Java 启动项目中，我们只需要如下配置就能启动Profile机制：\n\n​\t-Dspring.profiles.active=dev\n\n​\t注：Spring 会先判定是否存在 spring.profiles.active 配置后，再去查找 spring.profiles.default 配置的，所以 spring.profiles.active 的优先级要大于 spring.profiles.default\n\n#### 3）按照 springboot 的规则\n\n​\t-Dspring.profiles.active 配置的值记为 {profile} ，则它会用 application-{profiles}.properties 文件去代替原来默认的 application.properties文件\n\n## 2、使用 Spring EL\n\n####   1）读取属性文件的值，如：\n\n```java\n// ${......} 代表占位符\n@Value(\"${database.driverName}\")   \nString driver\n```\n\n \n\n####   2）记录一个Bean初始化事件，如：\n\n```java\n// #{......} 代表启用 Spring表达式，它将具有运算功能；T(......)代表的是引入类\n@Value(\"#{T(System).currentTimeMillis()}\")  \nprivate Long initTime = null;\n//直接赋值： 赋值字符串\n@Value(\"#{‘使用 Spring EL 赋值字符串’}\")\nprivate String str = null;\n// 科学计数法赋值\n@Value(\"#{9.3E3}\")\nprivate double d;\n// 其他Spring Bean属性赋值当前的Bean\n@Value(\"#{beanName.str}\")\nprivate String otherBeanProp = null;\n```\n\n还可以进行计算、三元运算、比较等。\n\n \n\n ","slug":"Spring-Bean生命周期","published":1,"updated":"2019-11-14T09:19:21.652Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0h000fvguqew4x0veo","content":"<h1>一、Spring Bean生命周期</h1>\n<p><img src=\"/img/clip_image002.png\" alt=\"img\"></p>\n<p>解释：</p>\n<ul>\n<li>\n<p>Spring 通过我们的配置，如 @ComponentScan 定义的扫描路径去找到带有 @Component     的类，这个过程就是一个资源定位的过程。</p>\n</li>\n<li>\n<p>一旦找到了资源，那么它就开始解析，并且将定义的信息保存起来。注意，此时还没有初始化 Bean ，也就没有 Bean 实例，它有的仅仅是 Bean 的定义。</p>\n</li>\n<li>\n<p>然后就会把 Bean 定义发布到 Spring IoC 容器中，此时，IoC容器也只有 Bean 的定义，还是没有 Bean 的实例生成。</p>\n<p>在默认的情况下，Spring会继续去完成Bean的实例化和依赖注入， 这样从IoC容器中就可以得到一个依赖注入完成的Bean。但是，有些Bean会在取的时候才初始化和依赖注入。如下图：</p>\n</li>\n</ul>\n<p><img src=\"/img/clip_image004.png\" alt=\"img\"></p>\n<p>解释：</p>\n<ul>\n<li>其中流程节点针对于单个Bean，BeanPostProcessor是针对所有Bean而言。</li>\n<li>即使你定义了ApplicationContextAware接口，但是有时候并不会调用，这要根据你的IoC容器来决定。</li>\n<li>Spring IoC     容器的最低要求是实现 BeanFactory 接口，而不是实现 ApplicationContext 接口。对于那些没有实现     ApplicationContext 接口的容器，对生命周期对应的 ApplicationContextAware     定义的方法也是不会被调用的，只有实现了 ApplicationContext 接口的容器，才会在生命周期调用 ApplicationContextAware 所定义的     setApplicationContext 方法。</li>\n</ul>\n<h1>二、Spring Bean作用域</h1>\n<h2>1、使用@Profile</h2>\n<h4>1）假设存在dev_spring_boot 和 test_spring_boot两个数据库，使用注解@Profile定义两个Bean</h4>\n<p>​    <img src=\"/img/SpringBean3.png\" alt=\"img\"></p>\n<h4>2）在 Java 启动项目中，我们只需要如下配置就能启动Profile机制：</h4>\n<p>​\t-Dspring.profiles.active=dev</p>\n<p>​\t注：Spring 会先判定是否存在 spring.profiles.active 配置后，再去查找 spring.profiles.default 配置的，所以 spring.profiles.active 的优先级要大于 spring.profiles.default</p>\n<h4>3）按照 springboot 的规则</h4>\n<p>​\t-Dspring.profiles.active 配置的值记为 {profile} ，则它会用 application-{profiles}.properties 文件去代替原来默认的 application.properties文件</p>\n<h2>2、使用 Spring EL</h2>\n<h4>1）读取属性文件的值，如：</h4>\n<pre><code class=\"language-java\">// ${......} 代表占位符\n@Value(&quot;${database.driverName}&quot;)   \nString driver\n</code></pre>\n<h4>2）记录一个Bean初始化事件，如：</h4>\n<pre><code class=\"language-java\">// #{......} 代表启用 Spring表达式，它将具有运算功能；T(......)代表的是引入类\n@Value(&quot;#{T(System).currentTimeMillis()}&quot;)  \nprivate Long initTime = null;\n//直接赋值： 赋值字符串\n@Value(&quot;#{‘使用 Spring EL 赋值字符串’}&quot;)\nprivate String str = null;\n// 科学计数法赋值\n@Value(&quot;#{9.3E3}&quot;)\nprivate double d;\n// 其他Spring Bean属性赋值当前的Bean\n@Value(&quot;#{beanName.str}&quot;)\nprivate String otherBeanProp = null;\n</code></pre>\n<p>还可以进行计算、三元运算、比较等。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、Spring Bean生命周期</h1>\n<p><img src=\"/img/clip_image002.png\" alt=\"img\"></p>\n<p>解释：</p>\n<ul>\n<li>\n<p>Spring 通过我们的配置，如 @ComponentScan 定义的扫描路径去找到带有 @Component     的类，这个过程就是一个资源定位的过程。</p>\n</li>\n<li>\n<p>一旦找到了资源，那么它就开始解析，并且将定义的信息保存起来。注意，此时还没有初始化 Bean ，也就没有 Bean 实例，它有的仅仅是 Bean 的定义。</p>\n</li>\n<li>\n<p>然后就会把 Bean 定义发布到 Spring IoC 容器中，此时，IoC容器也只有 Bean 的定义，还是没有 Bean 的实例生成。</p>\n<p>在默认的情况下，Spring会继续去完成Bean的实例化和依赖注入， 这样从IoC容器中就可以得到一个依赖注入完成的Bean。但是，有些Bean会在取的时候才初始化和依赖注入。如下图：</p>\n</li>\n</ul>\n<p><img src=\"/img/clip_image004.png\" alt=\"img\"></p>\n<p>解释：</p>\n<ul>\n<li>其中流程节点针对于单个Bean，BeanPostProcessor是针对所有Bean而言。</li>\n<li>即使你定义了ApplicationContextAware接口，但是有时候并不会调用，这要根据你的IoC容器来决定。</li>\n<li>Spring IoC     容器的最低要求是实现 BeanFactory 接口，而不是实现 ApplicationContext 接口。对于那些没有实现     ApplicationContext 接口的容器，对生命周期对应的 ApplicationContextAware     定义的方法也是不会被调用的，只有实现了 ApplicationContext 接口的容器，才会在生命周期调用 ApplicationContextAware 所定义的     setApplicationContext 方法。</li>\n</ul>\n<h1>二、Spring Bean作用域</h1>\n<h2>1、使用@Profile</h2>\n<h4>1）假设存在dev_spring_boot 和 test_spring_boot两个数据库，使用注解@Profile定义两个Bean</h4>\n<p>​    <img src=\"/img/SpringBean3.png\" alt=\"img\"></p>\n<h4>2）在 Java 启动项目中，我们只需要如下配置就能启动Profile机制：</h4>\n<p>​\t-Dspring.profiles.active=dev</p>\n<p>​\t注：Spring 会先判定是否存在 spring.profiles.active 配置后，再去查找 spring.profiles.default 配置的，所以 spring.profiles.active 的优先级要大于 spring.profiles.default</p>\n<h4>3）按照 springboot 的规则</h4>\n<p>​\t-Dspring.profiles.active 配置的值记为 {profile} ，则它会用 application-{profiles}.properties 文件去代替原来默认的 application.properties文件</p>\n<h2>2、使用 Spring EL</h2>\n<h4>1）读取属性文件的值，如：</h4>\n<pre><code class=\"language-java\">// ${......} 代表占位符\n@Value(&quot;${database.driverName}&quot;)   \nString driver\n</code></pre>\n<h4>2）记录一个Bean初始化事件，如：</h4>\n<pre><code class=\"language-java\">// #{......} 代表启用 Spring表达式，它将具有运算功能；T(......)代表的是引入类\n@Value(&quot;#{T(System).currentTimeMillis()}&quot;)  \nprivate Long initTime = null;\n//直接赋值： 赋值字符串\n@Value(&quot;#{‘使用 Spring EL 赋值字符串’}&quot;)\nprivate String str = null;\n// 科学计数法赋值\n@Value(&quot;#{9.3E3}&quot;)\nprivate double d;\n// 其他Spring Bean属性赋值当前的Bean\n@Value(&quot;#{beanName.str}&quot;)\nprivate String otherBeanProp = null;\n</code></pre>\n<p>还可以进行计算、三元运算、比较等。</p>\n"},{"title":"SpringCloud-Alibaba整合Nacos配置中心","author":"郑天祺","date":"2019-11-27T09:53:00.000Z","_content":"\n在 Nacos Spring Cloud 中，dataId 的完整格式如下：${prefix}-${spring.profile.active}.${file-extension}\n\n​\t${prefix} 为dataId的前缀，对应于Client端配置 spring.cloud.nacos.config.prefix 的值，如未配置，则默认对应Client端 spring.application.name 配置项的值。\n\n​\t${file-extension} 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。\n\n​\t${spring.profile.active} 为为当前环境对应的 profile，如为空，则变为${prefix}-${spring.profile.active}.${file-extension}形式。\n\n建议${prefix}采用类似 package.class的命名规则保证全局唯一性，class 部分建议是配置的业务含义。\n\n全部字符小写。只允许英文字符和 4 种特殊字符（\".\"、\":\"、\"-\"、\"_\"），不超过 256 字节。\n\n一、nacos配置\n\n![image-20191127175944755](/img/nacos-springCloud1.png)\n\n![image-20191127180038072](/img/nacos-springCloud2.png)\n\n二、配置文件\n\n创建配置文件  bootstrap.yml，并添加基础配置信息：\n\n```java\nspring:\n  application:\n    name: nacos-config-example\n  cloud:\n    nacos:\n      config:\n        server-addr: http://192.168.101.147:8848/\n        # config external configuration\n        ext-config:\n          # 1、Data Id (nacos-config-example.mysql-config.properties) 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新\n          - data-id: mysql-config.properties\n          # 2、Data Id (nacos-config-example.es-config.properties) 不在默认的组，支持动态刷新\n          - data-id: es-config.properties\n            group: GLOBALE_GROUP\n            refresh: true\n        encode: utf-8\n\n```\n\n三、使用变量\n\n```java\n    @Value(\"jdbc-name\")\n    private String jdbcName;\n    @Value(\"jdbc-password\")\n    private String jdbcPassword;\n\n    @Value(\"es-name\")\n    private String esName;\n    @Value(\"es-password\")\n    private String esPassword;\n```\n\n","source":"_posts/SpringCloud-Alibaba整合Nacos.md","raw":"title: SpringCloud-Alibaba整合Nacos配置中心\nauthor: 郑天祺\ntags:\n  - nacos-config\n  - SpringCloud\ncategories:\n  - SpringCloud\ndate: 2019-11-27 17:53:00\n---\n\n在 Nacos Spring Cloud 中，dataId 的完整格式如下：${prefix}-${spring.profile.active}.${file-extension}\n\n​\t${prefix} 为dataId的前缀，对应于Client端配置 spring.cloud.nacos.config.prefix 的值，如未配置，则默认对应Client端 spring.application.name 配置项的值。\n\n​\t${file-extension} 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。\n\n​\t${spring.profile.active} 为为当前环境对应的 profile，如为空，则变为${prefix}-${spring.profile.active}.${file-extension}形式。\n\n建议${prefix}采用类似 package.class的命名规则保证全局唯一性，class 部分建议是配置的业务含义。\n\n全部字符小写。只允许英文字符和 4 种特殊字符（\".\"、\":\"、\"-\"、\"_\"），不超过 256 字节。\n\n一、nacos配置\n\n![image-20191127175944755](/img/nacos-springCloud1.png)\n\n![image-20191127180038072](/img/nacos-springCloud2.png)\n\n二、配置文件\n\n创建配置文件  bootstrap.yml，并添加基础配置信息：\n\n```java\nspring:\n  application:\n    name: nacos-config-example\n  cloud:\n    nacos:\n      config:\n        server-addr: http://192.168.101.147:8848/\n        # config external configuration\n        ext-config:\n          # 1、Data Id (nacos-config-example.mysql-config.properties) 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新\n          - data-id: mysql-config.properties\n          # 2、Data Id (nacos-config-example.es-config.properties) 不在默认的组，支持动态刷新\n          - data-id: es-config.properties\n            group: GLOBALE_GROUP\n            refresh: true\n        encode: utf-8\n\n```\n\n三、使用变量\n\n```java\n    @Value(\"jdbc-name\")\n    private String jdbcName;\n    @Value(\"jdbc-password\")\n    private String jdbcPassword;\n\n    @Value(\"es-name\")\n    private String esName;\n    @Value(\"es-password\")\n    private String esPassword;\n```\n\n","slug":"SpringCloud-Alibaba整合Nacos","published":1,"updated":"2019-12-03T07:17:35.263Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0j000gvguq8rrmeujq","content":"<p>在 Nacos Spring Cloud 中，dataId 的完整格式如下：${prefix}-${spring.profile.active}.${file-extension}</p>\n<p>​\t${prefix} 为dataId的前缀，对应于Client端配置 spring.cloud.nacos.config.prefix 的值，如未配置，则默认对应Client端 spring.application.name 配置项的值。</p>\n<p>​\t${file-extension} 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。</p>\n<p>​\t${spring.profile.active} 为为当前环境对应的 profile，如为空，则变为${prefix}-${spring.profile.active}.${file-extension}形式。</p>\n<p>建议${prefix}采用类似 package.class的命名规则保证全局唯一性，class 部分建议是配置的业务含义。</p>\n<p>全部字符小写。只允许英文字符和 4 种特殊字符（&quot;.&quot;、&quot;:&quot;、&quot;-&quot;、&quot;_&quot;），不超过 256 字节。</p>\n<p>一、nacos配置</p>\n<p><img src=\"/img/nacos-springCloud1.png\" alt=\"image-20191127175944755\"></p>\n<p><img src=\"/img/nacos-springCloud2.png\" alt=\"image-20191127180038072\"></p>\n<p>二、配置文件</p>\n<p>创建配置文件  bootstrap.yml，并添加基础配置信息：</p>\n<pre><code class=\"language-java\">spring:\n  application:\n    name: nacos-config-example\n  cloud:\n    nacos:\n      config:\n        server-addr: http://192.168.101.147:8848/\n        # config external configuration\n        ext-config:\n          # 1、Data Id (nacos-config-example.mysql-config.properties) 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新\n          - data-id: mysql-config.properties\n          # 2、Data Id (nacos-config-example.es-config.properties) 不在默认的组，支持动态刷新\n          - data-id: es-config.properties\n            group: GLOBALE_GROUP\n            refresh: true\n        encode: utf-8\n\n</code></pre>\n<p>三、使用变量</p>\n<pre><code class=\"language-java\">    @Value(&quot;jdbc-name&quot;)\n    private String jdbcName;\n    @Value(&quot;jdbc-password&quot;)\n    private String jdbcPassword;\n\n    @Value(&quot;es-name&quot;)\n    private String esName;\n    @Value(&quot;es-password&quot;)\n    private String esPassword;\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>在 Nacos Spring Cloud 中，dataId 的完整格式如下：${prefix}-${spring.profile.active}.${file-extension}</p>\n<p>​\t${prefix} 为dataId的前缀，对应于Client端配置 spring.cloud.nacos.config.prefix 的值，如未配置，则默认对应Client端 spring.application.name 配置项的值。</p>\n<p>​\t${file-extension} 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。</p>\n<p>​\t${spring.profile.active} 为为当前环境对应的 profile，如为空，则变为${prefix}-${spring.profile.active}.${file-extension}形式。</p>\n<p>建议${prefix}采用类似 package.class的命名规则保证全局唯一性，class 部分建议是配置的业务含义。</p>\n<p>全部字符小写。只允许英文字符和 4 种特殊字符（&quot;.&quot;、&quot;:&quot;、&quot;-&quot;、&quot;_&quot;），不超过 256 字节。</p>\n<p>一、nacos配置</p>\n<p><img src=\"/img/nacos-springCloud1.png\" alt=\"image-20191127175944755\"></p>\n<p><img src=\"/img/nacos-springCloud2.png\" alt=\"image-20191127180038072\"></p>\n<p>二、配置文件</p>\n<p>创建配置文件  bootstrap.yml，并添加基础配置信息：</p>\n<pre><code class=\"language-java\">spring:\n  application:\n    name: nacos-config-example\n  cloud:\n    nacos:\n      config:\n        server-addr: http://192.168.101.147:8848/\n        # config external configuration\n        ext-config:\n          # 1、Data Id (nacos-config-example.mysql-config.properties) 在默认的组 DEFAULT_GROUP,不支持配置的动态刷新\n          - data-id: mysql-config.properties\n          # 2、Data Id (nacos-config-example.es-config.properties) 不在默认的组，支持动态刷新\n          - data-id: es-config.properties\n            group: GLOBALE_GROUP\n            refresh: true\n        encode: utf-8\n\n</code></pre>\n<p>三、使用变量</p>\n<pre><code class=\"language-java\">    @Value(&quot;jdbc-name&quot;)\n    private String jdbcName;\n    @Value(&quot;jdbc-password&quot;)\n    private String jdbcPassword;\n\n    @Value(&quot;es-name&quot;)\n    private String esName;\n    @Value(&quot;es-password&quot;)\n    private String esPassword;\n</code></pre>\n"},{"title":"SpringCloud-Alibaba整合Nacos服务注册发现","author":"郑天祺","date":"2019-12-03T07:18:00.000Z","_content":"\n# 一、服务注册\n\n## 1、引入依赖\n\n```java\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n## 2、配置application.yml\n\n在application.yaml配置文件内添加Nacos Server的地址：\n\n```java\nserver:\n  port: 8081\nspring:\n  application:\n    name: nacos-producer # 注册到nacos的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n```\n\n## 3、springboot启动类\n\n在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能\n\n```java\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class NacosProviderDemoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(NacosProviderDemoApplication.class, args);\n    }\n}\n\n```\n\n## 4、确认注册成功\n\n运行程序，打开Nacos管理服务，可以看到nacos-producer已经成功注册。\n\n![image-20191203152720691](/img/nacos-producer.png)\n\n# 二、服务发现\n\n\n基于Alibaba Nacos Spring Cloud（服务发现）、Spring Cloud OpenFeign（声明式调用，同时整合了熔断器、负载均衡），推荐使用此方法。\n\n## 1、引入依赖\n\n```java\n<!-- Nacos服务发现 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n\n<!-- 声明式调用 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n\n<!-- 负载均衡 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>\n</dependency>\n\n<!-- 熔断器 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n</dependency>\n```\n\n## 2、配置文件配置\n\n在application.yaml配置文件内添加Nacos Server的地址，并开启feign的熔断器功能：\n\n```java\nserver:\n  port: 8081\n  \nspring:\n  application:\n    name: nacos-producer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n\n#允许feign开启熔断器，默认未开启\nfeign:\n  hystrix:\n    enabled: true\n\nhystrix:\n  command:\n    default:\n      execution:\n        timeout:\n          enabled: true\n      isolation:\n        thread:\n          #目前有两个容器实例，单个请求超时5s,+重试>10s，超15s则熔断\n          timeoutInMilliseconds: 15000\n\nribbon:\n  #ribbon请求连接的超时时间- 限制3秒内必须请求到服务，并不限制服务处理的返回时间\n  connectTimeout: 3000\n  #请求处理的超时时间 下级服务响应最大时间,超出时间消费方（路由也是消费方）返回timeout,超时时间不可大于断路器的超时时间\n  readTimeout: 5000\n```\n\n## 3、开启服务发现、负载均衡、熔断器功能\n\n在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能，添加 @EnableCircuitBreaker 开始熔断器功能：\n\n```java\n@SpringBootApplication\n@EnableDiscoveryClient   //开启服务发现\n@EnableCircuitBreaker    //开始熔断功能\n@EnableFeignClients(basePackages = {\"com.sy\"})   //开启Feign客户端，并指定扫描范围\n@ComponentScan(basePackages = {\"com.sy\"})\npublic class NacosDiscoveryExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosDiscoveryExampleApplication.class, args);\n    }\n}\n```\n\n## 4、创建服务代理类\n\n使用@FeignClient注解声明服务调用的代理类，其中参数含义为：\n\t1.name：服务提供者注册在服务注册中心的名称；\n\t2.fallback：使用者提供的断路器实现，必须是当前代理类的实现类；\n\t3.fallbackFactory：使用者提供的Hystrix的断路器工厂类实现。\n\n注：fallback 与 fallbackFactory 只需要配置一个，建议使用fallbackFactory。 示例如下：\n\n```java\n@Component\n@FeignClient(name = \"nacos-producer\", fallbackFactory = HystrixClientFallbackFactory.class)\npublic interface ConsumerService {\n    @LoadBalanced\n    @GetMapping(value = \"/hello\")\n    String hello();\n\n    @LoadBalanced\n    @GetMapping(value = \"/hello/{string}\")\n    String hello(@PathVariable(\"string\") String string);\n}\n```\n\n## 5、创建Hystrix的断路器工厂类\n\n```java\n@Component\npublic class HystrixClientFallbackFactory implements FallbackFactory<ConsumerService> {\n    @Override\n    public ConsumerService create(Throwable cause) {\n        // 打印日志\n        LocalLog.info(\"fallback; reason was: \" + cause.getMessage());\n        return new ConsumerService() {\n            @Override\n            public String hello() {\n                return \"请求失败\";\n            }\n\n            @Override\n            public String hello(String string) {\n                return \"请求失败. string=\" + string;\n            }\n        };\n    }\n}\n```\n\n## 6、通用代理类的实例进行服务调用，与本地调用无异。如下：\n\n```java\n@RestController\npublic class ConsumerController {\n    @Autowired\n    private ConsumerService consumerService;\n\n    @RequestMapping(value = \"/feign/{string}\", method = RequestMethod.GET)\n    public String echo(@PathVariable String string) {\n        return consumerService.hello(string);\n    }\n}\n```\n\n","source":"_posts/SpringCloud-Alibaba整合Nacos服务注册发现.md","raw":"title: SpringCloud-Alibaba整合Nacos服务注册发现\nauthor: 郑天祺\ntags:\n\n  - SpringCloud\ncategories:\n  - SpringCloud\ndate: 2019-12-03 15:18:00\n\n---\n\n# 一、服务注册\n\n## 1、引入依赖\n\n```java\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n## 2、配置application.yml\n\n在application.yaml配置文件内添加Nacos Server的地址：\n\n```java\nserver:\n  port: 8081\nspring:\n  application:\n    name: nacos-producer # 注册到nacos的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n```\n\n## 3、springboot启动类\n\n在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能\n\n```java\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class NacosProviderDemoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(NacosProviderDemoApplication.class, args);\n    }\n}\n\n```\n\n## 4、确认注册成功\n\n运行程序，打开Nacos管理服务，可以看到nacos-producer已经成功注册。\n\n![image-20191203152720691](/img/nacos-producer.png)\n\n# 二、服务发现\n\n\n基于Alibaba Nacos Spring Cloud（服务发现）、Spring Cloud OpenFeign（声明式调用，同时整合了熔断器、负载均衡），推荐使用此方法。\n\n## 1、引入依赖\n\n```java\n<!-- Nacos服务发现 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n\n<!-- 声明式调用 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n\n<!-- 负载均衡 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-ribbon</artifactId>\n</dependency>\n\n<!-- 熔断器 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n</dependency>\n```\n\n## 2、配置文件配置\n\n在application.yaml配置文件内添加Nacos Server的地址，并开启feign的熔断器功能：\n\n```java\nserver:\n  port: 8081\n  \nspring:\n  application:\n    name: nacos-producer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n\n#允许feign开启熔断器，默认未开启\nfeign:\n  hystrix:\n    enabled: true\n\nhystrix:\n  command:\n    default:\n      execution:\n        timeout:\n          enabled: true\n      isolation:\n        thread:\n          #目前有两个容器实例，单个请求超时5s,+重试>10s，超15s则熔断\n          timeoutInMilliseconds: 15000\n\nribbon:\n  #ribbon请求连接的超时时间- 限制3秒内必须请求到服务，并不限制服务处理的返回时间\n  connectTimeout: 3000\n  #请求处理的超时时间 下级服务响应最大时间,超出时间消费方（路由也是消费方）返回timeout,超时时间不可大于断路器的超时时间\n  readTimeout: 5000\n```\n\n## 3、开启服务发现、负载均衡、熔断器功能\n\n在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能，添加 @EnableCircuitBreaker 开始熔断器功能：\n\n```java\n@SpringBootApplication\n@EnableDiscoveryClient   //开启服务发现\n@EnableCircuitBreaker    //开始熔断功能\n@EnableFeignClients(basePackages = {\"com.sy\"})   //开启Feign客户端，并指定扫描范围\n@ComponentScan(basePackages = {\"com.sy\"})\npublic class NacosDiscoveryExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosDiscoveryExampleApplication.class, args);\n    }\n}\n```\n\n## 4、创建服务代理类\n\n使用@FeignClient注解声明服务调用的代理类，其中参数含义为：\n\t1.name：服务提供者注册在服务注册中心的名称；\n\t2.fallback：使用者提供的断路器实现，必须是当前代理类的实现类；\n\t3.fallbackFactory：使用者提供的Hystrix的断路器工厂类实现。\n\n注：fallback 与 fallbackFactory 只需要配置一个，建议使用fallbackFactory。 示例如下：\n\n```java\n@Component\n@FeignClient(name = \"nacos-producer\", fallbackFactory = HystrixClientFallbackFactory.class)\npublic interface ConsumerService {\n    @LoadBalanced\n    @GetMapping(value = \"/hello\")\n    String hello();\n\n    @LoadBalanced\n    @GetMapping(value = \"/hello/{string}\")\n    String hello(@PathVariable(\"string\") String string);\n}\n```\n\n## 5、创建Hystrix的断路器工厂类\n\n```java\n@Component\npublic class HystrixClientFallbackFactory implements FallbackFactory<ConsumerService> {\n    @Override\n    public ConsumerService create(Throwable cause) {\n        // 打印日志\n        LocalLog.info(\"fallback; reason was: \" + cause.getMessage());\n        return new ConsumerService() {\n            @Override\n            public String hello() {\n                return \"请求失败\";\n            }\n\n            @Override\n            public String hello(String string) {\n                return \"请求失败. string=\" + string;\n            }\n        };\n    }\n}\n```\n\n## 6、通用代理类的实例进行服务调用，与本地调用无异。如下：\n\n```java\n@RestController\npublic class ConsumerController {\n    @Autowired\n    private ConsumerService consumerService;\n\n    @RequestMapping(value = \"/feign/{string}\", method = RequestMethod.GET)\n    public String echo(@PathVariable String string) {\n        return consumerService.hello(string);\n    }\n}\n```\n\n","slug":"SpringCloud-Alibaba整合Nacos服务注册发现","published":1,"updated":"2019-12-03T08:02:58.242Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0n000kvguqksfm1mnd","content":"<h1>一、服务注册</h1>\n<h2>1、引入依赖</h2>\n<pre><code class=\"language-java\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h2>2、配置application.yml</h2>\n<p>在application.yaml配置文件内添加Nacos Server的地址：</p>\n<pre><code class=\"language-java\">server:\n  port: 8081\nspring:\n  application:\n    name: nacos-producer # 注册到nacos的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n</code></pre>\n<h2>3、springboot启动类</h2>\n<p>在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能</p>\n<pre><code class=\"language-java\">@SpringBootApplication\n@EnableDiscoveryClient\npublic class NacosProviderDemoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(NacosProviderDemoApplication.class, args);\n    }\n}\n\n</code></pre>\n<h2>4、确认注册成功</h2>\n<p>运行程序，打开Nacos管理服务，可以看到nacos-producer已经成功注册。</p>\n<p><img src=\"/img/nacos-producer.png\" alt=\"image-20191203152720691\"></p>\n<h1>二、服务发现</h1>\n<p>基于Alibaba Nacos Spring Cloud（服务发现）、Spring Cloud OpenFeign（声明式调用，同时整合了熔断器、负载均衡），推荐使用此方法。</p>\n<h2>1、引入依赖</h2>\n<pre><code class=\"language-java\">&lt;!-- Nacos服务发现 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 声明式调用 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 负载均衡 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 熔断器 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h2>2、配置文件配置</h2>\n<p>在application.yaml配置文件内添加Nacos Server的地址，并开启feign的熔断器功能：</p>\n<pre><code class=\"language-java\">server:\n  port: 8081\n  \nspring:\n  application:\n    name: nacos-producer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n\n#允许feign开启熔断器，默认未开启\nfeign:\n  hystrix:\n    enabled: true\n\nhystrix:\n  command:\n    default:\n      execution:\n        timeout:\n          enabled: true\n      isolation:\n        thread:\n          #目前有两个容器实例，单个请求超时5s,+重试&gt;10s，超15s则熔断\n          timeoutInMilliseconds: 15000\n\nribbon:\n  #ribbon请求连接的超时时间- 限制3秒内必须请求到服务，并不限制服务处理的返回时间\n  connectTimeout: 3000\n  #请求处理的超时时间 下级服务响应最大时间,超出时间消费方（路由也是消费方）返回timeout,超时时间不可大于断路器的超时时间\n  readTimeout: 5000\n</code></pre>\n<h2>3、开启服务发现、负载均衡、熔断器功能</h2>\n<p>在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能，添加 @EnableCircuitBreaker 开始熔断器功能：</p>\n<pre><code class=\"language-java\">@SpringBootApplication\n@EnableDiscoveryClient   //开启服务发现\n@EnableCircuitBreaker    //开始熔断功能\n@EnableFeignClients(basePackages = {&quot;com.sy&quot;})   //开启Feign客户端，并指定扫描范围\n@ComponentScan(basePackages = {&quot;com.sy&quot;})\npublic class NacosDiscoveryExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosDiscoveryExampleApplication.class, args);\n    }\n}\n</code></pre>\n<h2>4、创建服务代理类</h2>\n<p>使用@FeignClient注解声明服务调用的代理类，其中参数含义为：\n\t1.name：服务提供者注册在服务注册中心的名称；\n\t2.fallback：使用者提供的断路器实现，必须是当前代理类的实现类；\n\t3.fallbackFactory：使用者提供的Hystrix的断路器工厂类实现。</p>\n<p>注：fallback 与 fallbackFactory 只需要配置一个，建议使用fallbackFactory。 示例如下：</p>\n<pre><code class=\"language-java\">@Component\n@FeignClient(name = &quot;nacos-producer&quot;, fallbackFactory = HystrixClientFallbackFactory.class)\npublic interface ConsumerService {\n    @LoadBalanced\n    @GetMapping(value = &quot;/hello&quot;)\n    String hello();\n\n    @LoadBalanced\n    @GetMapping(value = &quot;/hello/{string}&quot;)\n    String hello(@PathVariable(&quot;string&quot;) String string);\n}\n</code></pre>\n<h2>5、创建Hystrix的断路器工厂类</h2>\n<pre><code class=\"language-java\">@Component\npublic class HystrixClientFallbackFactory implements FallbackFactory&lt;ConsumerService&gt; {\n    @Override\n    public ConsumerService create(Throwable cause) {\n        // 打印日志\n        LocalLog.info(&quot;fallback; reason was: &quot; + cause.getMessage());\n        return new ConsumerService() {\n            @Override\n            public String hello() {\n                return &quot;请求失败&quot;;\n            }\n\n            @Override\n            public String hello(String string) {\n                return &quot;请求失败. string=&quot; + string;\n            }\n        };\n    }\n}\n</code></pre>\n<h2>6、通用代理类的实例进行服务调用，与本地调用无异。如下：</h2>\n<pre><code class=\"language-java\">@RestController\npublic class ConsumerController {\n    @Autowired\n    private ConsumerService consumerService;\n\n    @RequestMapping(value = &quot;/feign/{string}&quot;, method = RequestMethod.GET)\n    public String echo(@PathVariable String string) {\n        return consumerService.hello(string);\n    }\n}\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、服务注册</h1>\n<h2>1、引入依赖</h2>\n<pre><code class=\"language-java\">&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h2>2、配置application.yml</h2>\n<p>在application.yaml配置文件内添加Nacos Server的地址：</p>\n<pre><code class=\"language-java\">server:\n  port: 8081\nspring:\n  application:\n    name: nacos-producer # 注册到nacos的服务名称\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n</code></pre>\n<h2>3、springboot启动类</h2>\n<p>在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能</p>\n<pre><code class=\"language-java\">@SpringBootApplication\n@EnableDiscoveryClient\npublic class NacosProviderDemoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(NacosProviderDemoApplication.class, args);\n    }\n}\n\n</code></pre>\n<h2>4、确认注册成功</h2>\n<p>运行程序，打开Nacos管理服务，可以看到nacos-producer已经成功注册。</p>\n<p><img src=\"/img/nacos-producer.png\" alt=\"image-20191203152720691\"></p>\n<h1>二、服务发现</h1>\n<p>基于Alibaba Nacos Spring Cloud（服务发现）、Spring Cloud OpenFeign（声明式调用，同时整合了熔断器、负载均衡），推荐使用此方法。</p>\n<h2>1、引入依赖</h2>\n<pre><code class=\"language-java\">&lt;!-- Nacos服务发现 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 声明式调用 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 负载均衡 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n&lt;!-- 熔断器 --&gt;\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>\n<h2>2、配置文件配置</h2>\n<p>在application.yaml配置文件内添加Nacos Server的地址，并开启feign的熔断器功能：</p>\n<pre><code class=\"language-java\">server:\n  port: 8081\n  \nspring:\n  application:\n    name: nacos-producer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: 127.0.0.1:8848\n\n#允许feign开启熔断器，默认未开启\nfeign:\n  hystrix:\n    enabled: true\n\nhystrix:\n  command:\n    default:\n      execution:\n        timeout:\n          enabled: true\n      isolation:\n        thread:\n          #目前有两个容器实例，单个请求超时5s,+重试&gt;10s，超15s则熔断\n          timeoutInMilliseconds: 15000\n\nribbon:\n  #ribbon请求连接的超时时间- 限制3秒内必须请求到服务，并不限制服务处理的返回时间\n  connectTimeout: 3000\n  #请求处理的超时时间 下级服务响应最大时间,超出时间消费方（路由也是消费方）返回timeout,超时时间不可大于断路器的超时时间\n  readTimeout: 5000\n</code></pre>\n<h2>3、开启服务发现、负载均衡、熔断器功能</h2>\n<p>在启动类添加 Spring Cloud 原生注解 @EnableDiscoveryClient ，开启服务注册发现功能，添加 @EnableCircuitBreaker 开始熔断器功能：</p>\n<pre><code class=\"language-java\">@SpringBootApplication\n@EnableDiscoveryClient   //开启服务发现\n@EnableCircuitBreaker    //开始熔断功能\n@EnableFeignClients(basePackages = {&quot;com.sy&quot;})   //开启Feign客户端，并指定扫描范围\n@ComponentScan(basePackages = {&quot;com.sy&quot;})\npublic class NacosDiscoveryExampleApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(NacosDiscoveryExampleApplication.class, args);\n    }\n}\n</code></pre>\n<h2>4、创建服务代理类</h2>\n<p>使用@FeignClient注解声明服务调用的代理类，其中参数含义为：\n\t1.name：服务提供者注册在服务注册中心的名称；\n\t2.fallback：使用者提供的断路器实现，必须是当前代理类的实现类；\n\t3.fallbackFactory：使用者提供的Hystrix的断路器工厂类实现。</p>\n<p>注：fallback 与 fallbackFactory 只需要配置一个，建议使用fallbackFactory。 示例如下：</p>\n<pre><code class=\"language-java\">@Component\n@FeignClient(name = &quot;nacos-producer&quot;, fallbackFactory = HystrixClientFallbackFactory.class)\npublic interface ConsumerService {\n    @LoadBalanced\n    @GetMapping(value = &quot;/hello&quot;)\n    String hello();\n\n    @LoadBalanced\n    @GetMapping(value = &quot;/hello/{string}&quot;)\n    String hello(@PathVariable(&quot;string&quot;) String string);\n}\n</code></pre>\n<h2>5、创建Hystrix的断路器工厂类</h2>\n<pre><code class=\"language-java\">@Component\npublic class HystrixClientFallbackFactory implements FallbackFactory&lt;ConsumerService&gt; {\n    @Override\n    public ConsumerService create(Throwable cause) {\n        // 打印日志\n        LocalLog.info(&quot;fallback; reason was: &quot; + cause.getMessage());\n        return new ConsumerService() {\n            @Override\n            public String hello() {\n                return &quot;请求失败&quot;;\n            }\n\n            @Override\n            public String hello(String string) {\n                return &quot;请求失败. string=&quot; + string;\n            }\n        };\n    }\n}\n</code></pre>\n<h2>6、通用代理类的实例进行服务调用，与本地调用无异。如下：</h2>\n<pre><code class=\"language-java\">@RestController\npublic class ConsumerController {\n    @Autowired\n    private ConsumerService consumerService;\n\n    @RequestMapping(value = &quot;/feign/{string}&quot;, method = RequestMethod.GET)\n    public String echo(@PathVariable String string) {\n        return consumerService.hello(string);\n    }\n}\n</code></pre>\n"},{"title":"TCP握手、挥手协议","author":"郑天祺","date":"2019-08-30T07:58:00.000Z","_content":"\n## 1、TCP三次握手协议（打开连接）\n\n![](/img/三次握手协议1.png)\n\n第一次： A城发信，B城收到了------> 此时B城就会明白 ：A城的发信能力和自己的收信能力是没问题的\n\n第二次：B城发信，A城收到了-----> 此时A城就会明白 ：A城的发信能力和收信能力都是没问题的，B城的发信能力和收信能力都是没问题的。但是B不知道自己发信能力如何，所以要进行第三次握手\n\n第三次：A城发信，B城收到了，此时B城就会明白，B城的发信能力和自己的收信能力是没有问题的。\n\n更加简洁的图片\n\n![](/img/三次握手协议2.png)\n\n\n\n## 2、TCP四次挥手协议（关闭连接）\n\n![](/img/四次挥手协议.png)\n\n第一次：A和B打电话，通话即将结束后，A说“我有事先忙了，我得关闭链接了”，\n\n3) demo\n\n第一次握手(SYN=1, seq=x)\n\n客户端发送一个TCP的SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号X,保存在包头的序列号(Sequence Number)字段里。\n\n发送完毕后，客户端进入SYN_SEND 状态。\n\n \n\n第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1):\n\n服务器发回确认包(ACK)应答。即SYN 标志位和ACK 标志位均为1。服务器端选择自己ISN 序列号，放到Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的ISN 加1，即X+1。\n\n发送完毕后，服务器端进入SYN_RCVD 状态。\n\n \n\n第三次握手(ACK=1，ACKnum=y+1)\n\n客户端再次发送确认包(ACK)，SYN标志位为0，ACK标志位为1，并且把服务器发来ACK的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN发完毕后，客户端进入ESTABLISHED 状态，当服务器端接收到这个包时，也进入ESTABLISHED 状态，TCP握手结束。 \n\n### （2）四次挥手\n\n![](/img/四次挥手协议2.png)\n\n第一次挥手(FIN=1，seq=x)\n\n假设客户端想要关闭连接，客户端发送一个FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。发送完毕后，客户端进入FIN_WAIT_1 状态。\n\n第二次挥手(ACK=1，ACKnum=x+1)\n\n服务器端确认客户端的FIN包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。发送完毕后，服务器端进入CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入FIN_WAIT_2 状态，等待服务器端关闭连接。\n\n第三次挥手(FIN=1，seq=w)\n\n服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN置为1。发送完毕后，服务器端进入LAST_ACK 状态，等待来自客户端的最后一个ACK。\n\n第四次挥手(ACK=1，ACKnum=w+1)\n\n客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入TIME_WAIT状态，等待可能出现的要求重传的ACK包。\n\n服务器端接收到这个确认包之后，关闭连接，进入CLOSED 状态。\n\n客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入CLOSED状态。\n\n ","source":"_posts/TCP握手、挥手协议.md","raw":"title: TCP握手、挥手协议\nauthor: 郑天祺\ntags:\n  - TCP/IP\ncategories:\n  - 网络\ndate: 2019-08-30 15:58:00\n\n---\n\n## 1、TCP三次握手协议（打开连接）\n\n![](/img/三次握手协议1.png)\n\n第一次： A城发信，B城收到了------> 此时B城就会明白 ：A城的发信能力和自己的收信能力是没问题的\n\n第二次：B城发信，A城收到了-----> 此时A城就会明白 ：A城的发信能力和收信能力都是没问题的，B城的发信能力和收信能力都是没问题的。但是B不知道自己发信能力如何，所以要进行第三次握手\n\n第三次：A城发信，B城收到了，此时B城就会明白，B城的发信能力和自己的收信能力是没有问题的。\n\n更加简洁的图片\n\n![](/img/三次握手协议2.png)\n\n\n\n## 2、TCP四次挥手协议（关闭连接）\n\n![](/img/四次挥手协议.png)\n\n第一次：A和B打电话，通话即将结束后，A说“我有事先忙了，我得关闭链接了”，\n\n3) demo\n\n第一次握手(SYN=1, seq=x)\n\n客户端发送一个TCP的SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号X,保存在包头的序列号(Sequence Number)字段里。\n\n发送完毕后，客户端进入SYN_SEND 状态。\n\n \n\n第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1):\n\n服务器发回确认包(ACK)应答。即SYN 标志位和ACK 标志位均为1。服务器端选择自己ISN 序列号，放到Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的ISN 加1，即X+1。\n\n发送完毕后，服务器端进入SYN_RCVD 状态。\n\n \n\n第三次握手(ACK=1，ACKnum=y+1)\n\n客户端再次发送确认包(ACK)，SYN标志位为0，ACK标志位为1，并且把服务器发来ACK的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN发完毕后，客户端进入ESTABLISHED 状态，当服务器端接收到这个包时，也进入ESTABLISHED 状态，TCP握手结束。 \n\n### （2）四次挥手\n\n![](/img/四次挥手协议2.png)\n\n第一次挥手(FIN=1，seq=x)\n\n假设客户端想要关闭连接，客户端发送一个FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。发送完毕后，客户端进入FIN_WAIT_1 状态。\n\n第二次挥手(ACK=1，ACKnum=x+1)\n\n服务器端确认客户端的FIN包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。发送完毕后，服务器端进入CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入FIN_WAIT_2 状态，等待服务器端关闭连接。\n\n第三次挥手(FIN=1，seq=w)\n\n服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN置为1。发送完毕后，服务器端进入LAST_ACK 状态，等待来自客户端的最后一个ACK。\n\n第四次挥手(ACK=1，ACKnum=w+1)\n\n客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入TIME_WAIT状态，等待可能出现的要求重传的ACK包。\n\n服务器端接收到这个确认包之后，关闭连接，进入CLOSED 状态。\n\n客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入CLOSED状态。\n\n ","slug":"TCP握手、挥手协议","published":1,"updated":"2019-10-15T10:09:29.423Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0p000nvguqsbfsbgbm","content":"<h2>1、TCP三次握手协议（打开连接）</h2>\n<p><img src=\"/img/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%8D%8F%E8%AE%AE1.png\" alt></p>\n<p>第一次： A城发信，B城收到了------&gt; 此时B城就会明白 ：A城的发信能力和自己的收信能力是没问题的</p>\n<p>第二次：B城发信，A城收到了-----&gt; 此时A城就会明白 ：A城的发信能力和收信能力都是没问题的，B城的发信能力和收信能力都是没问题的。但是B不知道自己发信能力如何，所以要进行第三次握手</p>\n<p>第三次：A城发信，B城收到了，此时B城就会明白，B城的发信能力和自己的收信能力是没有问题的。</p>\n<p>更加简洁的图片</p>\n<p><img src=\"/img/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%8D%8F%E8%AE%AE2.png\" alt></p>\n<h2>2、TCP四次挥手协议（关闭连接）</h2>\n<p><img src=\"/img/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%8D%8F%E8%AE%AE.png\" alt></p>\n<p>第一次：A和B打电话，通话即将结束后，A说“我有事先忙了，我得关闭链接了”，</p>\n<ol start=\"3\">\n<li>demo</li>\n</ol>\n<p>第一次握手(SYN=1, seq=x)</p>\n<p>客户端发送一个TCP的SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号X,保存在包头的序列号(Sequence Number)字段里。</p>\n<p>发送完毕后，客户端进入SYN_SEND 状态。</p>\n<p>第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1):</p>\n<p>服务器发回确认包(ACK)应答。即SYN 标志位和ACK 标志位均为1。服务器端选择自己ISN 序列号，放到Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的ISN 加1，即X+1。</p>\n<p>发送完毕后，服务器端进入SYN_RCVD 状态。</p>\n<p>第三次握手(ACK=1，ACKnum=y+1)</p>\n<p>客户端再次发送确认包(ACK)，SYN标志位为0，ACK标志位为1，并且把服务器发来ACK的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN发完毕后，客户端进入ESTABLISHED 状态，当服务器端接收到这个包时，也进入ESTABLISHED 状态，TCP握手结束。</p>\n<h3>（2）四次挥手</h3>\n<p><img src=\"/img/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%8D%8F%E8%AE%AE2.png\" alt></p>\n<p>第一次挥手(FIN=1，seq=x)</p>\n<p>假设客户端想要关闭连接，客户端发送一个FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。发送完毕后，客户端进入FIN_WAIT_1 状态。</p>\n<p>第二次挥手(ACK=1，ACKnum=x+1)</p>\n<p>服务器端确认客户端的FIN包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。发送完毕后，服务器端进入CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入FIN_WAIT_2 状态，等待服务器端关闭连接。</p>\n<p>第三次挥手(FIN=1，seq=w)</p>\n<p>服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN置为1。发送完毕后，服务器端进入LAST_ACK 状态，等待来自客户端的最后一个ACK。</p>\n<p>第四次挥手(ACK=1，ACKnum=w+1)</p>\n<p>客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入TIME_WAIT状态，等待可能出现的要求重传的ACK包。</p>\n<p>服务器端接收到这个确认包之后，关闭连接，进入CLOSED 状态。</p>\n<p>客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入CLOSED状态。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、TCP三次握手协议（打开连接）</h2>\n<p><img src=\"/img/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%8D%8F%E8%AE%AE1.png\" alt></p>\n<p>第一次： A城发信，B城收到了------&gt; 此时B城就会明白 ：A城的发信能力和自己的收信能力是没问题的</p>\n<p>第二次：B城发信，A城收到了-----&gt; 此时A城就会明白 ：A城的发信能力和收信能力都是没问题的，B城的发信能力和收信能力都是没问题的。但是B不知道自己发信能力如何，所以要进行第三次握手</p>\n<p>第三次：A城发信，B城收到了，此时B城就会明白，B城的发信能力和自己的收信能力是没有问题的。</p>\n<p>更加简洁的图片</p>\n<p><img src=\"/img/%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%8D%8F%E8%AE%AE2.png\" alt></p>\n<h2>2、TCP四次挥手协议（关闭连接）</h2>\n<p><img src=\"/img/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%8D%8F%E8%AE%AE.png\" alt></p>\n<p>第一次：A和B打电话，通话即将结束后，A说“我有事先忙了，我得关闭链接了”，</p>\n<ol start=\"3\">\n<li>demo</li>\n</ol>\n<p>第一次握手(SYN=1, seq=x)</p>\n<p>客户端发送一个TCP的SYN 标志位置1的包，指明客户端打算连接的服务器的端口，以及初始序号X,保存在包头的序列号(Sequence Number)字段里。</p>\n<p>发送完毕后，客户端进入SYN_SEND 状态。</p>\n<p>第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1):</p>\n<p>服务器发回确认包(ACK)应答。即SYN 标志位和ACK 标志位均为1。服务器端选择自己ISN 序列号，放到Seq 域里，同时将确认序号(Acknowledgement Number)设置为客户的ISN 加1，即X+1。</p>\n<p>发送完毕后，服务器端进入SYN_RCVD 状态。</p>\n<p>第三次握手(ACK=1，ACKnum=y+1)</p>\n<p>客户端再次发送确认包(ACK)，SYN标志位为0，ACK标志位为1，并且把服务器发来ACK的序号字段+1，放在确定字段中发送给对方，并且在数据段放写ISN发完毕后，客户端进入ESTABLISHED 状态，当服务器端接收到这个包时，也进入ESTABLISHED 状态，TCP握手结束。</p>\n<h3>（2）四次挥手</h3>\n<p><img src=\"/img/%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E5%8D%8F%E8%AE%AE2.png\" alt></p>\n<p>第一次挥手(FIN=1，seq=x)</p>\n<p>假设客户端想要关闭连接，客户端发送一个FIN 标志位置为1的包，表示自己已经没有数据可以发送了，但是仍然可以接受数据。发送完毕后，客户端进入FIN_WAIT_1 状态。</p>\n<p>第二次挥手(ACK=1，ACKnum=x+1)</p>\n<p>服务器端确认客户端的FIN包，发送一个确认包，表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。发送完毕后，服务器端进入CLOSE_WAIT 状态，客户端接收到这个确认包之后，进入FIN_WAIT_2 状态，等待服务器端关闭连接。</p>\n<p>第三次挥手(FIN=1，seq=w)</p>\n<p>服务器端准备好关闭连接时，向客户端发送结束连接请求，FIN置为1。发送完毕后，服务器端进入LAST_ACK 状态，等待来自客户端的最后一个ACK。</p>\n<p>第四次挥手(ACK=1，ACKnum=w+1)</p>\n<p>客户端接收到来自服务器端的关闭请求，发送一个确认包，并进入TIME_WAIT状态，等待可能出现的要求重传的ACK包。</p>\n<p>服务器端接收到这个确认包之后，关闭连接，进入CLOSED 状态。</p>\n<p>客户端等待了某个固定时间（两个最大段生命周期，2MSL，2 Maximum Segment Lifetime）之后，没有收到服务器端的ACK，认为服务器端已经正常关闭连接，于是自己也关闭连接，进入CLOSED状态。</p>\n"},{"title":"TCP IP四层网络模型","author":"郑天祺","date":"2019-08-30T07:12:00.000Z","_content":"\n## 1、用户发送请求\n\n![](/img/TCPIP用户发送请求.png)\n\n## 2、服务器接收请求\n\n![](/img/TCPIP服务器接收请求.png)\n\n## 3、网络连接模型\n\n（《网络是怎么连接的》课本翻译）\n\n![](/img/网络连接模型.png)\n\n## 4、使用协议进行通讯\n\n​\tsocket是一种抽象层，应用程序通过它来发送和接收数据，就像应用程序打开一个文件句柄，把数据读写到磁盘上一样。主要的socket类型为：\n​\t1.流套接字（stream socket）-TCP\n​\t2.数据报文套接字（datagram socket）-UDP\n\n![](/img/使用协议进行通讯.png)\n\n## 5、Socket通讯模型\n\n![](/img/Socket通讯模型.png)\n\n6、TCP协议的通信过程\n\n​\t对于TCP通信来说，每个TCPSocket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。\n\n![](/img/TCP协议通讯过程.png)\n\n![](/img/TCP协议通讯过程1.png)\n\n![](/img/TCP协议通讯过程2.png)","source":"_posts/TCP-IP四层网络模型.md","raw":"title: TCP IP四层网络模型\nauthor: 郑天祺\ntags:\n  - TCP/IP\ncategories:\n  - 网络\ndate: 2019-08-30 15:12:00\n\n---\n\n## 1、用户发送请求\n\n![](/img/TCPIP用户发送请求.png)\n\n## 2、服务器接收请求\n\n![](/img/TCPIP服务器接收请求.png)\n\n## 3、网络连接模型\n\n（《网络是怎么连接的》课本翻译）\n\n![](/img/网络连接模型.png)\n\n## 4、使用协议进行通讯\n\n​\tsocket是一种抽象层，应用程序通过它来发送和接收数据，就像应用程序打开一个文件句柄，把数据读写到磁盘上一样。主要的socket类型为：\n​\t1.流套接字（stream socket）-TCP\n​\t2.数据报文套接字（datagram socket）-UDP\n\n![](/img/使用协议进行通讯.png)\n\n## 5、Socket通讯模型\n\n![](/img/Socket通讯模型.png)\n\n6、TCP协议的通信过程\n\n​\t对于TCP通信来说，每个TCPSocket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。\n\n![](/img/TCP协议通讯过程.png)\n\n![](/img/TCP协议通讯过程1.png)\n\n![](/img/TCP协议通讯过程2.png)","slug":"TCP-IP四层网络模型","published":1,"updated":"2019-10-15T12:19:39.272Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0s000svguqu5zttes6","content":"<h2>1、用户发送请求</h2>\n<p><img src=\"/img/TCPIP%E7%94%A8%E6%88%B7%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82.png\" alt></p>\n<h2>2、服务器接收请求</h2>\n<p><img src=\"/img/TCPIP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E6%94%B6%E8%AF%B7%E6%B1%82.png\" alt></p>\n<h2>3、网络连接模型</h2>\n<p>（《网络是怎么连接的》课本翻译）</p>\n<p><img src=\"/img/%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2>4、使用协议进行通讯</h2>\n<p>​\tsocket是一种抽象层，应用程序通过它来发送和接收数据，就像应用程序打开一个文件句柄，把数据读写到磁盘上一样。主要的socket类型为：\n​\t1.流套接字（stream socket）-TCP\n​\t2.数据报文套接字（datagram socket）-UDP</p>\n<p><img src=\"/img/%E4%BD%BF%E7%94%A8%E5%8D%8F%E8%AE%AE%E8%BF%9B%E8%A1%8C%E9%80%9A%E8%AE%AF.png\" alt></p>\n<h2>5、Socket通讯模型</h2>\n<p><img src=\"/img/Socket%E9%80%9A%E8%AE%AF%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<p>6、TCP协议的通信过程</p>\n<p>​\t对于TCP通信来说，每个TCPSocket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。</p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B.png\" alt></p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B1.png\" alt></p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B2.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、用户发送请求</h2>\n<p><img src=\"/img/TCPIP%E7%94%A8%E6%88%B7%E5%8F%91%E9%80%81%E8%AF%B7%E6%B1%82.png\" alt></p>\n<h2>2、服务器接收请求</h2>\n<p><img src=\"/img/TCPIP%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8E%A5%E6%94%B6%E8%AF%B7%E6%B1%82.png\" alt></p>\n<h2>3、网络连接模型</h2>\n<p>（《网络是怎么连接的》课本翻译）</p>\n<p><img src=\"/img/%E7%BD%91%E7%BB%9C%E8%BF%9E%E6%8E%A5%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2>4、使用协议进行通讯</h2>\n<p>​\tsocket是一种抽象层，应用程序通过它来发送和接收数据，就像应用程序打开一个文件句柄，把数据读写到磁盘上一样。主要的socket类型为：\n​\t1.流套接字（stream socket）-TCP\n​\t2.数据报文套接字（datagram socket）-UDP</p>\n<p><img src=\"/img/%E4%BD%BF%E7%94%A8%E5%8D%8F%E8%AE%AE%E8%BF%9B%E8%A1%8C%E9%80%9A%E8%AE%AF.png\" alt></p>\n<h2>5、Socket通讯模型</h2>\n<p><img src=\"/img/Socket%E9%80%9A%E8%AE%AF%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<p>6、TCP协议的通信过程</p>\n<p>​\t对于TCP通信来说，每个TCPSocket的内核中都有一个发送缓冲区和一个接收缓冲区，TCP的全双工的工作模式及TCP的滑动窗口就是依赖于这两个独立的Buffer和该Buffer的填充状态。</p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B.png\" alt></p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B1.png\" alt></p>\n<p><img src=\"/img/TCP%E5%8D%8F%E8%AE%AE%E9%80%9A%E8%AE%AF%E8%BF%87%E7%A8%8B2.png\" alt></p>\n"},{"title":"Yarn概述","author":"郑天祺","date":"2019-12-18T01:12:00.000Z","_content":"\n# 一、组件介绍\t\n\n​\tYarn的基本思想是将 JobTracker 的资源管理和作业的调度/监控两大主要职能拆分为两个独立的进程：\n\n​\t\ta. 一个全局的 Resource Manager \n\n​\t\tb. 每个应用对应的 Application Master（AM）\n\n​\tResource Manager 和每个节点上的 Node Manager（NM）组成了全新的通用操作系统，以分布式的方式管理应用程序。\n\n​\tResource Manager拥有为系统中所有应用分配资源的决定权。与之相关的是应用程序的Application Master，负责与Resource Manager协商资源，并与Node Manager协同工作来执行和监控任务。\n\n![image-20191218091838954](/img/Yarn.png)\n\n## （1）Resource Manager\n\n​\t\tYarn Resource Manager是一个纯粹的调度器，它负责整个系统的资源管理和分配。它本身主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。\n\n​\t\t调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的应用程序。\n\n注意：该调度器是一个“纯调度器”，他不再从事任何与具体应用程序相关的工作\n\n## （2）Application Master\n\n​\t\tApplication Master实际上是特定框架库的一个实例，负责与 Resource Manager协商资源，并和Resource Manager协同工作来   执行和监控Container，以及它们的资源消耗。\n\n## （3）Node Manager\n\n​\t\tNode Manager 是每个节点的框架代理。她负责启动应用的Container，监控Container的资源使用（包括CPU、内存、硬盘和网络带宽等），并把这些信息汇报给调度器。\n\n## （4）Resource Request 和 Container\n\n​\t\tYarn 被设计成可以允许应用程序（通过 Application Master） 以共享的、安全的，以及多用租户的方式使用集群的资源。它也会感知集群的网络拓扑，一边可以有效地调度，以及优化数据访问。\n\n# 二、Yarn工作流程\n\n​\t（1）客户端提交 MapReduce作业\n\n​\t（2）Yarn 资源管理器负责协调集群上计算资源的分配\n\n​\t（3）Yarn 节点管理器（Node Manager）负责启动和监视集群中机器上的计算容器（Container）\n\n​\t（4）应用程序的 Master 负责协调运行 MapReduce 作业的任务，它和MapReduce 任务在容器中运行，这些同期由资源管理器分配对节点管理器进行管理\n\n​\t（5）分布式文件系统（HDFS）用来与其他实体间共享作业文件","source":"_posts/Yarn概述.md","raw":"title: Yarn概述\nauthor: 郑天祺\ntags:\n\n  - HADOOP\ncategories:\n  - 大数据\ndate: 2019-12-18 09:12:00\n\n---\n\n# 一、组件介绍\t\n\n​\tYarn的基本思想是将 JobTracker 的资源管理和作业的调度/监控两大主要职能拆分为两个独立的进程：\n\n​\t\ta. 一个全局的 Resource Manager \n\n​\t\tb. 每个应用对应的 Application Master（AM）\n\n​\tResource Manager 和每个节点上的 Node Manager（NM）组成了全新的通用操作系统，以分布式的方式管理应用程序。\n\n​\tResource Manager拥有为系统中所有应用分配资源的决定权。与之相关的是应用程序的Application Master，负责与Resource Manager协商资源，并与Node Manager协同工作来执行和监控任务。\n\n![image-20191218091838954](/img/Yarn.png)\n\n## （1）Resource Manager\n\n​\t\tYarn Resource Manager是一个纯粹的调度器，它负责整个系统的资源管理和分配。它本身主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。\n\n​\t\t调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的应用程序。\n\n注意：该调度器是一个“纯调度器”，他不再从事任何与具体应用程序相关的工作\n\n## （2）Application Master\n\n​\t\tApplication Master实际上是特定框架库的一个实例，负责与 Resource Manager协商资源，并和Resource Manager协同工作来   执行和监控Container，以及它们的资源消耗。\n\n## （3）Node Manager\n\n​\t\tNode Manager 是每个节点的框架代理。她负责启动应用的Container，监控Container的资源使用（包括CPU、内存、硬盘和网络带宽等），并把这些信息汇报给调度器。\n\n## （4）Resource Request 和 Container\n\n​\t\tYarn 被设计成可以允许应用程序（通过 Application Master） 以共享的、安全的，以及多用租户的方式使用集群的资源。它也会感知集群的网络拓扑，一边可以有效地调度，以及优化数据访问。\n\n# 二、Yarn工作流程\n\n​\t（1）客户端提交 MapReduce作业\n\n​\t（2）Yarn 资源管理器负责协调集群上计算资源的分配\n\n​\t（3）Yarn 节点管理器（Node Manager）负责启动和监视集群中机器上的计算容器（Container）\n\n​\t（4）应用程序的 Master 负责协调运行 MapReduce 作业的任务，它和MapReduce 任务在容器中运行，这些同期由资源管理器分配对节点管理器进行管理\n\n​\t（5）分布式文件系统（HDFS）用来与其他实体间共享作业文件","slug":"Yarn概述","published":1,"updated":"2019-12-18T02:22:59.255Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0t000tvguqct2s13hr","content":"<h1>一、组件介绍</h1>\n<p>​\tYarn的基本思想是将 JobTracker 的资源管理和作业的调度/监控两大主要职能拆分为两个独立的进程：</p>\n<p>​\t\ta. 一个全局的 Resource Manager</p>\n<p>​\t\tb. 每个应用对应的 Application Master（AM）</p>\n<p>​\tResource Manager 和每个节点上的 Node Manager（NM）组成了全新的通用操作系统，以分布式的方式管理应用程序。</p>\n<p>​\tResource Manager拥有为系统中所有应用分配资源的决定权。与之相关的是应用程序的Application Master，负责与Resource Manager协商资源，并与Node Manager协同工作来执行和监控任务。</p>\n<p><img src=\"/img/Yarn.png\" alt=\"image-20191218091838954\"></p>\n<h2>（1）Resource Manager</h2>\n<p>​\t\tYarn Resource Manager是一个纯粹的调度器，它负责整个系统的资源管理和分配。它本身主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。</p>\n<p>​\t\t调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的应用程序。</p>\n<p>注意：该调度器是一个“纯调度器”，他不再从事任何与具体应用程序相关的工作</p>\n<h2>（2）Application Master</h2>\n<p>​\t\tApplication Master实际上是特定框架库的一个实例，负责与 Resource Manager协商资源，并和Resource Manager协同工作来   执行和监控Container，以及它们的资源消耗。</p>\n<h2>（3）Node Manager</h2>\n<p>​\t\tNode Manager 是每个节点的框架代理。她负责启动应用的Container，监控Container的资源使用（包括CPU、内存、硬盘和网络带宽等），并把这些信息汇报给调度器。</p>\n<h2>（4）Resource Request 和 Container</h2>\n<p>​\t\tYarn 被设计成可以允许应用程序（通过 Application Master） 以共享的、安全的，以及多用租户的方式使用集群的资源。它也会感知集群的网络拓扑，一边可以有效地调度，以及优化数据访问。</p>\n<h1>二、Yarn工作流程</h1>\n<p>​\t（1）客户端提交 MapReduce作业</p>\n<p>​\t（2）Yarn 资源管理器负责协调集群上计算资源的分配</p>\n<p>​\t（3）Yarn 节点管理器（Node Manager）负责启动和监视集群中机器上的计算容器（Container）</p>\n<p>​\t（4）应用程序的 Master 负责协调运行 MapReduce 作业的任务，它和MapReduce 任务在容器中运行，这些同期由资源管理器分配对节点管理器进行管理</p>\n<p>​\t（5）分布式文件系统（HDFS）用来与其他实体间共享作业文件</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、组件介绍</h1>\n<p>​\tYarn的基本思想是将 JobTracker 的资源管理和作业的调度/监控两大主要职能拆分为两个独立的进程：</p>\n<p>​\t\ta. 一个全局的 Resource Manager</p>\n<p>​\t\tb. 每个应用对应的 Application Master（AM）</p>\n<p>​\tResource Manager 和每个节点上的 Node Manager（NM）组成了全新的通用操作系统，以分布式的方式管理应用程序。</p>\n<p>​\tResource Manager拥有为系统中所有应用分配资源的决定权。与之相关的是应用程序的Application Master，负责与Resource Manager协商资源，并与Node Manager协同工作来执行和监控任务。</p>\n<p><img src=\"/img/Yarn.png\" alt=\"image-20191218091838954\"></p>\n<h2>（1）Resource Manager</h2>\n<p>​\t\tYarn Resource Manager是一个纯粹的调度器，它负责整个系统的资源管理和分配。它本身主要由两个组件构成：调度器（Scheduler）和应用程序管理器（Applications Manager，AM）。</p>\n<p>​\t\t调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的应用程序。</p>\n<p>注意：该调度器是一个“纯调度器”，他不再从事任何与具体应用程序相关的工作</p>\n<h2>（2）Application Master</h2>\n<p>​\t\tApplication Master实际上是特定框架库的一个实例，负责与 Resource Manager协商资源，并和Resource Manager协同工作来   执行和监控Container，以及它们的资源消耗。</p>\n<h2>（3）Node Manager</h2>\n<p>​\t\tNode Manager 是每个节点的框架代理。她负责启动应用的Container，监控Container的资源使用（包括CPU、内存、硬盘和网络带宽等），并把这些信息汇报给调度器。</p>\n<h2>（4）Resource Request 和 Container</h2>\n<p>​\t\tYarn 被设计成可以允许应用程序（通过 Application Master） 以共享的、安全的，以及多用租户的方式使用集群的资源。它也会感知集群的网络拓扑，一边可以有效地调度，以及优化数据访问。</p>\n<h1>二、Yarn工作流程</h1>\n<p>​\t（1）客户端提交 MapReduce作业</p>\n<p>​\t（2）Yarn 资源管理器负责协调集群上计算资源的分配</p>\n<p>​\t（3）Yarn 节点管理器（Node Manager）负责启动和监视集群中机器上的计算容器（Container）</p>\n<p>​\t（4）应用程序的 Master 负责协调运行 MapReduce 作业的任务，它和MapReduce 任务在容器中运行，这些同期由资源管理器分配对节点管理器进行管理</p>\n<p>​\t（5）分布式文件系统（HDFS）用来与其他实体间共享作业文件</p>\n"},{"title":"WordCount简析","author":"郑天祺","date":"2019-12-18T03:57:00.000Z","_content":"\n```java\npackage org.apache.hadoop.examples;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n    /**\n     * map 阶段\n     * <p>\n     * Object 此处为文本数据的起始位置的偏移量;可以直接使用 Long 类型，源码此处使用Object做了泛化\n     * Text 输入< key, value >对的 value 值，此处为一段具体的文本数据\n     * Text 输出< key, value >对的 key 值，此处为一个单词\n     * IntWritable：输出< key, value >对的 value 值，此处固定为 1\n     */\n    public static class TokenizerMapper\n            extends Mapper<Object, Text, Text, IntWritable> {\n        // IntWritable 是 Hadoop 对 Integer 的进一步封装，使其可以进行序列化。\n        private final static IntWritable one = new IntWritable(1);\n        // map 端的任务是对输入数据按照单词进行切分，每个单词为 Text 类型。\n        private Text word = new Text();\n\n        /**\n         * @param key     输入数据在原数据中的偏移量\n         * @param value   具体的数据数据，此处为一段字符串\n         * @param context 用于暂时存储 map() 处理后的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void map(Object key, Text value, Context context\n        ) throws IOException, InterruptedException {\n            // 字符串分割，也可以用 apache.common.lang3的 StringUtils.split\n            StringTokenizer itr = new StringTokenizer(value.toString());\n            // map 输出的 key value\n            while (itr.hasMoreTokens()) {\n                word.set(itr.nextToken());\n                context.write(word, one);\n            }\n        }\n    }\n\n    /**\n     * reduce阶段，map的输出是reduce的输入\n     * Text：输入< key, value >对的key值，此处为一个单词\n     * IntWritable：输入< key, value >对的value值\n     * Text：输出< key, value >对的key值，此处为一个单词\n     * IntWritable：输出< key, value >对，此处为相同单词词频累加之后的值。实际上就是一个数字\n     */\n    public static class IntSumReducer\n            extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n\n        /**\n         * @param key     输入< key, value >对的key值，也就是一个单词\n         * @param values  一系列的key值相同的序列化结构\n         * @param context 临时存储reduce端产生的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void reduce(Text key, Iterable<IntWritable> values,\n                           Context context\n        ) throws IOException, InterruptedException {\n            // 将相同的key进行合并，value累加\n            int sum = 0;\n            for (IntWritable val : values) {\n                sum += val.get();\n            }\n            result.set(sum);\n            // 单词和它的数目\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n        if (otherArgs.length < 2) {\n            System.err.println(\"Usage: wordcount <in> [<in>...] <out>\");\n            System.exit(2);\n        }\n        // main函数调用Job类及逆行MapReduce 作业的初始化\n        Job job = Job.getInstance(conf, \"word count\");\n        job.setJarByClass(WordCount.class);\n        // 设置 job 的 map 阶段的执行类\n        job.setMapperClass(TokenizerMapper.class);\n        // 设置 job 的 combine 阶段的执行类\n        job.setCombinerClass(IntSumReducer.class);\n        // 设置 job 的 reduce 阶段的执行类\n        job.setReducerClass(IntSumReducer.class);\n        // map的输出 key、value 映射\n        job.setOutputKeyClass(Text.class);\n        // 设置程序的输出的value值的类型\n        job.setOutputValueClass(IntWritable.class);\n        // 调用 addInputFormat 设置输入路径\n        for (int i = 0; i < otherArgs.length - 1; ++i) {\n            // Path 是绝对路径\n            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));\n        }\n        // 输入文件 和 输出文件的路径\n        FileOutputFormat.setOutputPath(job,\n                new Path(otherArgs[otherArgs.length - 1]));\n        // 等待任务完成，任务完成之后退出程序\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n","source":"_posts/WordCount简析.md","raw":"title: WordCount简析\nauthor: 郑天祺\ntags:\n  - HADOOP\ncategories:\n  - 大数据\ndate: 2019-12-18 11:57:00\n\n---\n\n```java\npackage org.apache.hadoop.examples;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n    /**\n     * map 阶段\n     * <p>\n     * Object 此处为文本数据的起始位置的偏移量;可以直接使用 Long 类型，源码此处使用Object做了泛化\n     * Text 输入< key, value >对的 value 值，此处为一段具体的文本数据\n     * Text 输出< key, value >对的 key 值，此处为一个单词\n     * IntWritable：输出< key, value >对的 value 值，此处固定为 1\n     */\n    public static class TokenizerMapper\n            extends Mapper<Object, Text, Text, IntWritable> {\n        // IntWritable 是 Hadoop 对 Integer 的进一步封装，使其可以进行序列化。\n        private final static IntWritable one = new IntWritable(1);\n        // map 端的任务是对输入数据按照单词进行切分，每个单词为 Text 类型。\n        private Text word = new Text();\n\n        /**\n         * @param key     输入数据在原数据中的偏移量\n         * @param value   具体的数据数据，此处为一段字符串\n         * @param context 用于暂时存储 map() 处理后的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void map(Object key, Text value, Context context\n        ) throws IOException, InterruptedException {\n            // 字符串分割，也可以用 apache.common.lang3的 StringUtils.split\n            StringTokenizer itr = new StringTokenizer(value.toString());\n            // map 输出的 key value\n            while (itr.hasMoreTokens()) {\n                word.set(itr.nextToken());\n                context.write(word, one);\n            }\n        }\n    }\n\n    /**\n     * reduce阶段，map的输出是reduce的输入\n     * Text：输入< key, value >对的key值，此处为一个单词\n     * IntWritable：输入< key, value >对的value值\n     * Text：输出< key, value >对的key值，此处为一个单词\n     * IntWritable：输出< key, value >对，此处为相同单词词频累加之后的值。实际上就是一个数字\n     */\n    public static class IntSumReducer\n            extends Reducer<Text, IntWritable, Text, IntWritable> {\n        private IntWritable result = new IntWritable();\n\n        /**\n         * @param key     输入< key, value >对的key值，也就是一个单词\n         * @param values  一系列的key值相同的序列化结构\n         * @param context 临时存储reduce端产生的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void reduce(Text key, Iterable<IntWritable> values,\n                           Context context\n        ) throws IOException, InterruptedException {\n            // 将相同的key进行合并，value累加\n            int sum = 0;\n            for (IntWritable val : values) {\n                sum += val.get();\n            }\n            result.set(sum);\n            // 单词和它的数目\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n        if (otherArgs.length < 2) {\n            System.err.println(\"Usage: wordcount <in> [<in>...] <out>\");\n            System.exit(2);\n        }\n        // main函数调用Job类及逆行MapReduce 作业的初始化\n        Job job = Job.getInstance(conf, \"word count\");\n        job.setJarByClass(WordCount.class);\n        // 设置 job 的 map 阶段的执行类\n        job.setMapperClass(TokenizerMapper.class);\n        // 设置 job 的 combine 阶段的执行类\n        job.setCombinerClass(IntSumReducer.class);\n        // 设置 job 的 reduce 阶段的执行类\n        job.setReducerClass(IntSumReducer.class);\n        // map的输出 key、value 映射\n        job.setOutputKeyClass(Text.class);\n        // 设置程序的输出的value值的类型\n        job.setOutputValueClass(IntWritable.class);\n        // 调用 addInputFormat 设置输入路径\n        for (int i = 0; i < otherArgs.length - 1; ++i) {\n            // Path 是绝对路径\n            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));\n        }\n        // 输入文件 和 输出文件的路径\n        FileOutputFormat.setOutputPath(job,\n                new Path(otherArgs[otherArgs.length - 1]));\n        // 等待任务完成，任务完成之后退出程序\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n```\n\n","slug":"WordCount简析","published":1,"updated":"2019-12-18T03:59:10.021Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0w000xvguqp7ozx9k9","content":"<pre><code class=\"language-java\">package org.apache.hadoop.examples;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n    /**\n     * map 阶段\n     * &lt;p&gt;\n     * Object 此处为文本数据的起始位置的偏移量;可以直接使用 Long 类型，源码此处使用Object做了泛化\n     * Text 输入&lt; key, value &gt;对的 value 值，此处为一段具体的文本数据\n     * Text 输出&lt; key, value &gt;对的 key 值，此处为一个单词\n     * IntWritable：输出&lt; key, value &gt;对的 value 值，此处固定为 1\n     */\n    public static class TokenizerMapper\n            extends Mapper&lt;Object, Text, Text, IntWritable&gt; {\n        // IntWritable 是 Hadoop 对 Integer 的进一步封装，使其可以进行序列化。\n        private final static IntWritable one = new IntWritable(1);\n        // map 端的任务是对输入数据按照单词进行切分，每个单词为 Text 类型。\n        private Text word = new Text();\n\n        /**\n         * @param key     输入数据在原数据中的偏移量\n         * @param value   具体的数据数据，此处为一段字符串\n         * @param context 用于暂时存储 map() 处理后的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void map(Object key, Text value, Context context\n        ) throws IOException, InterruptedException {\n            // 字符串分割，也可以用 apache.common.lang3的 StringUtils.split\n            StringTokenizer itr = new StringTokenizer(value.toString());\n            // map 输出的 key value\n            while (itr.hasMoreTokens()) {\n                word.set(itr.nextToken());\n                context.write(word, one);\n            }\n        }\n    }\n\n    /**\n     * reduce阶段，map的输出是reduce的输入\n     * Text：输入&lt; key, value &gt;对的key值，此处为一个单词\n     * IntWritable：输入&lt; key, value &gt;对的value值\n     * Text：输出&lt; key, value &gt;对的key值，此处为一个单词\n     * IntWritable：输出&lt; key, value &gt;对，此处为相同单词词频累加之后的值。实际上就是一个数字\n     */\n    public static class IntSumReducer\n            extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {\n        private IntWritable result = new IntWritable();\n\n        /**\n         * @param key     输入&lt; key, value &gt;对的key值，也就是一个单词\n         * @param values  一系列的key值相同的序列化结构\n         * @param context 临时存储reduce端产生的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void reduce(Text key, Iterable&lt;IntWritable&gt; values,\n                           Context context\n        ) throws IOException, InterruptedException {\n            // 将相同的key进行合并，value累加\n            int sum = 0;\n            for (IntWritable val : values) {\n                sum += val.get();\n            }\n            result.set(sum);\n            // 单词和它的数目\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n        if (otherArgs.length &lt; 2) {\n            System.err.println(&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\n            System.exit(2);\n        }\n        // main函数调用Job类及逆行MapReduce 作业的初始化\n        Job job = Job.getInstance(conf, &quot;word count&quot;);\n        job.setJarByClass(WordCount.class);\n        // 设置 job 的 map 阶段的执行类\n        job.setMapperClass(TokenizerMapper.class);\n        // 设置 job 的 combine 阶段的执行类\n        job.setCombinerClass(IntSumReducer.class);\n        // 设置 job 的 reduce 阶段的执行类\n        job.setReducerClass(IntSumReducer.class);\n        // map的输出 key、value 映射\n        job.setOutputKeyClass(Text.class);\n        // 设置程序的输出的value值的类型\n        job.setOutputValueClass(IntWritable.class);\n        // 调用 addInputFormat 设置输入路径\n        for (int i = 0; i &lt; otherArgs.length - 1; ++i) {\n            // Path 是绝对路径\n            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));\n        }\n        // 输入文件 和 输出文件的路径\n        FileOutputFormat.setOutputPath(job,\n                new Path(otherArgs[otherArgs.length - 1]));\n        // 等待任务完成，任务完成之后退出程序\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<pre><code class=\"language-java\">package org.apache.hadoop.examples;\n\nimport java.io.IOException;\nimport java.util.StringTokenizer;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.io.IntWritable;\nimport org.apache.hadoop.io.Text;\nimport org.apache.hadoop.mapreduce.Job;\nimport org.apache.hadoop.mapreduce.Mapper;\nimport org.apache.hadoop.mapreduce.Reducer;\nimport org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\nimport org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\nimport org.apache.hadoop.util.GenericOptionsParser;\n\npublic class WordCount {\n    /**\n     * map 阶段\n     * &lt;p&gt;\n     * Object 此处为文本数据的起始位置的偏移量;可以直接使用 Long 类型，源码此处使用Object做了泛化\n     * Text 输入&lt; key, value &gt;对的 value 值，此处为一段具体的文本数据\n     * Text 输出&lt; key, value &gt;对的 key 值，此处为一个单词\n     * IntWritable：输出&lt; key, value &gt;对的 value 值，此处固定为 1\n     */\n    public static class TokenizerMapper\n            extends Mapper&lt;Object, Text, Text, IntWritable&gt; {\n        // IntWritable 是 Hadoop 对 Integer 的进一步封装，使其可以进行序列化。\n        private final static IntWritable one = new IntWritable(1);\n        // map 端的任务是对输入数据按照单词进行切分，每个单词为 Text 类型。\n        private Text word = new Text();\n\n        /**\n         * @param key     输入数据在原数据中的偏移量\n         * @param value   具体的数据数据，此处为一段字符串\n         * @param context 用于暂时存储 map() 处理后的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void map(Object key, Text value, Context context\n        ) throws IOException, InterruptedException {\n            // 字符串分割，也可以用 apache.common.lang3的 StringUtils.split\n            StringTokenizer itr = new StringTokenizer(value.toString());\n            // map 输出的 key value\n            while (itr.hasMoreTokens()) {\n                word.set(itr.nextToken());\n                context.write(word, one);\n            }\n        }\n    }\n\n    /**\n     * reduce阶段，map的输出是reduce的输入\n     * Text：输入&lt; key, value &gt;对的key值，此处为一个单词\n     * IntWritable：输入&lt; key, value &gt;对的value值\n     * Text：输出&lt; key, value &gt;对的key值，此处为一个单词\n     * IntWritable：输出&lt; key, value &gt;对，此处为相同单词词频累加之后的值。实际上就是一个数字\n     */\n    public static class IntSumReducer\n            extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {\n        private IntWritable result = new IntWritable();\n\n        /**\n         * @param key     输入&lt; key, value &gt;对的key值，也就是一个单词\n         * @param values  一系列的key值相同的序列化结构\n         * @param context 临时存储reduce端产生的结果\n         * @throws IOException          IO异常\n         * @throws InterruptedException 中断异常\n         */\n        @Override\n        public void reduce(Text key, Iterable&lt;IntWritable&gt; values,\n                           Context context\n        ) throws IOException, InterruptedException {\n            // 将相同的key进行合并，value累加\n            int sum = 0;\n            for (IntWritable val : values) {\n                sum += val.get();\n            }\n            result.set(sum);\n            // 单词和它的数目\n            context.write(key, result);\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        Configuration conf = new Configuration();\n        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n        if (otherArgs.length &lt; 2) {\n            System.err.println(&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\n            System.exit(2);\n        }\n        // main函数调用Job类及逆行MapReduce 作业的初始化\n        Job job = Job.getInstance(conf, &quot;word count&quot;);\n        job.setJarByClass(WordCount.class);\n        // 设置 job 的 map 阶段的执行类\n        job.setMapperClass(TokenizerMapper.class);\n        // 设置 job 的 combine 阶段的执行类\n        job.setCombinerClass(IntSumReducer.class);\n        // 设置 job 的 reduce 阶段的执行类\n        job.setReducerClass(IntSumReducer.class);\n        // map的输出 key、value 映射\n        job.setOutputKeyClass(Text.class);\n        // 设置程序的输出的value值的类型\n        job.setOutputValueClass(IntWritable.class);\n        // 调用 addInputFormat 设置输入路径\n        for (int i = 0; i &lt; otherArgs.length - 1; ++i) {\n            // Path 是绝对路径\n            FileInputFormat.addInputPath(job, new Path(otherArgs[i]));\n        }\n        // 输入文件 和 输出文件的路径\n        FileOutputFormat.setOutputPath(job,\n                new Path(otherArgs[otherArgs.length - 1]));\n        // 等待任务完成，任务完成之后退出程序\n        System.exit(job.waitForCompletion(true) ? 0 : 1);\n    }\n}\n\n</code></pre>\n"},{"title":"maven梳理","author":"郑天祺","date":"2019-08-28T09:01:00.000Z","_content":"# Maven使用\n\n## 1.两个操作：\n\n###    (1) 参数设置：\n\n​     Linux：在~/.bash_profile文件中添加\n\n```java\nexport MAVEN_OPTS=\"-Xms512m -Xmx1024m\"\n```\n\n​    （此设置是为了maven执行java时分配给大点的内存，解决容易引起maven导包或插件时卡顿）\n​     Windows：如下图\n​\t\t<img src=\"/img/maven配置.png\">\n​        \n\n### \t(2) 用户配置：\n\n把MAVEN_HOME/conf/seettings.xml  cp 到 ~/.m2/下，在.m2下的settings.xml中所作的配置就是用户级别的配置，而直接编辑MAVEN_HOME/conf/seettings.xml所作的配置是全局的配置\n\n```java\n上传到私服的流程：\n  a.  加入打包插件\n  b. mvn clean package // 加上clean 会清空target，然后再生成新的包。。。\n  c.mvn source:jar  // 生成源码包\n  d.mvn deploy // 上传私服，别忘升级版本哦~~~\n2.idea和eclipse导入时不同： \nidea是project下的module  eclipse是workspace下的project\n  idea导入maven项目  https://blog.csdn.net/weixin_37909363/article/details/80915509  \n```\n## 2. maven的命令：\n\n```java\nmaven常用命令\n\n创建maven项目：mvn archetype:create\n指定 group： -DgroupId=packageName\n指定 artifact：-DartifactId=projectName\n创建web项目：-DarchetypeArtifactId=maven-archetype-webapp \n创建maven项目：mvn archetype:generate\n验证项目是否正确：mvn validate\nmaven 打包：mvn package\n只打jar包：mvn jar:jar\n生成源码jar包：mvn source:jar\n产生应用需要的任何额外的源代码：mvn generate-sources\n编译源代码： mvn compile\n编译测试代码：mvn test-compile\n运行测试：mvn test\n运行检查：mvn verify\n清理maven项目：mvn clean  该操作会清空当前目录的target文件夹\n生成eclipse项目：mvn eclipse:eclipse\n清理eclipse配置：mvn eclipse:clean\n生成idea项目：mvn idea:idea\n安装项目到本地仓库：mvn install\n发布项目到远程仓库：mvn:deploy\n在集成测试可以运行的环境中处理和发布包：mvn integration-test\n显示maven依赖树：mvn dependency:tree\n显示maven依赖列表：mvn dependency:list\n下载依赖包的源码：mvn dependency:sources\n安装本地jar到本地仓库：mvn install:install-file -DgroupId=packageName -DartifactId=projectName -Dversion=version -Dpackaging=jar -Dfile=path\n    WEB\n启动tomcat：mvn tomcat:run\n启动jetty：mvn jetty:run\n运行打包部署：mvn tomcat:deploy\n撤销部署：mvn tomcat:undeploy\n启动web应用：mvn tomcat:start\n停止web应用：mvn tomcat:stop\n重新部署：mvn tomcat:redeploy\n部署展开的war文件：mvn war:exploded tomcat:exploded\n    maven 命令的格式为 mvn [plugin-name]:[goal-name]，可以接受的参数如下。\n-D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试；\n-P 指定 Profile 配置，可以用于区分环境；\n-e 显示maven运行出错的信息；\n-o 离线执行命令,即不去远程仓库更新包；\n-X 显示maven允许的debug信息；\n-U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。\n```\n\n","source":"_posts/maven梳理.md","raw":"title: maven梳理\ntags:\n\n  - maven\ncategories:\n  - 软件管理\nauthor: 郑天祺\ndate: 2019-08-28 17:01:00\n---\n# Maven使用\n\n## 1.两个操作：\n\n###    (1) 参数设置：\n\n​     Linux：在~/.bash_profile文件中添加\n\n```java\nexport MAVEN_OPTS=\"-Xms512m -Xmx1024m\"\n```\n\n​    （此设置是为了maven执行java时分配给大点的内存，解决容易引起maven导包或插件时卡顿）\n​     Windows：如下图\n​\t\t<img src=\"/img/maven配置.png\">\n​        \n\n### \t(2) 用户配置：\n\n把MAVEN_HOME/conf/seettings.xml  cp 到 ~/.m2/下，在.m2下的settings.xml中所作的配置就是用户级别的配置，而直接编辑MAVEN_HOME/conf/seettings.xml所作的配置是全局的配置\n\n```java\n上传到私服的流程：\n  a.  加入打包插件\n  b. mvn clean package // 加上clean 会清空target，然后再生成新的包。。。\n  c.mvn source:jar  // 生成源码包\n  d.mvn deploy // 上传私服，别忘升级版本哦~~~\n2.idea和eclipse导入时不同： \nidea是project下的module  eclipse是workspace下的project\n  idea导入maven项目  https://blog.csdn.net/weixin_37909363/article/details/80915509  \n```\n## 2. maven的命令：\n\n```java\nmaven常用命令\n\n创建maven项目：mvn archetype:create\n指定 group： -DgroupId=packageName\n指定 artifact：-DartifactId=projectName\n创建web项目：-DarchetypeArtifactId=maven-archetype-webapp \n创建maven项目：mvn archetype:generate\n验证项目是否正确：mvn validate\nmaven 打包：mvn package\n只打jar包：mvn jar:jar\n生成源码jar包：mvn source:jar\n产生应用需要的任何额外的源代码：mvn generate-sources\n编译源代码： mvn compile\n编译测试代码：mvn test-compile\n运行测试：mvn test\n运行检查：mvn verify\n清理maven项目：mvn clean  该操作会清空当前目录的target文件夹\n生成eclipse项目：mvn eclipse:eclipse\n清理eclipse配置：mvn eclipse:clean\n生成idea项目：mvn idea:idea\n安装项目到本地仓库：mvn install\n发布项目到远程仓库：mvn:deploy\n在集成测试可以运行的环境中处理和发布包：mvn integration-test\n显示maven依赖树：mvn dependency:tree\n显示maven依赖列表：mvn dependency:list\n下载依赖包的源码：mvn dependency:sources\n安装本地jar到本地仓库：mvn install:install-file -DgroupId=packageName -DartifactId=projectName -Dversion=version -Dpackaging=jar -Dfile=path\n    WEB\n启动tomcat：mvn tomcat:run\n启动jetty：mvn jetty:run\n运行打包部署：mvn tomcat:deploy\n撤销部署：mvn tomcat:undeploy\n启动web应用：mvn tomcat:start\n停止web应用：mvn tomcat:stop\n重新部署：mvn tomcat:redeploy\n部署展开的war文件：mvn war:exploded tomcat:exploded\n    maven 命令的格式为 mvn [plugin-name]:[goal-name]，可以接受的参数如下。\n-D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试；\n-P 指定 Profile 配置，可以用于区分环境；\n-e 显示maven运行出错的信息；\n-o 离线执行命令,即不去远程仓库更新包；\n-X 显示maven允许的debug信息；\n-U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。\n```\n\n","slug":"maven梳理","published":1,"updated":"2019-10-15T12:19:35.470Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0x000zvguqx2u3hlju","content":"<h1>Maven使用</h1>\n<h2>1.两个操作：</h2>\n<h3>(1) 参数设置：</h3>\n<p>​     Linux：在~/.bash_profile文件中添加</p>\n<pre><code class=\"language-java\">export MAVEN_OPTS=&quot;-Xms512m -Xmx1024m&quot;\n</code></pre>\n<p>​    （此设置是为了maven执行java时分配给大点的内存，解决容易引起maven导包或插件时卡顿）\n​     Windows：如下图\n​\t\t<img src=\"/img/maven配置.png\">\n​</p>\n<h3>(2) 用户配置：</h3>\n<p>把MAVEN_HOME/conf/seettings.xml  cp 到 ~/.m2/下，在.m2下的settings.xml中所作的配置就是用户级别的配置，而直接编辑MAVEN_HOME/conf/seettings.xml所作的配置是全局的配置</p>\n<pre><code class=\"language-java\">上传到私服的流程：\n  a.  加入打包插件\n  b. mvn clean package // 加上clean 会清空target，然后再生成新的包。。。\n  c.mvn source:jar  // 生成源码包\n  d.mvn deploy // 上传私服，别忘升级版本哦~~~\n2.idea和eclipse导入时不同： \nidea是project下的module  eclipse是workspace下的project\n  idea导入maven项目  https://blog.csdn.net/weixin_37909363/article/details/80915509  \n</code></pre>\n<h2>2. maven的命令：</h2>\n<pre><code class=\"language-java\">maven常用命令\n\n创建maven项目：mvn archetype:create\n指定 group： -DgroupId=packageName\n指定 artifact：-DartifactId=projectName\n创建web项目：-DarchetypeArtifactId=maven-archetype-webapp \n创建maven项目：mvn archetype:generate\n验证项目是否正确：mvn validate\nmaven 打包：mvn package\n只打jar包：mvn jar:jar\n生成源码jar包：mvn source:jar\n产生应用需要的任何额外的源代码：mvn generate-sources\n编译源代码： mvn compile\n编译测试代码：mvn test-compile\n运行测试：mvn test\n运行检查：mvn verify\n清理maven项目：mvn clean  该操作会清空当前目录的target文件夹\n生成eclipse项目：mvn eclipse:eclipse\n清理eclipse配置：mvn eclipse:clean\n生成idea项目：mvn idea:idea\n安装项目到本地仓库：mvn install\n发布项目到远程仓库：mvn:deploy\n在集成测试可以运行的环境中处理和发布包：mvn integration-test\n显示maven依赖树：mvn dependency:tree\n显示maven依赖列表：mvn dependency:list\n下载依赖包的源码：mvn dependency:sources\n安装本地jar到本地仓库：mvn install:install-file -DgroupId=packageName -DartifactId=projectName -Dversion=version -Dpackaging=jar -Dfile=path\n    WEB\n启动tomcat：mvn tomcat:run\n启动jetty：mvn jetty:run\n运行打包部署：mvn tomcat:deploy\n撤销部署：mvn tomcat:undeploy\n启动web应用：mvn tomcat:start\n停止web应用：mvn tomcat:stop\n重新部署：mvn tomcat:redeploy\n部署展开的war文件：mvn war:exploded tomcat:exploded\n    maven 命令的格式为 mvn [plugin-name]:[goal-name]，可以接受的参数如下。\n-D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试；\n-P 指定 Profile 配置，可以用于区分环境；\n-e 显示maven运行出错的信息；\n-o 离线执行命令,即不去远程仓库更新包；\n-X 显示maven允许的debug信息；\n-U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>Maven使用</h1>\n<h2>1.两个操作：</h2>\n<h3>(1) 参数设置：</h3>\n<p>​     Linux：在~/.bash_profile文件中添加</p>\n<pre><code class=\"language-java\">export MAVEN_OPTS=&quot;-Xms512m -Xmx1024m&quot;\n</code></pre>\n<p>​    （此设置是为了maven执行java时分配给大点的内存，解决容易引起maven导包或插件时卡顿）\n​     Windows：如下图\n​\t\t<img src=\"/img/maven配置.png\">\n​</p>\n<h3>(2) 用户配置：</h3>\n<p>把MAVEN_HOME/conf/seettings.xml  cp 到 ~/.m2/下，在.m2下的settings.xml中所作的配置就是用户级别的配置，而直接编辑MAVEN_HOME/conf/seettings.xml所作的配置是全局的配置</p>\n<pre><code class=\"language-java\">上传到私服的流程：\n  a.  加入打包插件\n  b. mvn clean package // 加上clean 会清空target，然后再生成新的包。。。\n  c.mvn source:jar  // 生成源码包\n  d.mvn deploy // 上传私服，别忘升级版本哦~~~\n2.idea和eclipse导入时不同： \nidea是project下的module  eclipse是workspace下的project\n  idea导入maven项目  https://blog.csdn.net/weixin_37909363/article/details/80915509  \n</code></pre>\n<h2>2. maven的命令：</h2>\n<pre><code class=\"language-java\">maven常用命令\n\n创建maven项目：mvn archetype:create\n指定 group： -DgroupId=packageName\n指定 artifact：-DartifactId=projectName\n创建web项目：-DarchetypeArtifactId=maven-archetype-webapp \n创建maven项目：mvn archetype:generate\n验证项目是否正确：mvn validate\nmaven 打包：mvn package\n只打jar包：mvn jar:jar\n生成源码jar包：mvn source:jar\n产生应用需要的任何额外的源代码：mvn generate-sources\n编译源代码： mvn compile\n编译测试代码：mvn test-compile\n运行测试：mvn test\n运行检查：mvn verify\n清理maven项目：mvn clean  该操作会清空当前目录的target文件夹\n生成eclipse项目：mvn eclipse:eclipse\n清理eclipse配置：mvn eclipse:clean\n生成idea项目：mvn idea:idea\n安装项目到本地仓库：mvn install\n发布项目到远程仓库：mvn:deploy\n在集成测试可以运行的环境中处理和发布包：mvn integration-test\n显示maven依赖树：mvn dependency:tree\n显示maven依赖列表：mvn dependency:list\n下载依赖包的源码：mvn dependency:sources\n安装本地jar到本地仓库：mvn install:install-file -DgroupId=packageName -DartifactId=projectName -Dversion=version -Dpackaging=jar -Dfile=path\n    WEB\n启动tomcat：mvn tomcat:run\n启动jetty：mvn jetty:run\n运行打包部署：mvn tomcat:deploy\n撤销部署：mvn tomcat:undeploy\n启动web应用：mvn tomcat:start\n停止web应用：mvn tomcat:stop\n重新部署：mvn tomcat:redeploy\n部署展开的war文件：mvn war:exploded tomcat:exploded\n    maven 命令的格式为 mvn [plugin-name]:[goal-name]，可以接受的参数如下。\n-D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试；\n-P 指定 Profile 配置，可以用于区分环境；\n-e 显示maven运行出错的信息；\n-o 离线执行命令,即不去远程仓库更新包；\n-X 显示maven允许的debug信息；\n-U 强制去远程更新snapshot的插件或依赖，默认每天只更新一次。\n</code></pre>\n"},{"title":"mysql排序","author":"郑天祺","date":"2019-11-20T12:35:00.000Z","_content":"\n\n\n# 1、正常的数字排序\n\n![image-20191120204232822](/img/mysql排序1.png)\n\n# 2、排序中文时\n\n，就是出现问题\n\n![image-20191120204352223](/img/mysql排序2.png)\n\n​\t这是因为我们在选取排序规则时，选择的不是gbk。所以想要正确的排序，需要我们了解我们选取字段的排序规则。\n\n# 3、现在改成gbk_chinese_ci\n\n，ci是不区分大小写\n\n![image-20191120204623652](/img/mysql排序3.png)\n\n这样的话，结果：\n\n![image-20191120204719806](/img/mysql排序4.png)\n\n# 4、英中排序\n\n![image-20191120205015864](/img/mysql排序5.png)\n\n​\t这个也是gbk的排序效果，但是我们想做到中英混搭的效果，我认为可以自已在mysql编译前放进自己的排序规则，\n\n# 5、中文混搭\n\n先看一下效果：\n\n![image-20191120205433980](/img/mysql排序6.png)\n\n我们sql用引入了一个函数GET_FIRST_PINYIN_CHAR\n\n```java\nSELECT\n\ta.id,\n\ta.username \nFROM\n\ttest AS a \nORDER BY\n\tGET_FIRST_PINYIN_CHAR(a.username)\n```\n\n这个函数需要在创建表之后定义，如下：\n\n```java\nDROP FUNCTION IF EXISTS `GET_FIRST_PINYIN_CHAR`;\nCREATE FUNCTION `GET_FIRST_PINYIN_CHAR`(PARAM VARCHAR(255)) RETURNS VARCHAR(2) CHARSET utf8\nBEGIN\n    DECLARE V_RETURN VARCHAR(255);\n    DECLARE V_FIRST_CHAR VARCHAR(2);\n    SET V_FIRST_CHAR = UPPER(LEFT(PARAM,1));\n  SET V_RETURN = V_FIRST_CHAR;\n    IF LENGTH( V_FIRST_CHAR)<>CHARACTER_LENGTH(V_FIRST_CHAR) THEN\n    SET V_RETURN = ELT(INTERVAL(CONV(HEX(LEFT(CONVERT(PARAM USING gbk),1)),16,10),\n        0xB0A1,0xB0C5,0xB2C1,0xB4EE,0xB6EA,0xB7A2,0xB8C1,0xB9FE,0xBBF7,\n        0xBFA6,0xC0AC,0xC2E8,0xC4C3,0xC5B6,0xC5BE,0xC6DA,0xC8BB,\n        0xC8F6,0xCBFA,0xCDDA,0xCEF4,0xD1B9,0xD4D1),\n    'A','B','C','D','E','F','G','H','J','K','L','M','N','O','P','Q','R','S','T','W','X','Y','Z');\n    END IF;\n    RETURN V_RETURN;\nEND\n```\n\n这个函数创建成功后，会显示ok。有些时候不成功，可能是没有打开创建函数的权限。\n\n需要在mysql配置文件中打开 log_bin_trust_function_creators ","source":"_posts/mysql排序.md","raw":"title: mysql排序\ntags:\n\n  - mysql\ncategories:\n  - 数据库\nauthor: 郑天祺\ndate: 2019-11-20 20:35:00\n---\n\n\n\n# 1、正常的数字排序\n\n![image-20191120204232822](/img/mysql排序1.png)\n\n# 2、排序中文时\n\n，就是出现问题\n\n![image-20191120204352223](/img/mysql排序2.png)\n\n​\t这是因为我们在选取排序规则时，选择的不是gbk。所以想要正确的排序，需要我们了解我们选取字段的排序规则。\n\n# 3、现在改成gbk_chinese_ci\n\n，ci是不区分大小写\n\n![image-20191120204623652](/img/mysql排序3.png)\n\n这样的话，结果：\n\n![image-20191120204719806](/img/mysql排序4.png)\n\n# 4、英中排序\n\n![image-20191120205015864](/img/mysql排序5.png)\n\n​\t这个也是gbk的排序效果，但是我们想做到中英混搭的效果，我认为可以自已在mysql编译前放进自己的排序规则，\n\n# 5、中文混搭\n\n先看一下效果：\n\n![image-20191120205433980](/img/mysql排序6.png)\n\n我们sql用引入了一个函数GET_FIRST_PINYIN_CHAR\n\n```java\nSELECT\n\ta.id,\n\ta.username \nFROM\n\ttest AS a \nORDER BY\n\tGET_FIRST_PINYIN_CHAR(a.username)\n```\n\n这个函数需要在创建表之后定义，如下：\n\n```java\nDROP FUNCTION IF EXISTS `GET_FIRST_PINYIN_CHAR`;\nCREATE FUNCTION `GET_FIRST_PINYIN_CHAR`(PARAM VARCHAR(255)) RETURNS VARCHAR(2) CHARSET utf8\nBEGIN\n    DECLARE V_RETURN VARCHAR(255);\n    DECLARE V_FIRST_CHAR VARCHAR(2);\n    SET V_FIRST_CHAR = UPPER(LEFT(PARAM,1));\n  SET V_RETURN = V_FIRST_CHAR;\n    IF LENGTH( V_FIRST_CHAR)<>CHARACTER_LENGTH(V_FIRST_CHAR) THEN\n    SET V_RETURN = ELT(INTERVAL(CONV(HEX(LEFT(CONVERT(PARAM USING gbk),1)),16,10),\n        0xB0A1,0xB0C5,0xB2C1,0xB4EE,0xB6EA,0xB7A2,0xB8C1,0xB9FE,0xBBF7,\n        0xBFA6,0xC0AC,0xC2E8,0xC4C3,0xC5B6,0xC5BE,0xC6DA,0xC8BB,\n        0xC8F6,0xCBFA,0xCDDA,0xCEF4,0xD1B9,0xD4D1),\n    'A','B','C','D','E','F','G','H','J','K','L','M','N','O','P','Q','R','S','T','W','X','Y','Z');\n    END IF;\n    RETURN V_RETURN;\nEND\n```\n\n这个函数创建成功后，会显示ok。有些时候不成功，可能是没有打开创建函数的权限。\n\n需要在mysql配置文件中打开 log_bin_trust_function_creators ","slug":"mysql排序","published":1,"updated":"2019-11-26T07:31:53.949Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm0z0014vguqmzhp91um","content":"<h1>1、正常的数字排序</h1>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F1.png\" alt=\"image-20191120204232822\"></p>\n<h1>2、排序中文时</h1>\n<p>，就是出现问题</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F2.png\" alt=\"image-20191120204352223\"></p>\n<p>​\t这是因为我们在选取排序规则时，选择的不是gbk。所以想要正确的排序，需要我们了解我们选取字段的排序规则。</p>\n<h1>3、现在改成gbk_chinese_ci</h1>\n<p>，ci是不区分大小写</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F3.png\" alt=\"image-20191120204623652\"></p>\n<p>这样的话，结果：</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F4.png\" alt=\"image-20191120204719806\"></p>\n<h1>4、英中排序</h1>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F5.png\" alt=\"image-20191120205015864\"></p>\n<p>​\t这个也是gbk的排序效果，但是我们想做到中英混搭的效果，我认为可以自已在mysql编译前放进自己的排序规则，</p>\n<h1>5、中文混搭</h1>\n<p>先看一下效果：</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F6.png\" alt=\"image-20191120205433980\"></p>\n<p>我们sql用引入了一个函数GET_FIRST_PINYIN_CHAR</p>\n<pre><code class=\"language-java\">SELECT\n\ta.id,\n\ta.username \nFROM\n\ttest AS a \nORDER BY\n\tGET_FIRST_PINYIN_CHAR(a.username)\n</code></pre>\n<p>这个函数需要在创建表之后定义，如下：</p>\n<pre><code class=\"language-java\">DROP FUNCTION IF EXISTS `GET_FIRST_PINYIN_CHAR`;\nCREATE FUNCTION `GET_FIRST_PINYIN_CHAR`(PARAM VARCHAR(255)) RETURNS VARCHAR(2) CHARSET utf8\nBEGIN\n    DECLARE V_RETURN VARCHAR(255);\n    DECLARE V_FIRST_CHAR VARCHAR(2);\n    SET V_FIRST_CHAR = UPPER(LEFT(PARAM,1));\n  SET V_RETURN = V_FIRST_CHAR;\n    IF LENGTH( V_FIRST_CHAR)&lt;&gt;CHARACTER_LENGTH(V_FIRST_CHAR) THEN\n    SET V_RETURN = ELT(INTERVAL(CONV(HEX(LEFT(CONVERT(PARAM USING gbk),1)),16,10),\n        0xB0A1,0xB0C5,0xB2C1,0xB4EE,0xB6EA,0xB7A2,0xB8C1,0xB9FE,0xBBF7,\n        0xBFA6,0xC0AC,0xC2E8,0xC4C3,0xC5B6,0xC5BE,0xC6DA,0xC8BB,\n        0xC8F6,0xCBFA,0xCDDA,0xCEF4,0xD1B9,0xD4D1),\n    'A','B','C','D','E','F','G','H','J','K','L','M','N','O','P','Q','R','S','T','W','X','Y','Z');\n    END IF;\n    RETURN V_RETURN;\nEND\n</code></pre>\n<p>这个函数创建成功后，会显示ok。有些时候不成功，可能是没有打开创建函数的权限。</p>\n<p>需要在mysql配置文件中打开 log_bin_trust_function_creators</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>1、正常的数字排序</h1>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F1.png\" alt=\"image-20191120204232822\"></p>\n<h1>2、排序中文时</h1>\n<p>，就是出现问题</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F2.png\" alt=\"image-20191120204352223\"></p>\n<p>​\t这是因为我们在选取排序规则时，选择的不是gbk。所以想要正确的排序，需要我们了解我们选取字段的排序规则。</p>\n<h1>3、现在改成gbk_chinese_ci</h1>\n<p>，ci是不区分大小写</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F3.png\" alt=\"image-20191120204623652\"></p>\n<p>这样的话，结果：</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F4.png\" alt=\"image-20191120204719806\"></p>\n<h1>4、英中排序</h1>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F5.png\" alt=\"image-20191120205015864\"></p>\n<p>​\t这个也是gbk的排序效果，但是我们想做到中英混搭的效果，我认为可以自已在mysql编译前放进自己的排序规则，</p>\n<h1>5、中文混搭</h1>\n<p>先看一下效果：</p>\n<p><img src=\"/img/mysql%E6%8E%92%E5%BA%8F6.png\" alt=\"image-20191120205433980\"></p>\n<p>我们sql用引入了一个函数GET_FIRST_PINYIN_CHAR</p>\n<pre><code class=\"language-java\">SELECT\n\ta.id,\n\ta.username \nFROM\n\ttest AS a \nORDER BY\n\tGET_FIRST_PINYIN_CHAR(a.username)\n</code></pre>\n<p>这个函数需要在创建表之后定义，如下：</p>\n<pre><code class=\"language-java\">DROP FUNCTION IF EXISTS `GET_FIRST_PINYIN_CHAR`;\nCREATE FUNCTION `GET_FIRST_PINYIN_CHAR`(PARAM VARCHAR(255)) RETURNS VARCHAR(2) CHARSET utf8\nBEGIN\n    DECLARE V_RETURN VARCHAR(255);\n    DECLARE V_FIRST_CHAR VARCHAR(2);\n    SET V_FIRST_CHAR = UPPER(LEFT(PARAM,1));\n  SET V_RETURN = V_FIRST_CHAR;\n    IF LENGTH( V_FIRST_CHAR)&lt;&gt;CHARACTER_LENGTH(V_FIRST_CHAR) THEN\n    SET V_RETURN = ELT(INTERVAL(CONV(HEX(LEFT(CONVERT(PARAM USING gbk),1)),16,10),\n        0xB0A1,0xB0C5,0xB2C1,0xB4EE,0xB6EA,0xB7A2,0xB8C1,0xB9FE,0xBBF7,\n        0xBFA6,0xC0AC,0xC2E8,0xC4C3,0xC5B6,0xC5BE,0xC6DA,0xC8BB,\n        0xC8F6,0xCBFA,0xCDDA,0xCEF4,0xD1B9,0xD4D1),\n    'A','B','C','D','E','F','G','H','J','K','L','M','N','O','P','Q','R','S','T','W','X','Y','Z');\n    END IF;\n    RETURN V_RETURN;\nEND\n</code></pre>\n<p>这个函数创建成功后，会显示ok。有些时候不成功，可能是没有打开创建函数的权限。</p>\n<p>需要在mysql配置文件中打开 log_bin_trust_function_creators</p>\n"},{"title":"java8新特性","author":"郑天祺","date":"2019-11-14T06:18:00.000Z","_content":"​\t都9102年了，JAVA出到了13.0.1。现在预习一下JAVA8新特性应该还来得及；用代码说话：\n\n# 一、Stream（流）\n\nStream（流）是一个来自数据源的元素队列并支持聚合操作\n\n数据源是流的来源。 数据源可以是集合，数组，I/O channel等\n\n优点：\n * 内部迭代：通过访问者模式(Visitor)实现\n * Pipelining：中间操作都会返回流对象本身\n * 聚合操作：类似SQL语句一样的操作， 比如 filter, map, reduce, find, match, sorted 等\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.IntSummaryStatistics;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.stream.Collectors;\n\npublic class Java8StreamTest {\n    final List<String> strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\", \"\", \"jkl\");\n    final List<Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n    final Random random = new Random();\n\n    @Test\n    public void filter() {\n        // filter 方法过滤出空字符串\n        List<String> filtered = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.toList());\n        System.out.println(filtered);\n    }\n\n    @Test\n    public void forEach() {\n        // Stream 提供了新的方法 'forEach' 来迭代流中的每个数据;limit 方法用于获取指定数量的流\n        random.ints().limit(10).forEach(System.out::println);\n    }\n\n    @Test\n    public void map() {\n        // map 方法用于映射每个元素到对应的结果\n        // 获取对应的平方数, distinct为去重\n        List<Integer> squaresList = numbers.stream().map(i -> i * i).distinct().collect(Collectors.toList());\n        System.out.println(squaresList);\n    }\n\n    @Test\n    public void sorted() {\n        // sorted 方法用于对流进行排序\n        random.ints().limit(10).sorted().forEach(System.out::println);\n    }\n\n    @Test\n    public void parallel() {\n        // 获取空字符串的数量\n        long count = strings.parallelStream().filter(string -> string.isEmpty()).count();\n        System.out.println(count);\n    }\n\n    @Test\n    public void join() {\n        // 类似于\n        // jdk：String mergedString = String.join(\",\", strings);\n        // common.lang3：String mergedString = StringUtils.join(strings);\n\n        String mergedString = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.joining(\",\"));\n        System.out.println(mergedString);\n    }\n\n    @Test\n    public void statistics(){\n        // 一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上\n        List<Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n        IntSummaryStatistics stats = numbers.stream().mapToInt((x) -> x).summaryStatistics();\n\n        System.out.println(\"列表中最大的数 : \" + stats.getMax());\n        System.out.println(\"列表中最小的数 : \" + stats.getMin());\n        System.out.println(\"所有数之和 : \" + stats.getSum());\n        System.out.println(\"平均数 : \" + stats.getAverage());\n    }\n\n}\n\n\n```\n\n# 二、方法引用\n\n方法引用\n\n方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。\n\n```java\npackage com.bjut.java8test;\n\n@FunctionalInterface\npublic interface Supplier<T>{\n    T get();\n}\n\n```\n\n```java\npackage com.bjut.java8test;\n\npublic class Car {\n    // Supplier是jdk1.8的接口，这里和lamda一起使用了\n    public static Car create(final Supplier<Car> supplier) {\n        return supplier.get();\n    }\n\n    public static void collide(final Car car) {\n        System.out.println(\"Colloded\" + car.toString());\n    }\n\n    public void follow(final Car another) {\n        System.out.println(\"Following the\" + another.toString());\n    }\n\n    public void repair() {\n        System.out.println(\"Repaired\" + this.toString());\n    }\n}\n```\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class Java8QuoteTest {\n    final Car car = Car.create(Car::new);\n    final List<Car> cars = Arrays.asList(car);\n    final Car police = Car.create(Car::new);\n\n    @Test\n    public void quoteType() {\n        // 静态方法引用：它的语法是Class::static_method，实例如下：\n        cars.forEach(Car::collide);\n        // 特定类的任意对象的方法引用：它的语法是Class::method实例如下：\n        cars.forEach(Car::repair);\n        // 特定对象的方法引用：它的语法是instance::method实例如下：\n        cars.forEach(police::follow);\n    }\n\n    @Test\n    public void quoteExample(){\n        List<String> names = new ArrayList<>(50);\n        names.add(\"hello\");\n        names.add(\"world\");\n        names.add(\"ni\");\n        names.add(\"hao\");\n        names.forEach(System.out::println);\n    }\n}\n\n```\n\n# 三、默认方法\n\n 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 \n\n```java\npackage com.bjut.java8test;\n\npublic interface Java8DefaultInterface {\n    default void print(){\n        System.out.println(\"默认方法\");\n    }\n}\n\n```\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\n/**\n * 测试接口默认方法\n */\npublic class Java8DefaultInterfaceTest implements Java8DefaultInterface{\n\n    @Test\n    public void test(){\n        Java8DefaultInterface defaultInterface = new Java8DefaultInterfaceTest();\n        defaultInterface.print();\n    }\n}\n\n```\n\n# 四、 Date Time API \n\n加强对日期与时间的处理。 \n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.time.*;\n\npublic class Java8DateTest {\n    LocalDateTime currentTime = LocalDateTime.now();\n\n    @Test\n    public void testLocalDateTime() {\n        // 获取服务器当前的日期时间\n        System.out.println(\"时间\" + currentTime);\n\n        // 获取服务器当前日期\n        LocalDate date1 = currentTime.toLocalDate();\n        System.out.println(\"date1: \" + date1);\n\n        // 获取服务器某月某天\n        Month month = currentTime.getMonth();\n        int day = currentTime.getDayOfMonth();\n        int seconds = currentTime.getSecond();\n        System.out.println(\"月: \" + month + \", 日: \" + day + \", 秒: \" + seconds);\n    }\n\n    @Test\n    public void testStructDateTime() {\n        LocalDateTime date2 = currentTime.withDayOfMonth(12).withYear(2012);\n        System.out.println(\"date2\" + date2);\n\n        // 23 december 2014\n        LocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 23);\n        System.out.println(\"date3\" + date3);\n\n        // 22 小时 15 分钟\n        LocalTime date4 = LocalTime.of(22, 15);\n        System.out.println(\"date4: \" + date4);\n\n        // 解析字符串\n        LocalTime date5 = LocalTime.parse(\"20:15:30\");\n        System.out.println(\"date5: \" + date5);\n    }\n\n    @Test\n    public void testZonedDateTime() {\n        // 获取当前时间日期\n        ZonedDateTime date1 = ZonedDateTime.parse(\"2015-12-03T10:15:30+05:30[Asia/Shanghai]\");\n        System.out.println(\"date1: \" + date1);\n\n        ZoneId id = ZoneId.of(\"Europe/Paris\");\n        System.out.println(\"ZoneId: \" + id);\n\n        ZoneId currentZone = ZoneId.systemDefault();\n        System.out.println(\"当期时区: \" + currentZone);\n    }\n}\n\n```\n\n# 五、 Optional 类 \n\nOptional 类是一个可以为null的容器对象。优雅的解决null问题：我平时好像都是类似于 StringUtils.isBlank()\n\nJAVA9在它的基础上又增加了3个方法\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.util.Optional;\n\npublic class java8OptionalTest {\n\n    @Test\n    public void testOptional() {\n        Integer value1 = null;\n        Integer value2 = new Integer(10);\n\n        // Optional.ofNullable -允许传递null参数\n        Optional<Integer> a = Optional.ofNullable(value1);\n        // Optional.of - 如果传递的参数是null ， 抛出异常NullPointerException\n        Optional<Integer> b = Optional.of(value2);\n\n        System.out.println(sum(a, b));\n    }\n\n\n    private Integer sum(Optional<Integer> a, Optional<Integer> b) {\n        // Optional.isPresent - 判断值是否存在\n        System.out.println(\"第一个参数值存在\" + a.isPresent());\n        System.out.println(\"第二个参数值存在\" + b.isPresent());\n\n        // Option.orElse - 如果值存在，返回它，否则返回默认值\n        Integer value1 = a.orElse(new Integer(0));\n\n        // Optional.get - 获取值，值需要存在\n        Integer value2 = b.get();\n        return value1 + value2;\n    }\n}\n\n```\n\n\n\n参考文献：https://www.runoob.com/java/java8-new-features.html","source":"_posts/java8新特性.md","raw":"title: java8新特性\nauthor: 郑天祺\ntags:\n\n  - JDK1.8新特性\ncategories:\n  - java基础\ndate: 2019-11-14 14:18:00\n---\n​\t都9102年了，JAVA出到了13.0.1。现在预习一下JAVA8新特性应该还来得及；用代码说话：\n\n# 一、Stream（流）\n\nStream（流）是一个来自数据源的元素队列并支持聚合操作\n\n数据源是流的来源。 数据源可以是集合，数组，I/O channel等\n\n优点：\n * 内部迭代：通过访问者模式(Visitor)实现\n * Pipelining：中间操作都会返回流对象本身\n * 聚合操作：类似SQL语句一样的操作， 比如 filter, map, reduce, find, match, sorted 等\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.IntSummaryStatistics;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.stream.Collectors;\n\npublic class Java8StreamTest {\n    final List<String> strings = Arrays.asList(\"abc\", \"\", \"bc\", \"efg\", \"abcd\", \"\", \"jkl\");\n    final List<Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n    final Random random = new Random();\n\n    @Test\n    public void filter() {\n        // filter 方法过滤出空字符串\n        List<String> filtered = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.toList());\n        System.out.println(filtered);\n    }\n\n    @Test\n    public void forEach() {\n        // Stream 提供了新的方法 'forEach' 来迭代流中的每个数据;limit 方法用于获取指定数量的流\n        random.ints().limit(10).forEach(System.out::println);\n    }\n\n    @Test\n    public void map() {\n        // map 方法用于映射每个元素到对应的结果\n        // 获取对应的平方数, distinct为去重\n        List<Integer> squaresList = numbers.stream().map(i -> i * i).distinct().collect(Collectors.toList());\n        System.out.println(squaresList);\n    }\n\n    @Test\n    public void sorted() {\n        // sorted 方法用于对流进行排序\n        random.ints().limit(10).sorted().forEach(System.out::println);\n    }\n\n    @Test\n    public void parallel() {\n        // 获取空字符串的数量\n        long count = strings.parallelStream().filter(string -> string.isEmpty()).count();\n        System.out.println(count);\n    }\n\n    @Test\n    public void join() {\n        // 类似于\n        // jdk：String mergedString = String.join(\",\", strings);\n        // common.lang3：String mergedString = StringUtils.join(strings);\n\n        String mergedString = strings.stream().filter(string -> !string.isEmpty()).collect(Collectors.joining(\",\"));\n        System.out.println(mergedString);\n    }\n\n    @Test\n    public void statistics(){\n        // 一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上\n        List<Integer> numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n        IntSummaryStatistics stats = numbers.stream().mapToInt((x) -> x).summaryStatistics();\n\n        System.out.println(\"列表中最大的数 : \" + stats.getMax());\n        System.out.println(\"列表中最小的数 : \" + stats.getMin());\n        System.out.println(\"所有数之和 : \" + stats.getSum());\n        System.out.println(\"平均数 : \" + stats.getAverage());\n    }\n\n}\n\n\n```\n\n# 二、方法引用\n\n方法引用\n\n方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。\n\n```java\npackage com.bjut.java8test;\n\n@FunctionalInterface\npublic interface Supplier<T>{\n    T get();\n}\n\n```\n\n```java\npackage com.bjut.java8test;\n\npublic class Car {\n    // Supplier是jdk1.8的接口，这里和lamda一起使用了\n    public static Car create(final Supplier<Car> supplier) {\n        return supplier.get();\n    }\n\n    public static void collide(final Car car) {\n        System.out.println(\"Colloded\" + car.toString());\n    }\n\n    public void follow(final Car another) {\n        System.out.println(\"Following the\" + another.toString());\n    }\n\n    public void repair() {\n        System.out.println(\"Repaired\" + this.toString());\n    }\n}\n```\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class Java8QuoteTest {\n    final Car car = Car.create(Car::new);\n    final List<Car> cars = Arrays.asList(car);\n    final Car police = Car.create(Car::new);\n\n    @Test\n    public void quoteType() {\n        // 静态方法引用：它的语法是Class::static_method，实例如下：\n        cars.forEach(Car::collide);\n        // 特定类的任意对象的方法引用：它的语法是Class::method实例如下：\n        cars.forEach(Car::repair);\n        // 特定对象的方法引用：它的语法是instance::method实例如下：\n        cars.forEach(police::follow);\n    }\n\n    @Test\n    public void quoteExample(){\n        List<String> names = new ArrayList<>(50);\n        names.add(\"hello\");\n        names.add(\"world\");\n        names.add(\"ni\");\n        names.add(\"hao\");\n        names.forEach(System.out::println);\n    }\n}\n\n```\n\n# 三、默认方法\n\n 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 \n\n```java\npackage com.bjut.java8test;\n\npublic interface Java8DefaultInterface {\n    default void print(){\n        System.out.println(\"默认方法\");\n    }\n}\n\n```\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\n\n/**\n * 测试接口默认方法\n */\npublic class Java8DefaultInterfaceTest implements Java8DefaultInterface{\n\n    @Test\n    public void test(){\n        Java8DefaultInterface defaultInterface = new Java8DefaultInterfaceTest();\n        defaultInterface.print();\n    }\n}\n\n```\n\n# 四、 Date Time API \n\n加强对日期与时间的处理。 \n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.time.*;\n\npublic class Java8DateTest {\n    LocalDateTime currentTime = LocalDateTime.now();\n\n    @Test\n    public void testLocalDateTime() {\n        // 获取服务器当前的日期时间\n        System.out.println(\"时间\" + currentTime);\n\n        // 获取服务器当前日期\n        LocalDate date1 = currentTime.toLocalDate();\n        System.out.println(\"date1: \" + date1);\n\n        // 获取服务器某月某天\n        Month month = currentTime.getMonth();\n        int day = currentTime.getDayOfMonth();\n        int seconds = currentTime.getSecond();\n        System.out.println(\"月: \" + month + \", 日: \" + day + \", 秒: \" + seconds);\n    }\n\n    @Test\n    public void testStructDateTime() {\n        LocalDateTime date2 = currentTime.withDayOfMonth(12).withYear(2012);\n        System.out.println(\"date2\" + date2);\n\n        // 23 december 2014\n        LocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 23);\n        System.out.println(\"date3\" + date3);\n\n        // 22 小时 15 分钟\n        LocalTime date4 = LocalTime.of(22, 15);\n        System.out.println(\"date4: \" + date4);\n\n        // 解析字符串\n        LocalTime date5 = LocalTime.parse(\"20:15:30\");\n        System.out.println(\"date5: \" + date5);\n    }\n\n    @Test\n    public void testZonedDateTime() {\n        // 获取当前时间日期\n        ZonedDateTime date1 = ZonedDateTime.parse(\"2015-12-03T10:15:30+05:30[Asia/Shanghai]\");\n        System.out.println(\"date1: \" + date1);\n\n        ZoneId id = ZoneId.of(\"Europe/Paris\");\n        System.out.println(\"ZoneId: \" + id);\n\n        ZoneId currentZone = ZoneId.systemDefault();\n        System.out.println(\"当期时区: \" + currentZone);\n    }\n}\n\n```\n\n# 五、 Optional 类 \n\nOptional 类是一个可以为null的容器对象。优雅的解决null问题：我平时好像都是类似于 StringUtils.isBlank()\n\nJAVA9在它的基础上又增加了3个方法\n\n```java\npackage com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.util.Optional;\n\npublic class java8OptionalTest {\n\n    @Test\n    public void testOptional() {\n        Integer value1 = null;\n        Integer value2 = new Integer(10);\n\n        // Optional.ofNullable -允许传递null参数\n        Optional<Integer> a = Optional.ofNullable(value1);\n        // Optional.of - 如果传递的参数是null ， 抛出异常NullPointerException\n        Optional<Integer> b = Optional.of(value2);\n\n        System.out.println(sum(a, b));\n    }\n\n\n    private Integer sum(Optional<Integer> a, Optional<Integer> b) {\n        // Optional.isPresent - 判断值是否存在\n        System.out.println(\"第一个参数值存在\" + a.isPresent());\n        System.out.println(\"第二个参数值存在\" + b.isPresent());\n\n        // Option.orElse - 如果值存在，返回它，否则返回默认值\n        Integer value1 = a.orElse(new Integer(0));\n\n        // Optional.get - 获取值，值需要存在\n        Integer value2 = b.get();\n        return value1 + value2;\n    }\n}\n\n```\n\n\n\n参考文献：https://www.runoob.com/java/java8-new-features.html","slug":"java8新特性","published":1,"updated":"2019-11-14T08:30:37.235Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm110017vguq33ka4om2","content":"<p>​\t都9102年了，JAVA出到了13.0.1。现在预习一下JAVA8新特性应该还来得及；用代码说话：</p>\n<h1>一、Stream（流）</h1>\n<p>Stream（流）是一个来自数据源的元素队列并支持聚合操作</p>\n<p>数据源是流的来源。 数据源可以是集合，数组，I/O channel等</p>\n<p>优点：</p>\n<ul>\n<li>内部迭代：通过访问者模式(Visitor)实现</li>\n<li>Pipelining：中间操作都会返回流对象本身</li>\n<li>聚合操作：类似SQL语句一样的操作， 比如 filter, map, reduce, find, match, sorted 等</li>\n</ul>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.IntSummaryStatistics;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.stream.Collectors;\n\npublic class Java8StreamTest {\n    final List&lt;String&gt; strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;, &quot;&quot;, &quot;jkl&quot;);\n    final List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n    final Random random = new Random();\n\n    @Test\n    public void filter() {\n        // filter 方法过滤出空字符串\n        List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList());\n        System.out.println(filtered);\n    }\n\n    @Test\n    public void forEach() {\n        // Stream 提供了新的方法 'forEach' 来迭代流中的每个数据;limit 方法用于获取指定数量的流\n        random.ints().limit(10).forEach(System.out::println);\n    }\n\n    @Test\n    public void map() {\n        // map 方法用于映射每个元素到对应的结果\n        // 获取对应的平方数, distinct为去重\n        List&lt;Integer&gt; squaresList = numbers.stream().map(i -&gt; i * i).distinct().collect(Collectors.toList());\n        System.out.println(squaresList);\n    }\n\n    @Test\n    public void sorted() {\n        // sorted 方法用于对流进行排序\n        random.ints().limit(10).sorted().forEach(System.out::println);\n    }\n\n    @Test\n    public void parallel() {\n        // 获取空字符串的数量\n        long count = strings.parallelStream().filter(string -&gt; string.isEmpty()).count();\n        System.out.println(count);\n    }\n\n    @Test\n    public void join() {\n        // 类似于\n        // jdk：String mergedString = String.join(&quot;,&quot;, strings);\n        // common.lang3：String mergedString = StringUtils.join(strings);\n\n        String mergedString = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(&quot;,&quot;));\n        System.out.println(mergedString);\n    }\n\n    @Test\n    public void statistics(){\n        // 一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上\n        List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n        IntSummaryStatistics stats = numbers.stream().mapToInt((x) -&gt; x).summaryStatistics();\n\n        System.out.println(&quot;列表中最大的数 : &quot; + stats.getMax());\n        System.out.println(&quot;列表中最小的数 : &quot; + stats.getMin());\n        System.out.println(&quot;所有数之和 : &quot; + stats.getSum());\n        System.out.println(&quot;平均数 : &quot; + stats.getAverage());\n    }\n\n}\n\n\n</code></pre>\n<h1>二、方法引用</h1>\n<p>方法引用</p>\n<p>方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\n@FunctionalInterface\npublic interface Supplier&lt;T&gt;{\n    T get();\n}\n\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\npublic class Car {\n    // Supplier是jdk1.8的接口，这里和lamda一起使用了\n    public static Car create(final Supplier&lt;Car&gt; supplier) {\n        return supplier.get();\n    }\n\n    public static void collide(final Car car) {\n        System.out.println(&quot;Colloded&quot; + car.toString());\n    }\n\n    public void follow(final Car another) {\n        System.out.println(&quot;Following the&quot; + another.toString());\n    }\n\n    public void repair() {\n        System.out.println(&quot;Repaired&quot; + this.toString());\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class Java8QuoteTest {\n    final Car car = Car.create(Car::new);\n    final List&lt;Car&gt; cars = Arrays.asList(car);\n    final Car police = Car.create(Car::new);\n\n    @Test\n    public void quoteType() {\n        // 静态方法引用：它的语法是Class::static_method，实例如下：\n        cars.forEach(Car::collide);\n        // 特定类的任意对象的方法引用：它的语法是Class::method实例如下：\n        cars.forEach(Car::repair);\n        // 特定对象的方法引用：它的语法是instance::method实例如下：\n        cars.forEach(police::follow);\n    }\n\n    @Test\n    public void quoteExample(){\n        List&lt;String&gt; names = new ArrayList&lt;&gt;(50);\n        names.add(&quot;hello&quot;);\n        names.add(&quot;world&quot;);\n        names.add(&quot;ni&quot;);\n        names.add(&quot;hao&quot;);\n        names.forEach(System.out::println);\n    }\n}\n\n</code></pre>\n<h1>三、默认方法</h1>\n<p>默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\npublic interface Java8DefaultInterface {\n    default void print(){\n        System.out.println(&quot;默认方法&quot;);\n    }\n}\n\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\n/**\n * 测试接口默认方法\n */\npublic class Java8DefaultInterfaceTest implements Java8DefaultInterface{\n\n    @Test\n    public void test(){\n        Java8DefaultInterface defaultInterface = new Java8DefaultInterfaceTest();\n        defaultInterface.print();\n    }\n}\n\n</code></pre>\n<h1>四、 Date Time API</h1>\n<p>加强对日期与时间的处理。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.time.*;\n\npublic class Java8DateTest {\n    LocalDateTime currentTime = LocalDateTime.now();\n\n    @Test\n    public void testLocalDateTime() {\n        // 获取服务器当前的日期时间\n        System.out.println(&quot;时间&quot; + currentTime);\n\n        // 获取服务器当前日期\n        LocalDate date1 = currentTime.toLocalDate();\n        System.out.println(&quot;date1: &quot; + date1);\n\n        // 获取服务器某月某天\n        Month month = currentTime.getMonth();\n        int day = currentTime.getDayOfMonth();\n        int seconds = currentTime.getSecond();\n        System.out.println(&quot;月: &quot; + month + &quot;, 日: &quot; + day + &quot;, 秒: &quot; + seconds);\n    }\n\n    @Test\n    public void testStructDateTime() {\n        LocalDateTime date2 = currentTime.withDayOfMonth(12).withYear(2012);\n        System.out.println(&quot;date2&quot; + date2);\n\n        // 23 december 2014\n        LocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 23);\n        System.out.println(&quot;date3&quot; + date3);\n\n        // 22 小时 15 分钟\n        LocalTime date4 = LocalTime.of(22, 15);\n        System.out.println(&quot;date4: &quot; + date4);\n\n        // 解析字符串\n        LocalTime date5 = LocalTime.parse(&quot;20:15:30&quot;);\n        System.out.println(&quot;date5: &quot; + date5);\n    }\n\n    @Test\n    public void testZonedDateTime() {\n        // 获取当前时间日期\n        ZonedDateTime date1 = ZonedDateTime.parse(&quot;2015-12-03T10:15:30+05:30[Asia/Shanghai]&quot;);\n        System.out.println(&quot;date1: &quot; + date1);\n\n        ZoneId id = ZoneId.of(&quot;Europe/Paris&quot;);\n        System.out.println(&quot;ZoneId: &quot; + id);\n\n        ZoneId currentZone = ZoneId.systemDefault();\n        System.out.println(&quot;当期时区: &quot; + currentZone);\n    }\n}\n\n</code></pre>\n<h1>五、 Optional 类</h1>\n<p>Optional 类是一个可以为null的容器对象。优雅的解决null问题：我平时好像都是类似于 StringUtils.isBlank()</p>\n<p>JAVA9在它的基础上又增加了3个方法</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.util.Optional;\n\npublic class java8OptionalTest {\n\n    @Test\n    public void testOptional() {\n        Integer value1 = null;\n        Integer value2 = new Integer(10);\n\n        // Optional.ofNullable -允许传递null参数\n        Optional&lt;Integer&gt; a = Optional.ofNullable(value1);\n        // Optional.of - 如果传递的参数是null ， 抛出异常NullPointerException\n        Optional&lt;Integer&gt; b = Optional.of(value2);\n\n        System.out.println(sum(a, b));\n    }\n\n\n    private Integer sum(Optional&lt;Integer&gt; a, Optional&lt;Integer&gt; b) {\n        // Optional.isPresent - 判断值是否存在\n        System.out.println(&quot;第一个参数值存在&quot; + a.isPresent());\n        System.out.println(&quot;第二个参数值存在&quot; + b.isPresent());\n\n        // Option.orElse - 如果值存在，返回它，否则返回默认值\n        Integer value1 = a.orElse(new Integer(0));\n\n        // Optional.get - 获取值，值需要存在\n        Integer value2 = b.get();\n        return value1 + value2;\n    }\n}\n\n</code></pre>\n<p>参考文献：https://www.runoob.com/java/java8-new-features.html</p>\n","site":{"data":{}},"excerpt":"","more":"<p>​\t都9102年了，JAVA出到了13.0.1。现在预习一下JAVA8新特性应该还来得及；用代码说话：</p>\n<h1>一、Stream（流）</h1>\n<p>Stream（流）是一个来自数据源的元素队列并支持聚合操作</p>\n<p>数据源是流的来源。 数据源可以是集合，数组，I/O channel等</p>\n<p>优点：</p>\n<ul>\n<li>内部迭代：通过访问者模式(Visitor)实现</li>\n<li>Pipelining：中间操作都会返回流对象本身</li>\n<li>聚合操作：类似SQL语句一样的操作， 比如 filter, map, reduce, find, match, sorted 等</li>\n</ul>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.Arrays;\nimport java.util.IntSummaryStatistics;\nimport java.util.List;\nimport java.util.Random;\nimport java.util.stream.Collectors;\n\npublic class Java8StreamTest {\n    final List&lt;String&gt; strings = Arrays.asList(&quot;abc&quot;, &quot;&quot;, &quot;bc&quot;, &quot;efg&quot;, &quot;abcd&quot;, &quot;&quot;, &quot;jkl&quot;);\n    final List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n    final Random random = new Random();\n\n    @Test\n    public void filter() {\n        // filter 方法过滤出空字符串\n        List&lt;String&gt; filtered = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.toList());\n        System.out.println(filtered);\n    }\n\n    @Test\n    public void forEach() {\n        // Stream 提供了新的方法 'forEach' 来迭代流中的每个数据;limit 方法用于获取指定数量的流\n        random.ints().limit(10).forEach(System.out::println);\n    }\n\n    @Test\n    public void map() {\n        // map 方法用于映射每个元素到对应的结果\n        // 获取对应的平方数, distinct为去重\n        List&lt;Integer&gt; squaresList = numbers.stream().map(i -&gt; i * i).distinct().collect(Collectors.toList());\n        System.out.println(squaresList);\n    }\n\n    @Test\n    public void sorted() {\n        // sorted 方法用于对流进行排序\n        random.ints().limit(10).sorted().forEach(System.out::println);\n    }\n\n    @Test\n    public void parallel() {\n        // 获取空字符串的数量\n        long count = strings.parallelStream().filter(string -&gt; string.isEmpty()).count();\n        System.out.println(count);\n    }\n\n    @Test\n    public void join() {\n        // 类似于\n        // jdk：String mergedString = String.join(&quot;,&quot;, strings);\n        // common.lang3：String mergedString = StringUtils.join(strings);\n\n        String mergedString = strings.stream().filter(string -&gt; !string.isEmpty()).collect(Collectors.joining(&quot;,&quot;));\n        System.out.println(mergedString);\n    }\n\n    @Test\n    public void statistics(){\n        // 一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上\n        List&lt;Integer&gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\n        IntSummaryStatistics stats = numbers.stream().mapToInt((x) -&gt; x).summaryStatistics();\n\n        System.out.println(&quot;列表中最大的数 : &quot; + stats.getMax());\n        System.out.println(&quot;列表中最小的数 : &quot; + stats.getMin());\n        System.out.println(&quot;所有数之和 : &quot; + stats.getSum());\n        System.out.println(&quot;平均数 : &quot; + stats.getAverage());\n    }\n\n}\n\n\n</code></pre>\n<h1>二、方法引用</h1>\n<p>方法引用</p>\n<p>方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\n@FunctionalInterface\npublic interface Supplier&lt;T&gt;{\n    T get();\n}\n\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\npublic class Car {\n    // Supplier是jdk1.8的接口，这里和lamda一起使用了\n    public static Car create(final Supplier&lt;Car&gt; supplier) {\n        return supplier.get();\n    }\n\n    public static void collide(final Car car) {\n        System.out.println(&quot;Colloded&quot; + car.toString());\n    }\n\n    public void follow(final Car another) {\n        System.out.println(&quot;Following the&quot; + another.toString());\n    }\n\n    public void repair() {\n        System.out.println(&quot;Repaired&quot; + this.toString());\n    }\n}\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\nimport java.util.ArrayList;\nimport java.util.Arrays;\nimport java.util.List;\n\npublic class Java8QuoteTest {\n    final Car car = Car.create(Car::new);\n    final List&lt;Car&gt; cars = Arrays.asList(car);\n    final Car police = Car.create(Car::new);\n\n    @Test\n    public void quoteType() {\n        // 静态方法引用：它的语法是Class::static_method，实例如下：\n        cars.forEach(Car::collide);\n        // 特定类的任意对象的方法引用：它的语法是Class::method实例如下：\n        cars.forEach(Car::repair);\n        // 特定对象的方法引用：它的语法是instance::method实例如下：\n        cars.forEach(police::follow);\n    }\n\n    @Test\n    public void quoteExample(){\n        List&lt;String&gt; names = new ArrayList&lt;&gt;(50);\n        names.add(&quot;hello&quot;);\n        names.add(&quot;world&quot;);\n        names.add(&quot;ni&quot;);\n        names.add(&quot;hao&quot;);\n        names.forEach(System.out::println);\n    }\n}\n\n</code></pre>\n<h1>三、默认方法</h1>\n<p>默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\npublic interface Java8DefaultInterface {\n    default void print(){\n        System.out.println(&quot;默认方法&quot;);\n    }\n}\n\n</code></pre>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\n\n/**\n * 测试接口默认方法\n */\npublic class Java8DefaultInterfaceTest implements Java8DefaultInterface{\n\n    @Test\n    public void test(){\n        Java8DefaultInterface defaultInterface = new Java8DefaultInterfaceTest();\n        defaultInterface.print();\n    }\n}\n\n</code></pre>\n<h1>四、 Date Time API</h1>\n<p>加强对日期与时间的处理。</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.time.*;\n\npublic class Java8DateTest {\n    LocalDateTime currentTime = LocalDateTime.now();\n\n    @Test\n    public void testLocalDateTime() {\n        // 获取服务器当前的日期时间\n        System.out.println(&quot;时间&quot; + currentTime);\n\n        // 获取服务器当前日期\n        LocalDate date1 = currentTime.toLocalDate();\n        System.out.println(&quot;date1: &quot; + date1);\n\n        // 获取服务器某月某天\n        Month month = currentTime.getMonth();\n        int day = currentTime.getDayOfMonth();\n        int seconds = currentTime.getSecond();\n        System.out.println(&quot;月: &quot; + month + &quot;, 日: &quot; + day + &quot;, 秒: &quot; + seconds);\n    }\n\n    @Test\n    public void testStructDateTime() {\n        LocalDateTime date2 = currentTime.withDayOfMonth(12).withYear(2012);\n        System.out.println(&quot;date2&quot; + date2);\n\n        // 23 december 2014\n        LocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 23);\n        System.out.println(&quot;date3&quot; + date3);\n\n        // 22 小时 15 分钟\n        LocalTime date4 = LocalTime.of(22, 15);\n        System.out.println(&quot;date4: &quot; + date4);\n\n        // 解析字符串\n        LocalTime date5 = LocalTime.parse(&quot;20:15:30&quot;);\n        System.out.println(&quot;date5: &quot; + date5);\n    }\n\n    @Test\n    public void testZonedDateTime() {\n        // 获取当前时间日期\n        ZonedDateTime date1 = ZonedDateTime.parse(&quot;2015-12-03T10:15:30+05:30[Asia/Shanghai]&quot;);\n        System.out.println(&quot;date1: &quot; + date1);\n\n        ZoneId id = ZoneId.of(&quot;Europe/Paris&quot;);\n        System.out.println(&quot;ZoneId: &quot; + id);\n\n        ZoneId currentZone = ZoneId.systemDefault();\n        System.out.println(&quot;当期时区: &quot; + currentZone);\n    }\n}\n\n</code></pre>\n<h1>五、 Optional 类</h1>\n<p>Optional 类是一个可以为null的容器对象。优雅的解决null问题：我平时好像都是类似于 StringUtils.isBlank()</p>\n<p>JAVA9在它的基础上又增加了3个方法</p>\n<pre><code class=\"language-java\">package com.bjut.java8test;\n\nimport org.junit.Test;\nimport java.util.Optional;\n\npublic class java8OptionalTest {\n\n    @Test\n    public void testOptional() {\n        Integer value1 = null;\n        Integer value2 = new Integer(10);\n\n        // Optional.ofNullable -允许传递null参数\n        Optional&lt;Integer&gt; a = Optional.ofNullable(value1);\n        // Optional.of - 如果传递的参数是null ， 抛出异常NullPointerException\n        Optional&lt;Integer&gt; b = Optional.of(value2);\n\n        System.out.println(sum(a, b));\n    }\n\n\n    private Integer sum(Optional&lt;Integer&gt; a, Optional&lt;Integer&gt; b) {\n        // Optional.isPresent - 判断值是否存在\n        System.out.println(&quot;第一个参数值存在&quot; + a.isPresent());\n        System.out.println(&quot;第二个参数值存在&quot; + b.isPresent());\n\n        // Option.orElse - 如果值存在，返回它，否则返回默认值\n        Integer value1 = a.orElse(new Integer(0));\n\n        // Optional.get - 获取值，值需要存在\n        Integer value2 = b.get();\n        return value1 + value2;\n    }\n}\n\n</code></pre>\n<p>参考文献：https://www.runoob.com/java/java8-new-features.html</p>\n"},{"title":"公平锁、非公平锁","author":"郑天祺","date":"2019-08-31T05:21:00.000Z","_content":"\n1、概念：\n\n​        公平锁：加锁前先查看是否有排队等待的线程，有的话优先处理排在前面的线程，先来先得。\n​        公平所：线程加锁时直接尝试获取锁，获取不到就自动到队尾等待。\n\n​        更多的是直接使用非公平锁：非公平锁比公平锁性能高5-10倍，因为公平锁需要在多核情况下维护一个队列，如果当前线程不是队列的第一个无法获取锁，增加了线程切换次数。\n\n​        原理 ： https://www.cnblogs.com/little-fly/p/10365109.html\n\n​        https://www.jianshu.com/p/06340f8feb05\n\n​       \n\n2、Java语言中:\n\n​    公平和非公平锁的队列都基于锁内部维护的一个双向链表，表结点Node的值就是每一个请求当前锁的线程。\n\n​    两者的区别：https://www.jianshu.com/p/c7d17b5c6be3","source":"_posts/公平锁、非公平锁.md","raw":"title: 公平锁、非公平锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:21:00\n\n---\n\n1、概念：\n\n​        公平锁：加锁前先查看是否有排队等待的线程，有的话优先处理排在前面的线程，先来先得。\n​        公平所：线程加锁时直接尝试获取锁，获取不到就自动到队尾等待。\n\n​        更多的是直接使用非公平锁：非公平锁比公平锁性能高5-10倍，因为公平锁需要在多核情况下维护一个队列，如果当前线程不是队列的第一个无法获取锁，增加了线程切换次数。\n\n​        原理 ： https://www.cnblogs.com/little-fly/p/10365109.html\n\n​        https://www.jianshu.com/p/06340f8feb05\n\n​       \n\n2、Java语言中:\n\n​    公平和非公平锁的队列都基于锁内部维护的一个双向链表，表结点Node的值就是每一个请求当前锁的线程。\n\n​    两者的区别：https://www.jianshu.com/p/c7d17b5c6be3","slug":"公平锁、非公平锁","published":1,"updated":"2019-10-15T10:06:08.660Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm14001cvguq1k1fnroy","content":"<p>1、概念：</p>\n<p>​        公平锁：加锁前先查看是否有排队等待的线程，有的话优先处理排在前面的线程，先来先得。\n​        公平所：线程加锁时直接尝试获取锁，获取不到就自动到队尾等待。</p>\n<p>​        更多的是直接使用非公平锁：非公平锁比公平锁性能高5-10倍，因为公平锁需要在多核情况下维护一个队列，如果当前线程不是队列的第一个无法获取锁，增加了线程切换次数。</p>\n<p>​        原理 ： https://www.cnblogs.com/little-fly/p/10365109.html</p>\n<p>​        https://www.jianshu.com/p/06340f8feb05</p>\n<p>​</p>\n<p>2、Java语言中:</p>\n<p>​    公平和非公平锁的队列都基于锁内部维护的一个双向链表，表结点Node的值就是每一个请求当前锁的线程。</p>\n<p>​    两者的区别：https://www.jianshu.com/p/c7d17b5c6be3</p>\n","site":{"data":{}},"excerpt":"","more":"<p>1、概念：</p>\n<p>​        公平锁：加锁前先查看是否有排队等待的线程，有的话优先处理排在前面的线程，先来先得。\n​        公平所：线程加锁时直接尝试获取锁，获取不到就自动到队尾等待。</p>\n<p>​        更多的是直接使用非公平锁：非公平锁比公平锁性能高5-10倍，因为公平锁需要在多核情况下维护一个队列，如果当前线程不是队列的第一个无法获取锁，增加了线程切换次数。</p>\n<p>​        原理 ： https://www.cnblogs.com/little-fly/p/10365109.html</p>\n<p>​        https://www.jianshu.com/p/06340f8feb05</p>\n<p>​</p>\n<p>2、Java语言中:</p>\n<p>​    公平和非公平锁的队列都基于锁内部维护的一个双向链表，表结点Node的值就是每一个请求当前锁的线程。</p>\n<p>​    两者的区别：https://www.jianshu.com/p/c7d17b5c6be3</p>\n"},{"title":"偏向锁","author":"郑天祺","date":"2019-08-31T05:22:00.000Z","_content":"\n## 0、从偏向锁到重量锁\n\n​    在java同步代码快中，synchronized的使用方式无非有两个 :   \n\n​    **1）**通过对一个对象进行加锁来实现同步\n\n```java\nsynchronized(lockObject){\n     //代码\n }\n```\n\n​     **2）**对一个方法进行synchronized声明，进而对一个方法进行加锁来实现同步。\n\n```java\npublic synchornized void test(){\n     //代码\n }\n```\n\n​     无论是对一个对象进行加锁还是对一个方法进行加锁，实际上，都是对对象进行加锁\n\n## 1、先了解一下对象在JVM内存中的布局，如下图\n\n![img](/img/java对象存储.png)\n\n​        Mark Word：包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。在32位系统占4字节，在64位系统中占8字节；\n\n​         Class Pointer：用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。在32位系统占4字节，在64位系统中占8字节；\n\n​         Length：如果是数组对象，还有一个保存数组长度的空间，占4个字节；\n\n​         对齐填充：Java对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。\n\n​        从上图我们可以看出，对象中关于**锁的信息是存在Markword里**的。\n\n## 2、锁的创建\n\n\n\n```java\n// 随便创建一个对象\nLockObject lockObject = new LockObject();\n synchronized(lockObject){\n     //代码\n }\n```\n\n​    **1）**当我们创建一个对象LockObject时，该对象的部分Markword关键数据如下。\n\n![1571144064662](/img/锁的创建.png)\n\n​         从图中可以看出，偏向锁的标志位是“01”，状态是“0”，表示该对象还没有被加上偏向锁。（“1”是表示被加上偏向锁）。\n\n​         该对象被创建出来的那一刻，就有了偏向锁的标志位，这也说明了所有对象都是可偏向的，但所有对象的状态都为“0”，也同时说明所有被创建的对象的偏向锁并没有生效。\n\n​    **2）**不过，当线程执行到临界区（critical section）时，此时会利用CAS(Compare and Swap)操作，将线程ID插入到Markword中，同时修改偏向锁的标志位。\n\n​          此时的Mark word的结构信息如下：\n\n![1571144092579](/img/锁的创建2.png)\n\n​          此时偏向锁的状态为“1”，说明对象的偏向锁生效了，同时也可以看到，哪个线程获得了该对象的锁。   \n\n​    **3）**这个锁会偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。\n\n​    **4）**在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行加锁或者解锁操作，而是会做以下的步骤：\n\n​         **a、**Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.\n​         **b、**如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.\n​         **c、**如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。\n​         **d、**如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。\n\n​    **5）**如果此对象已经偏向了，并且不是偏向自己，则说明存在了竞争。此时可能就要根据另外线程的情况，可能是重新偏向，也有可能是做偏向撤销，但大部分情况下就是升级成轻量级锁了。可以看出，偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。\n\n   **6）**为什么要这样做呢？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。这也是为什么会有偏向锁出现的原因。在Jdk1.6之后，偏向锁的开关是默认开启的，适用于只有一个线程访问同步块的场景","source":"_posts/偏向锁.md","raw":"title: 偏向锁\nauthor: 郑天祺\ntags:\n\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:22:00\n\n---\n\n## 0、从偏向锁到重量锁\n\n​    在java同步代码快中，synchronized的使用方式无非有两个 :   \n\n​    **1）**通过对一个对象进行加锁来实现同步\n\n```java\nsynchronized(lockObject){\n     //代码\n }\n```\n\n​     **2）**对一个方法进行synchronized声明，进而对一个方法进行加锁来实现同步。\n\n```java\npublic synchornized void test(){\n     //代码\n }\n```\n\n​     无论是对一个对象进行加锁还是对一个方法进行加锁，实际上，都是对对象进行加锁\n\n## 1、先了解一下对象在JVM内存中的布局，如下图\n\n![img](/img/java对象存储.png)\n\n​        Mark Word：包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。在32位系统占4字节，在64位系统中占8字节；\n\n​         Class Pointer：用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。在32位系统占4字节，在64位系统中占8字节；\n\n​         Length：如果是数组对象，还有一个保存数组长度的空间，占4个字节；\n\n​         对齐填充：Java对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。\n\n​        从上图我们可以看出，对象中关于**锁的信息是存在Markword里**的。\n\n## 2、锁的创建\n\n\n\n```java\n// 随便创建一个对象\nLockObject lockObject = new LockObject();\n synchronized(lockObject){\n     //代码\n }\n```\n\n​    **1）**当我们创建一个对象LockObject时，该对象的部分Markword关键数据如下。\n\n![1571144064662](/img/锁的创建.png)\n\n​         从图中可以看出，偏向锁的标志位是“01”，状态是“0”，表示该对象还没有被加上偏向锁。（“1”是表示被加上偏向锁）。\n\n​         该对象被创建出来的那一刻，就有了偏向锁的标志位，这也说明了所有对象都是可偏向的，但所有对象的状态都为“0”，也同时说明所有被创建的对象的偏向锁并没有生效。\n\n​    **2）**不过，当线程执行到临界区（critical section）时，此时会利用CAS(Compare and Swap)操作，将线程ID插入到Markword中，同时修改偏向锁的标志位。\n\n​          此时的Mark word的结构信息如下：\n\n![1571144092579](/img/锁的创建2.png)\n\n​          此时偏向锁的状态为“1”，说明对象的偏向锁生效了，同时也可以看到，哪个线程获得了该对象的锁。   \n\n​    **3）**这个锁会偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。\n\n​    **4）**在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行加锁或者解锁操作，而是会做以下的步骤：\n\n​         **a、**Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.\n​         **b、**如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.\n​         **c、**如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。\n​         **d、**如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。\n\n​    **5）**如果此对象已经偏向了，并且不是偏向自己，则说明存在了竞争。此时可能就要根据另外线程的情况，可能是重新偏向，也有可能是做偏向撤销，但大部分情况下就是升级成轻量级锁了。可以看出，偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。\n\n   **6）**为什么要这样做呢？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。这也是为什么会有偏向锁出现的原因。在Jdk1.6之后，偏向锁的开关是默认开启的，适用于只有一个线程访问同步块的场景","slug":"偏向锁","published":1,"updated":"2019-10-15T12:55:26.116Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm16001fvguqd9izxsjs","content":"<h2>0、从偏向锁到重量锁</h2>\n<p>​    在java同步代码快中，synchronized的使用方式无非有两个 :</p>\n<p>​    **1）**通过对一个对象进行加锁来实现同步</p>\n<pre><code class=\"language-java\">synchronized(lockObject){\n     //代码\n }\n</code></pre>\n<p>​     **2）**对一个方法进行synchronized声明，进而对一个方法进行加锁来实现同步。</p>\n<pre><code class=\"language-java\">public synchornized void test(){\n     //代码\n }\n</code></pre>\n<p>​     无论是对一个对象进行加锁还是对一个方法进行加锁，实际上，都是对对象进行加锁</p>\n<h2>1、先了解一下对象在JVM内存中的布局，如下图</h2>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        Mark Word：包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。在32位系统占4字节，在64位系统中占8字节；</p>\n<p>​         Class Pointer：用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。在32位系统占4字节，在64位系统中占8字节；</p>\n<p>​         Length：如果是数组对象，还有一个保存数组长度的空间，占4个字节；</p>\n<p>​         对齐填充：Java对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。</p>\n<p>​        从上图我们可以看出，对象中关于<strong>锁的信息是存在Markword里</strong>的。</p>\n<h2>2、锁的创建</h2>\n<pre><code class=\"language-java\">// 随便创建一个对象\nLockObject lockObject = new LockObject();\n synchronized(lockObject){\n     //代码\n }\n</code></pre>\n<p>​    **1）**当我们创建一个对象LockObject时，该对象的部分Markword关键数据如下。</p>\n<p><img src=\"/img/%E9%94%81%E7%9A%84%E5%88%9B%E5%BB%BA.png\" alt=\"1571144064662\"></p>\n<p>​         从图中可以看出，偏向锁的标志位是“01”，状态是“0”，表示该对象还没有被加上偏向锁。（“1”是表示被加上偏向锁）。</p>\n<p>​         该对象被创建出来的那一刻，就有了偏向锁的标志位，这也说明了所有对象都是可偏向的，但所有对象的状态都为“0”，也同时说明所有被创建的对象的偏向锁并没有生效。</p>\n<p>​    **2）**不过，当线程执行到临界区（critical section）时，此时会利用CAS(Compare and Swap)操作，将线程ID插入到Markword中，同时修改偏向锁的标志位。</p>\n<p>​          此时的Mark word的结构信息如下：</p>\n<p><img src=\"/img/%E9%94%81%E7%9A%84%E5%88%9B%E5%BB%BA2.png\" alt=\"1571144092579\"></p>\n<p>​          此时偏向锁的状态为“1”，说明对象的偏向锁生效了，同时也可以看到，哪个线程获得了该对象的锁。</p>\n<p>​    **3）**这个锁会偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。</p>\n<p>​    **4）**在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行加锁或者解锁操作，而是会做以下的步骤：</p>\n<p>​         **a、**Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.\n​         **b、**如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.\n​         **c、**如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。\n​         **d、**如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。</p>\n<p>​    **5）**如果此对象已经偏向了，并且不是偏向自己，则说明存在了竞争。此时可能就要根据另外线程的情况，可能是重新偏向，也有可能是做偏向撤销，但大部分情况下就是升级成轻量级锁了。可以看出，偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。</p>\n<p>**6）**为什么要这样做呢？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。这也是为什么会有偏向锁出现的原因。在Jdk1.6之后，偏向锁的开关是默认开启的，适用于只有一个线程访问同步块的场景</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>0、从偏向锁到重量锁</h2>\n<p>​    在java同步代码快中，synchronized的使用方式无非有两个 :</p>\n<p>​    **1）**通过对一个对象进行加锁来实现同步</p>\n<pre><code class=\"language-java\">synchronized(lockObject){\n     //代码\n }\n</code></pre>\n<p>​     **2）**对一个方法进行synchronized声明，进而对一个方法进行加锁来实现同步。</p>\n<pre><code class=\"language-java\">public synchornized void test(){\n     //代码\n }\n</code></pre>\n<p>​     无论是对一个对象进行加锁还是对一个方法进行加锁，实际上，都是对对象进行加锁</p>\n<h2>1、先了解一下对象在JVM内存中的布局，如下图</h2>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        Mark Word：包含一系列的标记位，比如轻量级锁的标记位，偏向锁标记位等等。在32位系统占4字节，在64位系统中占8字节；</p>\n<p>​         Class Pointer：用来指向对象对应的Class对象（其对应的元数据对象）的内存地址。在32位系统占4字节，在64位系统中占8字节；</p>\n<p>​         Length：如果是数组对象，还有一个保存数组长度的空间，占4个字节；</p>\n<p>​         对齐填充：Java对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。</p>\n<p>​        从上图我们可以看出，对象中关于<strong>锁的信息是存在Markword里</strong>的。</p>\n<h2>2、锁的创建</h2>\n<pre><code class=\"language-java\">// 随便创建一个对象\nLockObject lockObject = new LockObject();\n synchronized(lockObject){\n     //代码\n }\n</code></pre>\n<p>​    **1）**当我们创建一个对象LockObject时，该对象的部分Markword关键数据如下。</p>\n<p><img src=\"/img/%E9%94%81%E7%9A%84%E5%88%9B%E5%BB%BA.png\" alt=\"1571144064662\"></p>\n<p>​         从图中可以看出，偏向锁的标志位是“01”，状态是“0”，表示该对象还没有被加上偏向锁。（“1”是表示被加上偏向锁）。</p>\n<p>​         该对象被创建出来的那一刻，就有了偏向锁的标志位，这也说明了所有对象都是可偏向的，但所有对象的状态都为“0”，也同时说明所有被创建的对象的偏向锁并没有生效。</p>\n<p>​    **2）**不过，当线程执行到临界区（critical section）时，此时会利用CAS(Compare and Swap)操作，将线程ID插入到Markword中，同时修改偏向锁的标志位。</p>\n<p>​          此时的Mark word的结构信息如下：</p>\n<p><img src=\"/img/%E9%94%81%E7%9A%84%E5%88%9B%E5%BB%BA2.png\" alt=\"1571144092579\"></p>\n<p>​          此时偏向锁的状态为“1”，说明对象的偏向锁生效了，同时也可以看到，哪个线程获得了该对象的锁。</p>\n<p>​    **3）**这个锁会偏向于第一个获得它的线程，在接下来的执行过程中，假如该锁没有被其他线程所获取，没有其他线程来竞争该锁，那么持有偏向锁的线程将永远不需要进行同步操作。</p>\n<p>​    **4）**在此线程之后的执行过程中，如果再次进入或者退出同一段同步块代码，并不再需要去进行加锁或者解锁操作，而是会做以下的步骤：</p>\n<p>​         **a、**Load-and-test，也就是简单判断一下当前线程id是否与Markword当中的线程id是否一致.\n​         **b、**如果一致，则说明此线程已经成功获得了锁，继续执行下面的代码.\n​         **c、**如果不一致，则要检查一下对象是否还是可偏向，即“是否偏向锁”标志位的值。\n​         **d、**如果还未偏向，则利用CAS操作来竞争锁，也即是第一次获取锁时的操作。</p>\n<p>​    **5）**如果此对象已经偏向了，并且不是偏向自己，则说明存在了竞争。此时可能就要根据另外线程的情况，可能是重新偏向，也有可能是做偏向撤销，但大部分情况下就是升级成轻量级锁了。可以看出，偏向锁是针对于一个线程而言的，线程获得锁之后就不会再有解锁等操作了，这样可以省略很多开销。假如有两个线程来竞争该锁话，那么偏向锁就失效了，进而升级成轻量级锁了。</p>\n<p>**6）**为什么要这样做呢？因为经验表明，其实大部分情况下，都会是同一个线程进入同一块同步代码块的。这也是为什么会有偏向锁出现的原因。在Jdk1.6之后，偏向锁的开关是默认开启的，适用于只有一个线程访问同步块的场景</p>\n"},{"title":"mysql表设计及优化","author":"郑天祺","date":"2019-08-31T07:28:00.000Z","_content":"\n## 一、一些建议\n\n建议来自《MYSQL 王者晋级之路》，本文做些笔记\n\n1）在创建业务表时，库名、表名、字段名必须使用小写字母，采用 “_” 分割。\n\n2）MySQL数据库中，通过lower_case_table_names参数来区别表名的大小写，默认为0，代表大小写敏感。如果是1，代表大小写不敏感，以小写存储。为字段选取数据类型时，要秉承着简单、够用的原则。表中的字段和索引数量都不宜过多，要保证SQL语句查询的高效性，快速执行完，避免出现堵塞、排队现象。\n\n3）表的存储引擎一定要选择使用InnoDB。MySQL 5.7基本已经废弃 MyISAM，8.0后彻底废弃。\n\n4）要显式地为表创建一个使用自增列 INT 或者 BIGINT 类型作为主键，可以保证写入顺序是自增的，和B+tree叶子节点分裂顺序一致。写入更加高效，TPS性能会更高，存储效率也是最高的。\n\n5）金钱、日期时间、IPV4尽量使用 int 来存储。用 int 来存储金钱，让 int 单位为分，这样就不存在四舍五入了，存储的数值更加准确。\n\n​        日期可以选择使用datetime，datetime的可用范围比timestamp大，物理存储上仅比timestamp 多占 1 个字节多的空间，整体性能上的消耗并不算太大。因此在生产环境可以使用datetime时间类型。当然也可以使用 int 来存储时间，通过转换函数 from_unixtime 和 unix_timesstamp来实现。 \n\n​        ![img](/img/mysql时间存储.png)\n\n​        IPV4字段基本上可以不适用char(15)来存储，使用int来存储，通过转换函数 inet_aton 和 inet_ntoa来实现。\n\n​        ![img](/img/mysql的ip存储.png)\n\n​        有些字段比如性别sex字段、状态status字段，基本上选择tinyint就可以。\n\n​\t\t有时候精确计算使用decimal，设计sum等统计数据时候\n\n6）text 和 blob 这种存大量文字或者存图片的大数据类型，建议不要和业务表放在一起。\n\n注：主要业务表切忌出现这样大类型的字段。\n\n​        SQL语句中尽量避免出现 or 子句，这种判断的子句可以让程序自动完成，不要交给数据库判断。也要避免使用union，尽量采用union all，减少去重和排序的工作。\n\n7）用 select 查询表时只需要获取必要的字段，避免使用 select *。这样可以减少网络带宽的消耗，还有可能利用到覆盖索引。\n\n​        建立索引时不要在选择性低的字段上创建，比如sex、status这种字段。\n\n​        索引的选择性计算方法：\n\n​        select count(distinct coll) / count(*) from table_name;  // 越接近 1 ，证明选择性越高，越适合创建索引。\n\nsum()函数容易返回null值，记得处理\n\n8）很长的字符串可以考虑创建前缀索引，提高索引利用率。\n\n​        单表索引数量不要太多，一般建议不要超过 4~5个（根据实际业务表再确定）。当执行DML语句操作时，也会索引进行更新，如果索引数量太多，则会造成索引树的分裂，性能也会下降。\n\n9）所有字段定义中，默认都加上 not null 约束，避免出现 null 。在对该字段进行 select count() 统计计数时，可以让统计结果更准确，因为值为null的数据不会被计算进去。\n\n10）表的字符集默认使用 UTF-8 ，必要时可申请使用 UTF8mb4 字符集。因为它的通用性比 GBK 、Latin1 都要好。UTF8字符集存储汉子占用3个字节，如果遇到表情储存的需求，就可以使用UTF8mb4\n\n11）建议模糊查询 select...like '%**%' 的语句不要出现在数据库中，可以使用搜索引擎sphinx代替。\n\n12）索引字段上面不要使用函数，否则使用不到索引，也不要创建函数索引。\n\n13）join列类型要保持一致，其中包括长度、字符集都要一致。？https://blog.csdn.net/n88Lpo/article/details/78099114\n\n14）当在执行计划中的 extra 项看到 Using filesort，或者看到 Using temporary 时，也要优先考虑创建排序索引和分组索引。（排序、分组字段上都要创建索引）\n\n15）limit 语句上的优化，建议使用主键来进行范围检索，缩短结果集大小，使查询效率更高效。\n\n## 二、算是面试题吧\n\n1）为什么一定要设一个主键？\n\n2）主键是自增还是UUID?\n\n3）主键为什么不推荐有业务含义？\n\n4）表示枚举的字段为什么不用enum类型？\n\n5）为什么不直接存储图片、音频、视频等大容量内容？\n\n6）字段为什么要定义NOT NULL DEFAULT ?\n\n答：\n\n1）为什么一定要设一个主键？\n\n因为在不设置主键的情况下，innodb也会自动生成一个隐藏列，作为自增主键。\n\n所以自己显示指定更可以清晰的看出主键id。\n\n2）主键是自增还是UUID?\n\n自增。innodb中的主键是聚簇索引。如果是自增的主键，插入数据时不会引发页分裂。性能更高。\n\n3）主键为什么不推荐有业务含义？\n\n倘若主键变更会引发很多麻烦；引发页分裂。\n\n4）表示枚举的字段为什么不用enum类型？\n\n枚举字段一般用tinyint类型。因为enum类型order by效率低，而且插入阿拉伯数字有问题。\n\n5）为什么不直接存储图片、音频、视频等大容量内容？\n\n在实际应用中，使用HDFS来存储文件。mysql只用来存储下载地址。\n\n当存文件的时候，比如Base64加密文件等，排序不能使用内存临时表（OOM），必须使用磁盘的临时表，导致查询缓慢；binlog太多，导致主从的效率问题。\n\n所以，不推荐使用text和blob类型。\n\n6）字段为什么要定义NOT NULL DEFAULT ?\n\n有null，count（包含null的列）会出现问题。而且影响索引的性能\n\n## 三、数据结构\n\n需要了解mysql的数据结构才能更加清楚上述效率的问题，请看数据结构篇~~","source":"_posts/mysql表设计及优化.md","raw":"title: mysql表设计及优化\nauthor: 郑天祺\ntags:\n  - mysql\ncategories:\n  - 数据库\ndate: 2019-08-31 15:28:00\n\n---\n\n## 一、一些建议\n\n建议来自《MYSQL 王者晋级之路》，本文做些笔记\n\n1）在创建业务表时，库名、表名、字段名必须使用小写字母，采用 “_” 分割。\n\n2）MySQL数据库中，通过lower_case_table_names参数来区别表名的大小写，默认为0，代表大小写敏感。如果是1，代表大小写不敏感，以小写存储。为字段选取数据类型时，要秉承着简单、够用的原则。表中的字段和索引数量都不宜过多，要保证SQL语句查询的高效性，快速执行完，避免出现堵塞、排队现象。\n\n3）表的存储引擎一定要选择使用InnoDB。MySQL 5.7基本已经废弃 MyISAM，8.0后彻底废弃。\n\n4）要显式地为表创建一个使用自增列 INT 或者 BIGINT 类型作为主键，可以保证写入顺序是自增的，和B+tree叶子节点分裂顺序一致。写入更加高效，TPS性能会更高，存储效率也是最高的。\n\n5）金钱、日期时间、IPV4尽量使用 int 来存储。用 int 来存储金钱，让 int 单位为分，这样就不存在四舍五入了，存储的数值更加准确。\n\n​        日期可以选择使用datetime，datetime的可用范围比timestamp大，物理存储上仅比timestamp 多占 1 个字节多的空间，整体性能上的消耗并不算太大。因此在生产环境可以使用datetime时间类型。当然也可以使用 int 来存储时间，通过转换函数 from_unixtime 和 unix_timesstamp来实现。 \n\n​        ![img](/img/mysql时间存储.png)\n\n​        IPV4字段基本上可以不适用char(15)来存储，使用int来存储，通过转换函数 inet_aton 和 inet_ntoa来实现。\n\n​        ![img](/img/mysql的ip存储.png)\n\n​        有些字段比如性别sex字段、状态status字段，基本上选择tinyint就可以。\n\n​\t\t有时候精确计算使用decimal，设计sum等统计数据时候\n\n6）text 和 blob 这种存大量文字或者存图片的大数据类型，建议不要和业务表放在一起。\n\n注：主要业务表切忌出现这样大类型的字段。\n\n​        SQL语句中尽量避免出现 or 子句，这种判断的子句可以让程序自动完成，不要交给数据库判断。也要避免使用union，尽量采用union all，减少去重和排序的工作。\n\n7）用 select 查询表时只需要获取必要的字段，避免使用 select *。这样可以减少网络带宽的消耗，还有可能利用到覆盖索引。\n\n​        建立索引时不要在选择性低的字段上创建，比如sex、status这种字段。\n\n​        索引的选择性计算方法：\n\n​        select count(distinct coll) / count(*) from table_name;  // 越接近 1 ，证明选择性越高，越适合创建索引。\n\nsum()函数容易返回null值，记得处理\n\n8）很长的字符串可以考虑创建前缀索引，提高索引利用率。\n\n​        单表索引数量不要太多，一般建议不要超过 4~5个（根据实际业务表再确定）。当执行DML语句操作时，也会索引进行更新，如果索引数量太多，则会造成索引树的分裂，性能也会下降。\n\n9）所有字段定义中，默认都加上 not null 约束，避免出现 null 。在对该字段进行 select count() 统计计数时，可以让统计结果更准确，因为值为null的数据不会被计算进去。\n\n10）表的字符集默认使用 UTF-8 ，必要时可申请使用 UTF8mb4 字符集。因为它的通用性比 GBK 、Latin1 都要好。UTF8字符集存储汉子占用3个字节，如果遇到表情储存的需求，就可以使用UTF8mb4\n\n11）建议模糊查询 select...like '%**%' 的语句不要出现在数据库中，可以使用搜索引擎sphinx代替。\n\n12）索引字段上面不要使用函数，否则使用不到索引，也不要创建函数索引。\n\n13）join列类型要保持一致，其中包括长度、字符集都要一致。？https://blog.csdn.net/n88Lpo/article/details/78099114\n\n14）当在执行计划中的 extra 项看到 Using filesort，或者看到 Using temporary 时，也要优先考虑创建排序索引和分组索引。（排序、分组字段上都要创建索引）\n\n15）limit 语句上的优化，建议使用主键来进行范围检索，缩短结果集大小，使查询效率更高效。\n\n## 二、算是面试题吧\n\n1）为什么一定要设一个主键？\n\n2）主键是自增还是UUID?\n\n3）主键为什么不推荐有业务含义？\n\n4）表示枚举的字段为什么不用enum类型？\n\n5）为什么不直接存储图片、音频、视频等大容量内容？\n\n6）字段为什么要定义NOT NULL DEFAULT ?\n\n答：\n\n1）为什么一定要设一个主键？\n\n因为在不设置主键的情况下，innodb也会自动生成一个隐藏列，作为自增主键。\n\n所以自己显示指定更可以清晰的看出主键id。\n\n2）主键是自增还是UUID?\n\n自增。innodb中的主键是聚簇索引。如果是自增的主键，插入数据时不会引发页分裂。性能更高。\n\n3）主键为什么不推荐有业务含义？\n\n倘若主键变更会引发很多麻烦；引发页分裂。\n\n4）表示枚举的字段为什么不用enum类型？\n\n枚举字段一般用tinyint类型。因为enum类型order by效率低，而且插入阿拉伯数字有问题。\n\n5）为什么不直接存储图片、音频、视频等大容量内容？\n\n在实际应用中，使用HDFS来存储文件。mysql只用来存储下载地址。\n\n当存文件的时候，比如Base64加密文件等，排序不能使用内存临时表（OOM），必须使用磁盘的临时表，导致查询缓慢；binlog太多，导致主从的效率问题。\n\n所以，不推荐使用text和blob类型。\n\n6）字段为什么要定义NOT NULL DEFAULT ?\n\n有null，count（包含null的列）会出现问题。而且影响索引的性能\n\n## 三、数据结构\n\n需要了解mysql的数据结构才能更加清楚上述效率的问题，请看数据结构篇~~","slug":"mysql表设计及优化","published":1,"updated":"2019-10-15T10:10:18.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm17001ivguqrm6hqj1h","content":"<h2>一、一些建议</h2>\n<p>建议来自《MYSQL 王者晋级之路》，本文做些笔记</p>\n<p>1）在创建业务表时，库名、表名、字段名必须使用小写字母，采用 “_” 分割。</p>\n<p>2）MySQL数据库中，通过lower_case_table_names参数来区别表名的大小写，默认为0，代表大小写敏感。如果是1，代表大小写不敏感，以小写存储。为字段选取数据类型时，要秉承着简单、够用的原则。表中的字段和索引数量都不宜过多，要保证SQL语句查询的高效性，快速执行完，避免出现堵塞、排队现象。</p>\n<p>3）表的存储引擎一定要选择使用InnoDB。MySQL 5.7基本已经废弃 MyISAM，8.0后彻底废弃。</p>\n<p>4）要显式地为表创建一个使用自增列 INT 或者 BIGINT 类型作为主键，可以保证写入顺序是自增的，和B+tree叶子节点分裂顺序一致。写入更加高效，TPS性能会更高，存储效率也是最高的。</p>\n<p>5）金钱、日期时间、IPV4尽量使用 int 来存储。用 int 来存储金钱，让 int 单位为分，这样就不存在四舍五入了，存储的数值更加准确。</p>\n<p>​        日期可以选择使用datetime，datetime的可用范围比timestamp大，物理存储上仅比timestamp 多占 1 个字节多的空间，整体性能上的消耗并不算太大。因此在生产环境可以使用datetime时间类型。当然也可以使用 int 来存储时间，通过转换函数 from_unixtime 和 unix_timesstamp来实现。</p>\n<p>​        <img src=\"/img/mysql%E6%97%B6%E9%97%B4%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        IPV4字段基本上可以不适用char(15)来存储，使用int来存储，通过转换函数 inet_aton 和 inet_ntoa来实现。</p>\n<p>​        <img src=\"/img/mysql%E7%9A%84ip%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        有些字段比如性别sex字段、状态status字段，基本上选择tinyint就可以。</p>\n<p>​\t\t有时候精确计算使用decimal，设计sum等统计数据时候</p>\n<p>6）text 和 blob 这种存大量文字或者存图片的大数据类型，建议不要和业务表放在一起。</p>\n<p>注：主要业务表切忌出现这样大类型的字段。</p>\n<p>​        SQL语句中尽量避免出现 or 子句，这种判断的子句可以让程序自动完成，不要交给数据库判断。也要避免使用union，尽量采用union all，减少去重和排序的工作。</p>\n<p>7）用 select 查询表时只需要获取必要的字段，避免使用 select *。这样可以减少网络带宽的消耗，还有可能利用到覆盖索引。</p>\n<p>​        建立索引时不要在选择性低的字段上创建，比如sex、status这种字段。</p>\n<p>​        索引的选择性计算方法：</p>\n<p>​        select count(distinct coll) / count(*) from table_name;  // 越接近 1 ，证明选择性越高，越适合创建索引。</p>\n<p>sum()函数容易返回null值，记得处理</p>\n<p>8）很长的字符串可以考虑创建前缀索引，提高索引利用率。</p>\n<p>​        单表索引数量不要太多，一般建议不要超过 4~5个（根据实际业务表再确定）。当执行DML语句操作时，也会索引进行更新，如果索引数量太多，则会造成索引树的分裂，性能也会下降。</p>\n<p>9）所有字段定义中，默认都加上 not null 约束，避免出现 null 。在对该字段进行 select count() 统计计数时，可以让统计结果更准确，因为值为null的数据不会被计算进去。</p>\n<p>10）表的字符集默认使用 UTF-8 ，必要时可申请使用 UTF8mb4 字符集。因为它的通用性比 GBK 、Latin1 都要好。UTF8字符集存储汉子占用3个字节，如果遇到表情储存的需求，就可以使用UTF8mb4</p>\n<p>11）建议模糊查询 select...like '%**%' 的语句不要出现在数据库中，可以使用搜索引擎sphinx代替。</p>\n<p>12）索引字段上面不要使用函数，否则使用不到索引，也不要创建函数索引。</p>\n<p>13）join列类型要保持一致，其中包括长度、字符集都要一致。？https://blog.csdn.net/n88Lpo/article/details/78099114</p>\n<p>14）当在执行计划中的 extra 项看到 Using filesort，或者看到 Using temporary 时，也要优先考虑创建排序索引和分组索引。（排序、分组字段上都要创建索引）</p>\n<p>15）limit 语句上的优化，建议使用主键来进行范围检索，缩短结果集大小，使查询效率更高效。</p>\n<h2>二、算是面试题吧</h2>\n<p>1）为什么一定要设一个主键？</p>\n<p>2）主键是自增还是UUID?</p>\n<p>3）主键为什么不推荐有业务含义？</p>\n<p>4）表示枚举的字段为什么不用enum类型？</p>\n<p>5）为什么不直接存储图片、音频、视频等大容量内容？</p>\n<p>6）字段为什么要定义NOT NULL DEFAULT ?</p>\n<p>答：</p>\n<p>1）为什么一定要设一个主键？</p>\n<p>因为在不设置主键的情况下，innodb也会自动生成一个隐藏列，作为自增主键。</p>\n<p>所以自己显示指定更可以清晰的看出主键id。</p>\n<p>2）主键是自增还是UUID?</p>\n<p>自增。innodb中的主键是聚簇索引。如果是自增的主键，插入数据时不会引发页分裂。性能更高。</p>\n<p>3）主键为什么不推荐有业务含义？</p>\n<p>倘若主键变更会引发很多麻烦；引发页分裂。</p>\n<p>4）表示枚举的字段为什么不用enum类型？</p>\n<p>枚举字段一般用tinyint类型。因为enum类型order by效率低，而且插入阿拉伯数字有问题。</p>\n<p>5）为什么不直接存储图片、音频、视频等大容量内容？</p>\n<p>在实际应用中，使用HDFS来存储文件。mysql只用来存储下载地址。</p>\n<p>当存文件的时候，比如Base64加密文件等，排序不能使用内存临时表（OOM），必须使用磁盘的临时表，导致查询缓慢；binlog太多，导致主从的效率问题。</p>\n<p>所以，不推荐使用text和blob类型。</p>\n<p>6）字段为什么要定义NOT NULL DEFAULT ?</p>\n<p>有null，count（包含null的列）会出现问题。而且影响索引的性能</p>\n<h2>三、数据结构</h2>\n<p>需要了解mysql的数据结构才能更加清楚上述效率的问题，请看数据结构篇~~</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>一、一些建议</h2>\n<p>建议来自《MYSQL 王者晋级之路》，本文做些笔记</p>\n<p>1）在创建业务表时，库名、表名、字段名必须使用小写字母，采用 “_” 分割。</p>\n<p>2）MySQL数据库中，通过lower_case_table_names参数来区别表名的大小写，默认为0，代表大小写敏感。如果是1，代表大小写不敏感，以小写存储。为字段选取数据类型时，要秉承着简单、够用的原则。表中的字段和索引数量都不宜过多，要保证SQL语句查询的高效性，快速执行完，避免出现堵塞、排队现象。</p>\n<p>3）表的存储引擎一定要选择使用InnoDB。MySQL 5.7基本已经废弃 MyISAM，8.0后彻底废弃。</p>\n<p>4）要显式地为表创建一个使用自增列 INT 或者 BIGINT 类型作为主键，可以保证写入顺序是自增的，和B+tree叶子节点分裂顺序一致。写入更加高效，TPS性能会更高，存储效率也是最高的。</p>\n<p>5）金钱、日期时间、IPV4尽量使用 int 来存储。用 int 来存储金钱，让 int 单位为分，这样就不存在四舍五入了，存储的数值更加准确。</p>\n<p>​        日期可以选择使用datetime，datetime的可用范围比timestamp大，物理存储上仅比timestamp 多占 1 个字节多的空间，整体性能上的消耗并不算太大。因此在生产环境可以使用datetime时间类型。当然也可以使用 int 来存储时间，通过转换函数 from_unixtime 和 unix_timesstamp来实现。</p>\n<p>​        <img src=\"/img/mysql%E6%97%B6%E9%97%B4%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        IPV4字段基本上可以不适用char(15)来存储，使用int来存储，通过转换函数 inet_aton 和 inet_ntoa来实现。</p>\n<p>​        <img src=\"/img/mysql%E7%9A%84ip%E5%AD%98%E5%82%A8.png\" alt=\"img\"></p>\n<p>​        有些字段比如性别sex字段、状态status字段，基本上选择tinyint就可以。</p>\n<p>​\t\t有时候精确计算使用decimal，设计sum等统计数据时候</p>\n<p>6）text 和 blob 这种存大量文字或者存图片的大数据类型，建议不要和业务表放在一起。</p>\n<p>注：主要业务表切忌出现这样大类型的字段。</p>\n<p>​        SQL语句中尽量避免出现 or 子句，这种判断的子句可以让程序自动完成，不要交给数据库判断。也要避免使用union，尽量采用union all，减少去重和排序的工作。</p>\n<p>7）用 select 查询表时只需要获取必要的字段，避免使用 select *。这样可以减少网络带宽的消耗，还有可能利用到覆盖索引。</p>\n<p>​        建立索引时不要在选择性低的字段上创建，比如sex、status这种字段。</p>\n<p>​        索引的选择性计算方法：</p>\n<p>​        select count(distinct coll) / count(*) from table_name;  // 越接近 1 ，证明选择性越高，越适合创建索引。</p>\n<p>sum()函数容易返回null值，记得处理</p>\n<p>8）很长的字符串可以考虑创建前缀索引，提高索引利用率。</p>\n<p>​        单表索引数量不要太多，一般建议不要超过 4~5个（根据实际业务表再确定）。当执行DML语句操作时，也会索引进行更新，如果索引数量太多，则会造成索引树的分裂，性能也会下降。</p>\n<p>9）所有字段定义中，默认都加上 not null 约束，避免出现 null 。在对该字段进行 select count() 统计计数时，可以让统计结果更准确，因为值为null的数据不会被计算进去。</p>\n<p>10）表的字符集默认使用 UTF-8 ，必要时可申请使用 UTF8mb4 字符集。因为它的通用性比 GBK 、Latin1 都要好。UTF8字符集存储汉子占用3个字节，如果遇到表情储存的需求，就可以使用UTF8mb4</p>\n<p>11）建议模糊查询 select...like '%**%' 的语句不要出现在数据库中，可以使用搜索引擎sphinx代替。</p>\n<p>12）索引字段上面不要使用函数，否则使用不到索引，也不要创建函数索引。</p>\n<p>13）join列类型要保持一致，其中包括长度、字符集都要一致。？https://blog.csdn.net/n88Lpo/article/details/78099114</p>\n<p>14）当在执行计划中的 extra 项看到 Using filesort，或者看到 Using temporary 时，也要优先考虑创建排序索引和分组索引。（排序、分组字段上都要创建索引）</p>\n<p>15）limit 语句上的优化，建议使用主键来进行范围检索，缩短结果集大小，使查询效率更高效。</p>\n<h2>二、算是面试题吧</h2>\n<p>1）为什么一定要设一个主键？</p>\n<p>2）主键是自增还是UUID?</p>\n<p>3）主键为什么不推荐有业务含义？</p>\n<p>4）表示枚举的字段为什么不用enum类型？</p>\n<p>5）为什么不直接存储图片、音频、视频等大容量内容？</p>\n<p>6）字段为什么要定义NOT NULL DEFAULT ?</p>\n<p>答：</p>\n<p>1）为什么一定要设一个主键？</p>\n<p>因为在不设置主键的情况下，innodb也会自动生成一个隐藏列，作为自增主键。</p>\n<p>所以自己显示指定更可以清晰的看出主键id。</p>\n<p>2）主键是自增还是UUID?</p>\n<p>自增。innodb中的主键是聚簇索引。如果是自增的主键，插入数据时不会引发页分裂。性能更高。</p>\n<p>3）主键为什么不推荐有业务含义？</p>\n<p>倘若主键变更会引发很多麻烦；引发页分裂。</p>\n<p>4）表示枚举的字段为什么不用enum类型？</p>\n<p>枚举字段一般用tinyint类型。因为enum类型order by效率低，而且插入阿拉伯数字有问题。</p>\n<p>5）为什么不直接存储图片、音频、视频等大容量内容？</p>\n<p>在实际应用中，使用HDFS来存储文件。mysql只用来存储下载地址。</p>\n<p>当存文件的时候，比如Base64加密文件等，排序不能使用内存临时表（OOM），必须使用磁盘的临时表，导致查询缓慢；binlog太多，导致主从的效率问题。</p>\n<p>所以，不推荐使用text和blob类型。</p>\n<p>6）字段为什么要定义NOT NULL DEFAULT ?</p>\n<p>有null，count（包含null的列）会出现问题。而且影响索引的性能</p>\n<h2>三、数据结构</h2>\n<p>需要了解mysql的数据结构才能更加清楚上述效率的问题，请看数据结构篇~~</p>\n"},{"title":"互斥锁","author":"郑天祺","date":"2019-08-31T05:13:00.000Z","_content":"\n## 1、关于“互斥”和“同步”的概念\n\n互斥 : 就是线程A访问了一组数据，线程BCD就不能同时访问这些数据，直到A停止访问了\n同步 : 就是ABCD这些线程要约定一个执行的协调顺序，比如D要执行，B和C必须都得做完，而B和C要开始，A必须先得做完。\n\n互斥 ：就是不同线程通过竞争进入临界区（共享的数据和硬件资源），为了防止访问冲突，在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写\n\n同步 ：关系则是多个线程彼此合作，通过一定的逻辑关系来共同完成一个任务。一般来说，同步关系中往往包含互斥，同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用\n\n总的来说，两者的区别就是：\n\n互斥是通过竞争对资源的独占使用，彼此之间不需要知道对方的存在，执行顺序是一个乱序。\n\n同步是协调多个相互关联线程合作完synchronized不同用法锁对象说明\n\n## 2、JAVA中synchronized和Lock是互斥锁\n\n 修饰在静态方法上，锁对象是当前类的Class对象\n 修饰在实例方法上，锁对象是当前实例对象\n 同步块中，锁对象是synchronized括号后面的对象成任务，彼此之间知道对方存在，执行顺序往往是有序的。\n\n## 3、synchronized的用法\n\n```java\n/** 如下demo的4个方法展示了不同使用方法下锁对象 **/\n public class SynchronizedDemo {\n\n    private static final Object LOCK = new Object();\n\n    public static synchronized void s1(){\n         System.out.println(\"类同步方法，锁对象是当前Class对象\");\n     }\n\n    public synchronized void s2() {\n         System.out.println(\"实例同步方法，锁对象是当前对象\");\n     }\n\n    public void s3() {\n         synchronized (LOCK) {\n             System.out.println(\"同步块，锁对象是LOCK对象\");\n         }\n     }\n\n    public void s4() {\n         synchronized (SynchronizedDemo.class) {\n             System.out.println(\"同步块，锁对象和静态同步方法的锁对象一样都是当前Class对象\");\n         }\n     }\n\n}\n\n \n```\n\n","source":"_posts/互斥锁.md","raw":"title: 互斥锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:13:00\n\n---\n\n## 1、关于“互斥”和“同步”的概念\n\n互斥 : 就是线程A访问了一组数据，线程BCD就不能同时访问这些数据，直到A停止访问了\n同步 : 就是ABCD这些线程要约定一个执行的协调顺序，比如D要执行，B和C必须都得做完，而B和C要开始，A必须先得做完。\n\n互斥 ：就是不同线程通过竞争进入临界区（共享的数据和硬件资源），为了防止访问冲突，在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写\n\n同步 ：关系则是多个线程彼此合作，通过一定的逻辑关系来共同完成一个任务。一般来说，同步关系中往往包含互斥，同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用\n\n总的来说，两者的区别就是：\n\n互斥是通过竞争对资源的独占使用，彼此之间不需要知道对方的存在，执行顺序是一个乱序。\n\n同步是协调多个相互关联线程合作完synchronized不同用法锁对象说明\n\n## 2、JAVA中synchronized和Lock是互斥锁\n\n 修饰在静态方法上，锁对象是当前类的Class对象\n 修饰在实例方法上，锁对象是当前实例对象\n 同步块中，锁对象是synchronized括号后面的对象成任务，彼此之间知道对方存在，执行顺序往往是有序的。\n\n## 3、synchronized的用法\n\n```java\n/** 如下demo的4个方法展示了不同使用方法下锁对象 **/\n public class SynchronizedDemo {\n\n    private static final Object LOCK = new Object();\n\n    public static synchronized void s1(){\n         System.out.println(\"类同步方法，锁对象是当前Class对象\");\n     }\n\n    public synchronized void s2() {\n         System.out.println(\"实例同步方法，锁对象是当前对象\");\n     }\n\n    public void s3() {\n         synchronized (LOCK) {\n             System.out.println(\"同步块，锁对象是LOCK对象\");\n         }\n     }\n\n    public void s4() {\n         synchronized (SynchronizedDemo.class) {\n             System.out.println(\"同步块，锁对象和静态同步方法的锁对象一样都是当前Class对象\");\n         }\n     }\n\n}\n\n \n```\n\n","slug":"互斥锁","published":1,"updated":"2019-10-15T10:10:39.998Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1a001mvguqgq7c7qfj","content":"<h2>1、关于“互斥”和“同步”的概念</h2>\n<p>互斥 : 就是线程A访问了一组数据，线程BCD就不能同时访问这些数据，直到A停止访问了\n同步 : 就是ABCD这些线程要约定一个执行的协调顺序，比如D要执行，B和C必须都得做完，而B和C要开始，A必须先得做完。</p>\n<p>互斥 ：就是不同线程通过竞争进入临界区（共享的数据和硬件资源），为了防止访问冲突，在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写</p>\n<p>同步 ：关系则是多个线程彼此合作，通过一定的逻辑关系来共同完成一个任务。一般来说，同步关系中往往包含互斥，同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用</p>\n<p>总的来说，两者的区别就是：</p>\n<p>互斥是通过竞争对资源的独占使用，彼此之间不需要知道对方的存在，执行顺序是一个乱序。</p>\n<p>同步是协调多个相互关联线程合作完synchronized不同用法锁对象说明</p>\n<h2>2、JAVA中synchronized和Lock是互斥锁</h2>\n<p>修饰在静态方法上，锁对象是当前类的Class对象\n修饰在实例方法上，锁对象是当前实例对象\n同步块中，锁对象是synchronized括号后面的对象成任务，彼此之间知道对方存在，执行顺序往往是有序的。</p>\n<h2>3、synchronized的用法</h2>\n<pre><code class=\"language-java\">/** 如下demo的4个方法展示了不同使用方法下锁对象 **/\n public class SynchronizedDemo {\n\n    private static final Object LOCK = new Object();\n\n    public static synchronized void s1(){\n         System.out.println(&quot;类同步方法，锁对象是当前Class对象&quot;);\n     }\n\n    public synchronized void s2() {\n         System.out.println(&quot;实例同步方法，锁对象是当前对象&quot;);\n     }\n\n    public void s3() {\n         synchronized (LOCK) {\n             System.out.println(&quot;同步块，锁对象是LOCK对象&quot;);\n         }\n     }\n\n    public void s4() {\n         synchronized (SynchronizedDemo.class) {\n             System.out.println(&quot;同步块，锁对象和静态同步方法的锁对象一样都是当前Class对象&quot;);\n         }\n     }\n\n}\n\n \n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、关于“互斥”和“同步”的概念</h2>\n<p>互斥 : 就是线程A访问了一组数据，线程BCD就不能同时访问这些数据，直到A停止访问了\n同步 : 就是ABCD这些线程要约定一个执行的协调顺序，比如D要执行，B和C必须都得做完，而B和C要开始，A必须先得做完。</p>\n<p>互斥 ：就是不同线程通过竞争进入临界区（共享的数据和硬件资源），为了防止访问冲突，在有限的时间内只允许其中之一独占性的使用共享资源。如不允许同时写</p>\n<p>同步 ：关系则是多个线程彼此合作，通过一定的逻辑关系来共同完成一个任务。一般来说，同步关系中往往包含互斥，同时对临界区的资源会按照某种逻辑顺序进行访问。如先生产后使用</p>\n<p>总的来说，两者的区别就是：</p>\n<p>互斥是通过竞争对资源的独占使用，彼此之间不需要知道对方的存在，执行顺序是一个乱序。</p>\n<p>同步是协调多个相互关联线程合作完synchronized不同用法锁对象说明</p>\n<h2>2、JAVA中synchronized和Lock是互斥锁</h2>\n<p>修饰在静态方法上，锁对象是当前类的Class对象\n修饰在实例方法上，锁对象是当前实例对象\n同步块中，锁对象是synchronized括号后面的对象成任务，彼此之间知道对方存在，执行顺序往往是有序的。</p>\n<h2>3、synchronized的用法</h2>\n<pre><code class=\"language-java\">/** 如下demo的4个方法展示了不同使用方法下锁对象 **/\n public class SynchronizedDemo {\n\n    private static final Object LOCK = new Object();\n\n    public static synchronized void s1(){\n         System.out.println(&quot;类同步方法，锁对象是当前Class对象&quot;);\n     }\n\n    public synchronized void s2() {\n         System.out.println(&quot;实例同步方法，锁对象是当前对象&quot;);\n     }\n\n    public void s3() {\n         synchronized (LOCK) {\n             System.out.println(&quot;同步块，锁对象是LOCK对象&quot;);\n         }\n     }\n\n    public void s4() {\n         synchronized (SynchronizedDemo.class) {\n             System.out.println(&quot;同步块，锁对象和静态同步方法的锁对象一样都是当前Class对象&quot;);\n         }\n     }\n\n}\n\n \n</code></pre>\n"},{"title":"分布式全局唯一ID生成策略","author":"郑天祺","date":"2019-10-09T04:00:00.000Z","_content":"\n# 一、需求\n\n在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。\n\n当需要将节点之间在不同时间的交互做唯一标识，数据日渐增长，\n\n对数据库的分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。\n\n此时一个能够生成全局唯一ID的系统是非常必要的。\n\n \n\n# 二、ID生成的原则：\n\n1、全局唯一性：不能出现重复的ID（最基本的要求）\n\n2、高性能，低延迟。（不要太繁杂的算法）\n\n3、易于存储，（占用较低的空间）\n\n \n\n# 三、相对应的算法：\n\n## 1、雪花算法 snowflake\n\n![1570599617667](/img/雪花算法.png)\n\n1位标识：由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0\n\n41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。可以使用69年，年T = (1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69\n\n10位机器标识码：可以部署在1024个节点（2^10=1024），如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。（但是这个也是会重复的网上说法木有参考性，可以改为TPM安全芯片、网卡等的唯一标识码，原则上他们是全球唯一的）\n\n12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号\n\n### **（1）优点：**\n\n时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。（排序方便，会有很多好处）\n\n灵活度高，可以根据业务需求，调整bit位的划分\n\n不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的（多一个依赖的组件，多一个风险，并增加了系统的复杂性）\n\n### **（2）缺点：**\n\n依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。（网上有优化时钟回拨问题利用记录最后一次成ID的时间，也可利用zookeeper、redis中间件）\n\n在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。\n\n应用举例：\n\nMongdb objectID\n\n可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。\n\n## 2、UUID\n\nUUID是Universally Unique Identifier的缩写，它是在一定的范围内（从特定的名字空间到全球）唯一的机器生成的标识符。（微软叫GUID：Globally Unique Identifier）\n\n为了保证UUID的唯一性，规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。\n\n（1）基于时间的UUID\n\n基于时间的UUID通过计算当前时间戳、随机数和机器MAC地址得到。由于在算法中使用了MAC地址，这个版本的UUID可以保证在全球范围的唯一性。但与此同时，使用MAC地址会带来安全性问题（曾被用于寻找梅丽莎病毒的制作者位置）。如果应用只是在局域网中使用，也可以使用退化的算法，以IP地址来代替MAC地址－－Java的UUID往往是这样实现的（当然也考虑了获取MAC的难度）。\n\n（2）DCE安全的UUID\n\nDCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。\n\n（3）基于名字的UUID（MD5）\n\n基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。\n\n（4) 随机UUID\n\n根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但随机的东西就像是买彩票：你指望它发财是不可能的，但狗屎运通常会在不经意中到来。\n\n(5) 基于名字的UUID（SHA1）\n\n和版本3的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。\n\n### (1)    优点：\n\n性能非常高：本地生成，没有网络消耗。\n\n### (2)    缺点：\n\n不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用\n\n信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露\n\nID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用（mysql主键索引是B+树，推荐使用自增存储效率高）\n\n## 3、利用数据库\n\n步长需设置为N，每台的初始值依次为0,1,2…N-1那么整个架构就变成了如下图所示：\n\n![1570600564344](/img/数据库分布式ID生成.png)\n\n美团Leaf-segment方案直接取一批号段，用完再取一批号段，避免每次都去请求数据库导致连接数和线程数过大。\n\n \n\n# 参考文档：\n\nMongdb objectID: https://docs.mongodb.com/manual/reference/method/ObjectId/#description\nLeaf——美团点评分布式ID生成系统: https://tech.meituan.com/2017/04/21/mt-leaf.html\n分布式ID生成 - 雪花算法: https://blog.csdn.net/u012488504/article/details/82194495\n梅丽莎病毒: https://baike.baidu.com/item/梅丽莎病毒/9739231\nmysql中InnoDB表为什么要建议用自增列做主键: https://www.cnblogs.com/moyand/p/9013663.html\n\n\n\n\n\n ","source":"_posts/分布式全局唯一ID生成策略.md","raw":"title: 分布式全局唯一ID生成策略\nauthor: 郑天祺\ntags:\n\n  - 分布式\ncategories:\n  - 分布式\ndate: 2019-10-09 12:00:00\n\n---\n\n# 一、需求\n\n在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。\n\n当需要将节点之间在不同时间的交互做唯一标识，数据日渐增长，\n\n对数据库的分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。\n\n此时一个能够生成全局唯一ID的系统是非常必要的。\n\n \n\n# 二、ID生成的原则：\n\n1、全局唯一性：不能出现重复的ID（最基本的要求）\n\n2、高性能，低延迟。（不要太繁杂的算法）\n\n3、易于存储，（占用较低的空间）\n\n \n\n# 三、相对应的算法：\n\n## 1、雪花算法 snowflake\n\n![1570599617667](/img/雪花算法.png)\n\n1位标识：由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0\n\n41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。可以使用69年，年T = (1L << 41) / (1000L * 60 * 60 * 24 * 365) = 69\n\n10位机器标识码：可以部署在1024个节点（2^10=1024），如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。（但是这个也是会重复的网上说法木有参考性，可以改为TPM安全芯片、网卡等的唯一标识码，原则上他们是全球唯一的）\n\n12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号\n\n### **（1）优点：**\n\n时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。（排序方便，会有很多好处）\n\n灵活度高，可以根据业务需求，调整bit位的划分\n\n不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的（多一个依赖的组件，多一个风险，并增加了系统的复杂性）\n\n### **（2）缺点：**\n\n依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。（网上有优化时钟回拨问题利用记录最后一次成ID的时间，也可利用zookeeper、redis中间件）\n\n在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。\n\n应用举例：\n\nMongdb objectID\n\n可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。\n\n## 2、UUID\n\nUUID是Universally Unique Identifier的缩写，它是在一定的范围内（从特定的名字空间到全球）唯一的机器生成的标识符。（微软叫GUID：Globally Unique Identifier）\n\n为了保证UUID的唯一性，规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。\n\n（1）基于时间的UUID\n\n基于时间的UUID通过计算当前时间戳、随机数和机器MAC地址得到。由于在算法中使用了MAC地址，这个版本的UUID可以保证在全球范围的唯一性。但与此同时，使用MAC地址会带来安全性问题（曾被用于寻找梅丽莎病毒的制作者位置）。如果应用只是在局域网中使用，也可以使用退化的算法，以IP地址来代替MAC地址－－Java的UUID往往是这样实现的（当然也考虑了获取MAC的难度）。\n\n（2）DCE安全的UUID\n\nDCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。\n\n（3）基于名字的UUID（MD5）\n\n基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。\n\n（4) 随机UUID\n\n根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但随机的东西就像是买彩票：你指望它发财是不可能的，但狗屎运通常会在不经意中到来。\n\n(5) 基于名字的UUID（SHA1）\n\n和版本3的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。\n\n### (1)    优点：\n\n性能非常高：本地生成，没有网络消耗。\n\n### (2)    缺点：\n\n不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用\n\n信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露\n\nID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用（mysql主键索引是B+树，推荐使用自增存储效率高）\n\n## 3、利用数据库\n\n步长需设置为N，每台的初始值依次为0,1,2…N-1那么整个架构就变成了如下图所示：\n\n![1570600564344](/img/数据库分布式ID生成.png)\n\n美团Leaf-segment方案直接取一批号段，用完再取一批号段，避免每次都去请求数据库导致连接数和线程数过大。\n\n \n\n# 参考文档：\n\nMongdb objectID: https://docs.mongodb.com/manual/reference/method/ObjectId/#description\nLeaf——美团点评分布式ID生成系统: https://tech.meituan.com/2017/04/21/mt-leaf.html\n分布式ID生成 - 雪花算法: https://blog.csdn.net/u012488504/article/details/82194495\n梅丽莎病毒: https://baike.baidu.com/item/梅丽莎病毒/9739231\nmysql中InnoDB表为什么要建议用自增列做主键: https://www.cnblogs.com/moyand/p/9013663.html\n\n\n\n\n\n ","slug":"分布式全局唯一ID生成策略","published":1,"updated":"2019-10-15T10:05:44.357Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1c001qvguqd7mdz42i","content":"<h1>一、需求</h1>\n<p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。</p>\n<p>当需要将节点之间在不同时间的交互做唯一标识，数据日渐增长，</p>\n<p>对数据库的分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。</p>\n<p>此时一个能够生成全局唯一ID的系统是非常必要的。</p>\n<h1>二、ID生成的原则：</h1>\n<p>1、全局唯一性：不能出现重复的ID（最基本的要求）</p>\n<p>2、高性能，低延迟。（不要太繁杂的算法）</p>\n<p>3、易于存储，（占用较低的空间）</p>\n<h1>三、相对应的算法：</h1>\n<h2>1、雪花算法 snowflake</h2>\n<p><img src=\"/img/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95.png\" alt=\"1570599617667\"></p>\n<p>1位标识：由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0</p>\n<p>41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69</p>\n<p>10位机器标识码：可以部署在1024个节点（2^10=1024），如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。（但是这个也是会重复的网上说法木有参考性，可以改为TPM安全芯片、网卡等的唯一标识码，原则上他们是全球唯一的）</p>\n<p>12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号</p>\n<h3><strong>（1）优点：</strong></h3>\n<p>时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。（排序方便，会有很多好处）</p>\n<p>灵活度高，可以根据业务需求，调整bit位的划分</p>\n<p>不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的（多一个依赖的组件，多一个风险，并增加了系统的复杂性）</p>\n<h3><strong>（2）缺点：</strong></h3>\n<p>依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。（网上有优化时钟回拨问题利用记录最后一次成ID的时间，也可利用zookeeper、redis中间件）</p>\n<p>在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。</p>\n<p>应用举例：</p>\n<p>Mongdb objectID</p>\n<p>可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。</p>\n<h2>2、UUID</h2>\n<p>UUID是Universally Unique Identifier的缩写，它是在一定的范围内（从特定的名字空间到全球）唯一的机器生成的标识符。（微软叫GUID：Globally Unique Identifier）</p>\n<p>为了保证UUID的唯一性，规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。</p>\n<p>（1）基于时间的UUID</p>\n<p>基于时间的UUID通过计算当前时间戳、随机数和机器MAC地址得到。由于在算法中使用了MAC地址，这个版本的UUID可以保证在全球范围的唯一性。但与此同时，使用MAC地址会带来安全性问题（曾被用于寻找梅丽莎病毒的制作者位置）。如果应用只是在局域网中使用，也可以使用退化的算法，以IP地址来代替MAC地址－－Java的UUID往往是这样实现的（当然也考虑了获取MAC的难度）。</p>\n<p>（2）DCE安全的UUID</p>\n<p>DCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。</p>\n<p>（3）基于名字的UUID（MD5）</p>\n<p>基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。</p>\n<p>（4) 随机UUID</p>\n<p>根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但随机的东西就像是买彩票：你指望它发财是不可能的，但狗屎运通常会在不经意中到来。</p>\n<p>(5) 基于名字的UUID（SHA1）</p>\n<p>和版本3的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。</p>\n<h3>(1)    优点：</h3>\n<p>性能非常高：本地生成，没有网络消耗。</p>\n<h3>(2)    缺点：</h3>\n<p>不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用</p>\n<p>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露</p>\n<p>ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用（mysql主键索引是B+树，推荐使用自增存储效率高）</p>\n<h2>3、利用数据库</h2>\n<p>步长需设置为N，每台的初始值依次为0,1,2…N-1那么整个架构就变成了如下图所示：</p>\n<p><img src=\"/img/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90.png\" alt=\"1570600564344\"></p>\n<p>美团Leaf-segment方案直接取一批号段，用完再取一批号段，避免每次都去请求数据库导致连接数和线程数过大。</p>\n<h1>参考文档：</h1>\n<p>Mongdb objectID: https://docs.mongodb.com/manual/reference/method/ObjectId/#description\nLeaf——美团点评分布式ID生成系统: https://tech.meituan.com/2017/04/21/mt-leaf.html\n分布式ID生成 - 雪花算法: https://blog.csdn.net/u012488504/article/details/82194495\n梅丽莎病毒: https://baike.baidu.com/item/梅丽莎病毒/9739231\nmysql中InnoDB表为什么要建议用自增列做主键: https://www.cnblogs.com/moyand/p/9013663.html</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、需求</h1>\n<p>在复杂分布式系统中，往往需要对大量的数据和消息进行唯一标识。</p>\n<p>当需要将节点之间在不同时间的交互做唯一标识，数据日渐增长，</p>\n<p>对数据库的分库分表后需要有一个唯一ID来标识一条数据或消息，数据库的自增ID显然不能满足需求。</p>\n<p>此时一个能够生成全局唯一ID的系统是非常必要的。</p>\n<h1>二、ID生成的原则：</h1>\n<p>1、全局唯一性：不能出现重复的ID（最基本的要求）</p>\n<p>2、高性能，低延迟。（不要太繁杂的算法）</p>\n<p>3、易于存储，（占用较低的空间）</p>\n<h1>三、相对应的算法：</h1>\n<h2>1、雪花算法 snowflake</h2>\n<p><img src=\"/img/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95.png\" alt=\"1570599617667\"></p>\n<p>1位标识：由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0</p>\n<p>41位时间戳：41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截 )得到的值，这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的。可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69</p>\n<p>10位机器标识码：可以部署在1024个节点（2^10=1024），如果机器分机房（IDC）部署，这10位可以由 5位机房ID + 5位机器ID 组成。（但是这个也是会重复的网上说法木有参考性，可以改为TPM安全芯片、网卡等的唯一标识码，原则上他们是全球唯一的）</p>\n<p>12位序列：毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号</p>\n<h3><strong>（1）优点：</strong></h3>\n<p>时间戳在高位，自增序列在低位，整个ID是趋势递增的，按照时间有序递增。（排序方便，会有很多好处）</p>\n<p>灵活度高，可以根据业务需求，调整bit位的划分</p>\n<p>不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的（多一个依赖的组件，多一个风险，并增加了系统的复杂性）</p>\n<h3><strong>（2）缺点：</strong></h3>\n<p>依赖机器的时钟，如果服务器时钟回拨，会导致重复ID生成。（网上有优化时钟回拨问题利用记录最后一次成ID的时间，也可利用zookeeper、redis中间件）</p>\n<p>在分布式环境上，每个服务器的时钟不可能完全同步，有时会出现不是全局递增的情况。</p>\n<p>应用举例：</p>\n<p>Mongdb objectID</p>\n<p>可以算作是和snowflake类似方法，通过“时间+机器码+pid+inc”共12个字节，通过4+3+2+3的方式最终标识成一个24长度的十六进制字符。</p>\n<h2>2、UUID</h2>\n<p>UUID是Universally Unique Identifier的缩写，它是在一定的范围内（从特定的名字空间到全球）唯一的机器生成的标识符。（微软叫GUID：Globally Unique Identifier）</p>\n<p>为了保证UUID的唯一性，规范定义了包括网卡MAC地址、时间戳、名字空间（Namespace）、随机或伪随机数、时序等元素，以及从这些元素生成UUID的算法。UUID的复杂特性在保证了其唯一性的同时，意味着只能由计算机生成。</p>\n<p>（1）基于时间的UUID</p>\n<p>基于时间的UUID通过计算当前时间戳、随机数和机器MAC地址得到。由于在算法中使用了MAC地址，这个版本的UUID可以保证在全球范围的唯一性。但与此同时，使用MAC地址会带来安全性问题（曾被用于寻找梅丽莎病毒的制作者位置）。如果应用只是在局域网中使用，也可以使用退化的算法，以IP地址来代替MAC地址－－Java的UUID往往是这样实现的（当然也考虑了获取MAC的难度）。</p>\n<p>（2）DCE安全的UUID</p>\n<p>DCE（Distributed Computing Environment）安全的UUID和基于时间的UUID算法相同，但会把时间戳的前4位置换为POSIX的UID或GID。这个版本的UUID在实际中较少用到。</p>\n<p>（3）基于名字的UUID（MD5）</p>\n<p>基于名字的UUID通过计算名字和名字空间的MD5散列值得到。这个版本的UUID保证了：相同名字空间中不同名字生成的UUID的唯一性；不同名字空间中的UUID的唯一性；相同名字空间中相同名字的UUID重复生成是相同的。</p>\n<p>（4) 随机UUID</p>\n<p>根据随机数，或者伪随机数生成UUID。这种UUID产生重复的概率是可以计算出来的，但随机的东西就像是买彩票：你指望它发财是不可能的，但狗屎运通常会在不经意中到来。</p>\n<p>(5) 基于名字的UUID（SHA1）</p>\n<p>和版本3的UUID算法类似，只是散列值计算使用SHA1（Secure Hash Algorithm 1）算法。</p>\n<h3>(1)    优点：</h3>\n<p>性能非常高：本地生成，没有网络消耗。</p>\n<h3>(2)    缺点：</h3>\n<p>不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用</p>\n<p>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露</p>\n<p>ID作为主键时在特定的环境会存在一些问题，比如做DB主键的场景下，UUID就非常不适用（mysql主键索引是B+树，推荐使用自增存储效率高）</p>\n<h2>3、利用数据库</h2>\n<p>步长需设置为N，每台的初始值依次为0,1,2…N-1那么整个架构就变成了如下图所示：</p>\n<p><img src=\"/img/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E5%B8%83%E5%BC%8FID%E7%94%9F%E6%88%90.png\" alt=\"1570600564344\"></p>\n<p>美团Leaf-segment方案直接取一批号段，用完再取一批号段，避免每次都去请求数据库导致连接数和线程数过大。</p>\n<h1>参考文档：</h1>\n<p>Mongdb objectID: https://docs.mongodb.com/manual/reference/method/ObjectId/#description\nLeaf——美团点评分布式ID生成系统: https://tech.meituan.com/2017/04/21/mt-leaf.html\n分布式ID生成 - 雪花算法: https://blog.csdn.net/u012488504/article/details/82194495\n梅丽莎病毒: https://baike.baidu.com/item/梅丽莎病毒/9739231\nmysql中InnoDB表为什么要建议用自增列做主键: https://www.cnblogs.com/moyand/p/9013663.html</p>\n"},{"title":"可信与可信计算","author":"郑天祺","date":"2019-09-28T08:55:00.000Z","_content":"\n一、“可信”有比较多的定义\n\n（1）TCG用实体行为的预期性来定义 “可信” ：如果一个实体的行为是预期的方式符合预期的目标，则该实体是可信的。\n\n（2）ISO/IEC 15408标准定义“可信”为：参与计算的组件、操作或过程在任意条件下是可预测的，并能够抵御病毒和物理干扰。\n\n（3）IEEE CS可信计算技术委员会（IEEE ComputerSocietyTechnical Committeeon Dependable Computing）所谓 “可信” 是指计算机系统所提供的服务是可以论证其是可信赖的，即不仅计算机系统所提供的服务是可信赖的，而且这种可信赖还是可论证的。这种可信依赖更多地指系统的可靠性、可用性和可维护性。\n\n（4）我国著名的信息安全专家沈昌祥院士对上述定义进行了综合和拓展，他认为“可信”要做到一个实体在实现给定目标对其行为总是同预期的结果一样，强调行为结果的可预测性和可控制性。\n\n（5）张焕国教授认为可信计算系统是能够提供系统的可靠性、可用性、安全性（信息的安全性和行为的安全性）的计算机系统，通俗的称为：可信≈可靠+安全。\n\n（6）另外，还有其他一些解释：可信是指计算机系统提供的服务可以被证明是可信赖的；如果一个系统按照预期的设计和策略运行，那么这个系统是可信的；当第二个实体符合第一个实体的期望行为时，第一个实体可假设第二个实体是可信的。\n\n二、为什么这么多定义？\n\n（1）因为他们的研究背景不同：可信赖计算（dependable computing）、安全计算（security computing）和信任计算（trusted computing）。他们统称为可信计算。\n\n（2）本文主要研究沈昌祥院士的trusted computing，信任计算\n\n（3）信任计算源自早起的安全硬件设计，基本思想是：假定真实性可以用于计算机系统中首先建立一个信任根，再建立一条信任链，一级度量认证一级，一级信任一级，把信任关系扩大到整个计算机系统，从而确保计算机系统可信。\n\n三、信任的属性\n\n（1）信任是一种二元关系，它可以是一对一、一对多（个体对群体）、多对一（群体对个体）或多对多（群体对群体）的。\n\n（2）信任具有二重性，既有主观性又有客观性。\n\n（3）信任不一定具有对称性，即A信任B，则不一定就有B信任A。\n\n（4）信任可度量，也就是说信任有程度之分，可以划分等级。\n\n（5）信任可传递，但不绝对，而且在传递过程中可能有损失，传递的路径越长，损失的可能性就越大。\n\n（6）信任具有动态性，即信任与环境(上下文)和时间因素相关。\n\n四、信任链\n\n​\t![1569663160081](/img/信任链.png)\n\n五、可信根\n\n![1569664589958](/img/可信根.png)\n\n图中的链也是信任链\n\n六、待研究领域\n\n（1）系统结构：包括硬件结构、TPM的物理安全、TPM的嵌入式软件、软件结构\n\n（2）密码技术：公钥密码、传统密码、哈希函数、随机数产生\n\n（3）信任链技术：包括信任的传递\n\n（4）信任的度量：动态度量、存储和报告机制、可信测试\n\n（5）可信软件：包括可信操作系统、可信编译、可信数据库、可信应用软件\n\n（6）可信网络：可信网络结构、可信网络协议、可信网络设备\n\n七、理论基础\n\n（1）可信模型：数学模型、行为学模型\n\n（2）可信度量理论：软件的动态可信性度量理论与模型\n\n（3）信任链理论：信任的传递理论、信任传递的损失度量\n\n（4）软件理论：可信性度量理论、可信软件工程、软件行为学","source":"_posts/可信与可信计算.md","raw":"title: 可信与可信计算\nauthor: 郑天祺\ntags:\n  - 可信计算\ncategories:\n  - 可信\ndate: 2019-09-28 16:55:00\n\n---\n\n一、“可信”有比较多的定义\n\n（1）TCG用实体行为的预期性来定义 “可信” ：如果一个实体的行为是预期的方式符合预期的目标，则该实体是可信的。\n\n（2）ISO/IEC 15408标准定义“可信”为：参与计算的组件、操作或过程在任意条件下是可预测的，并能够抵御病毒和物理干扰。\n\n（3）IEEE CS可信计算技术委员会（IEEE ComputerSocietyTechnical Committeeon Dependable Computing）所谓 “可信” 是指计算机系统所提供的服务是可以论证其是可信赖的，即不仅计算机系统所提供的服务是可信赖的，而且这种可信赖还是可论证的。这种可信依赖更多地指系统的可靠性、可用性和可维护性。\n\n（4）我国著名的信息安全专家沈昌祥院士对上述定义进行了综合和拓展，他认为“可信”要做到一个实体在实现给定目标对其行为总是同预期的结果一样，强调行为结果的可预测性和可控制性。\n\n（5）张焕国教授认为可信计算系统是能够提供系统的可靠性、可用性、安全性（信息的安全性和行为的安全性）的计算机系统，通俗的称为：可信≈可靠+安全。\n\n（6）另外，还有其他一些解释：可信是指计算机系统提供的服务可以被证明是可信赖的；如果一个系统按照预期的设计和策略运行，那么这个系统是可信的；当第二个实体符合第一个实体的期望行为时，第一个实体可假设第二个实体是可信的。\n\n二、为什么这么多定义？\n\n（1）因为他们的研究背景不同：可信赖计算（dependable computing）、安全计算（security computing）和信任计算（trusted computing）。他们统称为可信计算。\n\n（2）本文主要研究沈昌祥院士的trusted computing，信任计算\n\n（3）信任计算源自早起的安全硬件设计，基本思想是：假定真实性可以用于计算机系统中首先建立一个信任根，再建立一条信任链，一级度量认证一级，一级信任一级，把信任关系扩大到整个计算机系统，从而确保计算机系统可信。\n\n三、信任的属性\n\n（1）信任是一种二元关系，它可以是一对一、一对多（个体对群体）、多对一（群体对个体）或多对多（群体对群体）的。\n\n（2）信任具有二重性，既有主观性又有客观性。\n\n（3）信任不一定具有对称性，即A信任B，则不一定就有B信任A。\n\n（4）信任可度量，也就是说信任有程度之分，可以划分等级。\n\n（5）信任可传递，但不绝对，而且在传递过程中可能有损失，传递的路径越长，损失的可能性就越大。\n\n（6）信任具有动态性，即信任与环境(上下文)和时间因素相关。\n\n四、信任链\n\n​\t![1569663160081](/img/信任链.png)\n\n五、可信根\n\n![1569664589958](/img/可信根.png)\n\n图中的链也是信任链\n\n六、待研究领域\n\n（1）系统结构：包括硬件结构、TPM的物理安全、TPM的嵌入式软件、软件结构\n\n（2）密码技术：公钥密码、传统密码、哈希函数、随机数产生\n\n（3）信任链技术：包括信任的传递\n\n（4）信任的度量：动态度量、存储和报告机制、可信测试\n\n（5）可信软件：包括可信操作系统、可信编译、可信数据库、可信应用软件\n\n（6）可信网络：可信网络结构、可信网络协议、可信网络设备\n\n七、理论基础\n\n（1）可信模型：数学模型、行为学模型\n\n（2）可信度量理论：软件的动态可信性度量理论与模型\n\n（3）信任链理论：信任的传递理论、信任传递的损失度量\n\n（4）软件理论：可信性度量理论、可信软件工程、软件行为学","slug":"可信与可信计算","published":1,"updated":"2019-10-15T10:07:21.402Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1e001tvguqzbjjdm9z","content":"<p>一、“可信”有比较多的定义</p>\n<p>（1）TCG用实体行为的预期性来定义 “可信” ：如果一个实体的行为是预期的方式符合预期的目标，则该实体是可信的。</p>\n<p>（2）ISO/IEC 15408标准定义“可信”为：参与计算的组件、操作或过程在任意条件下是可预测的，并能够抵御病毒和物理干扰。</p>\n<p>（3）IEEE CS可信计算技术委员会（IEEE ComputerSocietyTechnical Committeeon Dependable Computing）所谓 “可信” 是指计算机系统所提供的服务是可以论证其是可信赖的，即不仅计算机系统所提供的服务是可信赖的，而且这种可信赖还是可论证的。这种可信依赖更多地指系统的可靠性、可用性和可维护性。</p>\n<p>（4）我国著名的信息安全专家沈昌祥院士对上述定义进行了综合和拓展，他认为“可信”要做到一个实体在实现给定目标对其行为总是同预期的结果一样，强调行为结果的可预测性和可控制性。</p>\n<p>（5）张焕国教授认为可信计算系统是能够提供系统的可靠性、可用性、安全性（信息的安全性和行为的安全性）的计算机系统，通俗的称为：可信≈可靠+安全。</p>\n<p>（6）另外，还有其他一些解释：可信是指计算机系统提供的服务可以被证明是可信赖的；如果一个系统按照预期的设计和策略运行，那么这个系统是可信的；当第二个实体符合第一个实体的期望行为时，第一个实体可假设第二个实体是可信的。</p>\n<p>二、为什么这么多定义？</p>\n<p>（1）因为他们的研究背景不同：可信赖计算（dependable computing）、安全计算（security computing）和信任计算（trusted computing）。他们统称为可信计算。</p>\n<p>（2）本文主要研究沈昌祥院士的trusted computing，信任计算</p>\n<p>（3）信任计算源自早起的安全硬件设计，基本思想是：假定真实性可以用于计算机系统中首先建立一个信任根，再建立一条信任链，一级度量认证一级，一级信任一级，把信任关系扩大到整个计算机系统，从而确保计算机系统可信。</p>\n<p>三、信任的属性</p>\n<p>（1）信任是一种二元关系，它可以是一对一、一对多（个体对群体）、多对一（群体对个体）或多对多（群体对群体）的。</p>\n<p>（2）信任具有二重性，既有主观性又有客观性。</p>\n<p>（3）信任不一定具有对称性，即A信任B，则不一定就有B信任A。</p>\n<p>（4）信任可度量，也就是说信任有程度之分，可以划分等级。</p>\n<p>（5）信任可传递，但不绝对，而且在传递过程中可能有损失，传递的路径越长，损失的可能性就越大。</p>\n<p>（6）信任具有动态性，即信任与环境(上下文)和时间因素相关。</p>\n<p>四、信任链</p>\n<p>​\t<img src=\"/img/%E4%BF%A1%E4%BB%BB%E9%93%BE.png\" alt=\"1569663160081\"></p>\n<p>五、可信根</p>\n<p><img src=\"/img/%E5%8F%AF%E4%BF%A1%E6%A0%B9.png\" alt=\"1569664589958\"></p>\n<p>图中的链也是信任链</p>\n<p>六、待研究领域</p>\n<p>（1）系统结构：包括硬件结构、TPM的物理安全、TPM的嵌入式软件、软件结构</p>\n<p>（2）密码技术：公钥密码、传统密码、哈希函数、随机数产生</p>\n<p>（3）信任链技术：包括信任的传递</p>\n<p>（4）信任的度量：动态度量、存储和报告机制、可信测试</p>\n<p>（5）可信软件：包括可信操作系统、可信编译、可信数据库、可信应用软件</p>\n<p>（6）可信网络：可信网络结构、可信网络协议、可信网络设备</p>\n<p>七、理论基础</p>\n<p>（1）可信模型：数学模型、行为学模型</p>\n<p>（2）可信度量理论：软件的动态可信性度量理论与模型</p>\n<p>（3）信任链理论：信任的传递理论、信任传递的损失度量</p>\n<p>（4）软件理论：可信性度量理论、可信软件工程、软件行为学</p>\n","site":{"data":{}},"excerpt":"","more":"<p>一、“可信”有比较多的定义</p>\n<p>（1）TCG用实体行为的预期性来定义 “可信” ：如果一个实体的行为是预期的方式符合预期的目标，则该实体是可信的。</p>\n<p>（2）ISO/IEC 15408标准定义“可信”为：参与计算的组件、操作或过程在任意条件下是可预测的，并能够抵御病毒和物理干扰。</p>\n<p>（3）IEEE CS可信计算技术委员会（IEEE ComputerSocietyTechnical Committeeon Dependable Computing）所谓 “可信” 是指计算机系统所提供的服务是可以论证其是可信赖的，即不仅计算机系统所提供的服务是可信赖的，而且这种可信赖还是可论证的。这种可信依赖更多地指系统的可靠性、可用性和可维护性。</p>\n<p>（4）我国著名的信息安全专家沈昌祥院士对上述定义进行了综合和拓展，他认为“可信”要做到一个实体在实现给定目标对其行为总是同预期的结果一样，强调行为结果的可预测性和可控制性。</p>\n<p>（5）张焕国教授认为可信计算系统是能够提供系统的可靠性、可用性、安全性（信息的安全性和行为的安全性）的计算机系统，通俗的称为：可信≈可靠+安全。</p>\n<p>（6）另外，还有其他一些解释：可信是指计算机系统提供的服务可以被证明是可信赖的；如果一个系统按照预期的设计和策略运行，那么这个系统是可信的；当第二个实体符合第一个实体的期望行为时，第一个实体可假设第二个实体是可信的。</p>\n<p>二、为什么这么多定义？</p>\n<p>（1）因为他们的研究背景不同：可信赖计算（dependable computing）、安全计算（security computing）和信任计算（trusted computing）。他们统称为可信计算。</p>\n<p>（2）本文主要研究沈昌祥院士的trusted computing，信任计算</p>\n<p>（3）信任计算源自早起的安全硬件设计，基本思想是：假定真实性可以用于计算机系统中首先建立一个信任根，再建立一条信任链，一级度量认证一级，一级信任一级，把信任关系扩大到整个计算机系统，从而确保计算机系统可信。</p>\n<p>三、信任的属性</p>\n<p>（1）信任是一种二元关系，它可以是一对一、一对多（个体对群体）、多对一（群体对个体）或多对多（群体对群体）的。</p>\n<p>（2）信任具有二重性，既有主观性又有客观性。</p>\n<p>（3）信任不一定具有对称性，即A信任B，则不一定就有B信任A。</p>\n<p>（4）信任可度量，也就是说信任有程度之分，可以划分等级。</p>\n<p>（5）信任可传递，但不绝对，而且在传递过程中可能有损失，传递的路径越长，损失的可能性就越大。</p>\n<p>（6）信任具有动态性，即信任与环境(上下文)和时间因素相关。</p>\n<p>四、信任链</p>\n<p>​\t<img src=\"/img/%E4%BF%A1%E4%BB%BB%E9%93%BE.png\" alt=\"1569663160081\"></p>\n<p>五、可信根</p>\n<p><img src=\"/img/%E5%8F%AF%E4%BF%A1%E6%A0%B9.png\" alt=\"1569664589958\"></p>\n<p>图中的链也是信任链</p>\n<p>六、待研究领域</p>\n<p>（1）系统结构：包括硬件结构、TPM的物理安全、TPM的嵌入式软件、软件结构</p>\n<p>（2）密码技术：公钥密码、传统密码、哈希函数、随机数产生</p>\n<p>（3）信任链技术：包括信任的传递</p>\n<p>（4）信任的度量：动态度量、存储和报告机制、可信测试</p>\n<p>（5）可信软件：包括可信操作系统、可信编译、可信数据库、可信应用软件</p>\n<p>（6）可信网络：可信网络结构、可信网络协议、可信网络设备</p>\n<p>七、理论基础</p>\n<p>（1）可信模型：数学模型、行为学模型</p>\n<p>（2）可信度量理论：软件的动态可信性度量理论与模型</p>\n<p>（3）信任链理论：信任的传递理论、信任传递的损失度量</p>\n<p>（4）软件理论：可信性度量理论、可信软件工程、软件行为学</p>\n"},{"title":"加密解密","author":"郑天祺","date":"2019-09-02T05:37:00.000Z","_content":"\n# 1、组成\n\n（1）明文：未加密的消息m；\n\n（2）密文：加密后的消息ct；\n\n（3）加解密算法：把明文变成密文，密文变成明文的转换函数；\n\n（4）加密密钥：明文 加密成 密文 需要的参数；\n\n（5）解密密钥：密文变成 明文 需要的参数\n\n# 2、分类\n\n## （1）对称加密算法\n\n对称加密算法 ： 加密密钥 = 解密密钥\n\n![](/img/对称加密算法.png)\n\n## （2）非对称加密算法\n\n对称加密算法 ： 加密密钥 != 解密密钥\n\n![](/img/非对称加密算法.png)\n\n## （3）混合加密机制\n\n混合加密算法：对称加密 + 非对称加密\n\n![](/img/混合加密的方式.png)\n\n### \t加密过程\n\n（a）首先利用对称加密技术加密索要安全传输的消息\n\n（b）然后将对称密钥通过非对称加密的方式用公钥进行加密，附在（a）所述消息中\n\n### \t解密过程\n\n（a）首先使用私钥解密密钥\n\n（b）然后再用此密钥解密消息\n\n## （4）为什么需要混合加密机制？\n\n### \t安全？速度快？\n\n​\t先拿对称加密和非对称加密算法，做一个对比\n\n​\t本文中的私钥、公钥是非对称加密的说法；密钥是对称加密的说法。\n\n![1571142451345](/img/加密算法.png)\n\n谈一下混合的好处：\n\n（a）利用对称加密的速度快：进行网络消息传输时响应及时；\n\n（b）非对称加密的安全优势：给你一个通过公钥加密的密钥，你先拿私钥解开加密的密钥，然后才能解开消息，保证密钥不被泄露。（注：有点绕；此处私钥、公钥是非对称加密的说法；密钥是对称加密的说法。）\n\n","source":"_posts/加密解密.md","raw":"title: 加密解密\nauthor: 郑天祺\ntags:\n\n  - 可信\n  - 密码学\ncategories:\n  - 可信\ndate: 2019-09-02 13:37:00\n\n---\n\n# 1、组成\n\n（1）明文：未加密的消息m；\n\n（2）密文：加密后的消息ct；\n\n（3）加解密算法：把明文变成密文，密文变成明文的转换函数；\n\n（4）加密密钥：明文 加密成 密文 需要的参数；\n\n（5）解密密钥：密文变成 明文 需要的参数\n\n# 2、分类\n\n## （1）对称加密算法\n\n对称加密算法 ： 加密密钥 = 解密密钥\n\n![](/img/对称加密算法.png)\n\n## （2）非对称加密算法\n\n对称加密算法 ： 加密密钥 != 解密密钥\n\n![](/img/非对称加密算法.png)\n\n## （3）混合加密机制\n\n混合加密算法：对称加密 + 非对称加密\n\n![](/img/混合加密的方式.png)\n\n### \t加密过程\n\n（a）首先利用对称加密技术加密索要安全传输的消息\n\n（b）然后将对称密钥通过非对称加密的方式用公钥进行加密，附在（a）所述消息中\n\n### \t解密过程\n\n（a）首先使用私钥解密密钥\n\n（b）然后再用此密钥解密消息\n\n## （4）为什么需要混合加密机制？\n\n### \t安全？速度快？\n\n​\t先拿对称加密和非对称加密算法，做一个对比\n\n​\t本文中的私钥、公钥是非对称加密的说法；密钥是对称加密的说法。\n\n![1571142451345](/img/加密算法.png)\n\n谈一下混合的好处：\n\n（a）利用对称加密的速度快：进行网络消息传输时响应及时；\n\n（b）非对称加密的安全优势：给你一个通过公钥加密的密钥，你先拿私钥解开加密的密钥，然后才能解开消息，保证密钥不被泄露。（注：有点绕；此处私钥、公钥是非对称加密的说法；密钥是对称加密的说法。）\n\n","slug":"加密解密","published":1,"updated":"2019-10-15T12:40:18.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1f001vvguqw2uhdmk5","content":"<h1>1、组成</h1>\n<p>（1）明文：未加密的消息m；</p>\n<p>（2）密文：加密后的消息ct；</p>\n<p>（3）加解密算法：把明文变成密文，密文变成明文的转换函数；</p>\n<p>（4）加密密钥：明文 加密成 密文 需要的参数；</p>\n<p>（5）解密密钥：密文变成 明文 需要的参数</p>\n<h1>2、分类</h1>\n<h2>（1）对称加密算法</h2>\n<p>对称加密算法 ： 加密密钥 = 解密密钥</p>\n<p><img src=\"/img/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt></p>\n<h2>（2）非对称加密算法</h2>\n<p>对称加密算法 ： 加密密钥 != 解密密钥</p>\n<p><img src=\"/img/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt></p>\n<h2>（3）混合加密机制</h2>\n<p>混合加密算法：对称加密 + 非对称加密</p>\n<p><img src=\"/img/%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86%E7%9A%84%E6%96%B9%E5%BC%8F.png\" alt></p>\n<h3>加密过程</h3>\n<p>（a）首先利用对称加密技术加密索要安全传输的消息</p>\n<p>（b）然后将对称密钥通过非对称加密的方式用公钥进行加密，附在（a）所述消息中</p>\n<h3>解密过程</h3>\n<p>（a）首先使用私钥解密密钥</p>\n<p>（b）然后再用此密钥解密消息</p>\n<h2>（4）为什么需要混合加密机制？</h2>\n<h3>安全？速度快？</h3>\n<p>​\t先拿对称加密和非对称加密算法，做一个对比</p>\n<p>​\t本文中的私钥、公钥是非对称加密的说法；密钥是对称加密的说法。</p>\n<p><img src=\"/img/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt=\"1571142451345\"></p>\n<p>谈一下混合的好处：</p>\n<p>（a）利用对称加密的速度快：进行网络消息传输时响应及时；</p>\n<p>（b）非对称加密的安全优势：给你一个通过公钥加密的密钥，你先拿私钥解开加密的密钥，然后才能解开消息，保证密钥不被泄露。（注：有点绕；此处私钥、公钥是非对称加密的说法；密钥是对称加密的说法。）</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>1、组成</h1>\n<p>（1）明文：未加密的消息m；</p>\n<p>（2）密文：加密后的消息ct；</p>\n<p>（3）加解密算法：把明文变成密文，密文变成明文的转换函数；</p>\n<p>（4）加密密钥：明文 加密成 密文 需要的参数；</p>\n<p>（5）解密密钥：密文变成 明文 需要的参数</p>\n<h1>2、分类</h1>\n<h2>（1）对称加密算法</h2>\n<p>对称加密算法 ： 加密密钥 = 解密密钥</p>\n<p><img src=\"/img/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt></p>\n<h2>（2）非对称加密算法</h2>\n<p>对称加密算法 ： 加密密钥 != 解密密钥</p>\n<p><img src=\"/img/%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt></p>\n<h2>（3）混合加密机制</h2>\n<p>混合加密算法：对称加密 + 非对称加密</p>\n<p><img src=\"/img/%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86%E7%9A%84%E6%96%B9%E5%BC%8F.png\" alt></p>\n<h3>加密过程</h3>\n<p>（a）首先利用对称加密技术加密索要安全传输的消息</p>\n<p>（b）然后将对称密钥通过非对称加密的方式用公钥进行加密，附在（a）所述消息中</p>\n<h3>解密过程</h3>\n<p>（a）首先使用私钥解密密钥</p>\n<p>（b）然后再用此密钥解密消息</p>\n<h2>（4）为什么需要混合加密机制？</h2>\n<h3>安全？速度快？</h3>\n<p>​\t先拿对称加密和非对称加密算法，做一个对比</p>\n<p>​\t本文中的私钥、公钥是非对称加密的说法；密钥是对称加密的说法。</p>\n<p><img src=\"/img/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95.png\" alt=\"1571142451345\"></p>\n<p>谈一下混合的好处：</p>\n<p>（a）利用对称加密的速度快：进行网络消息传输时响应及时；</p>\n<p>（b）非对称加密的安全优势：给你一个通过公钥加密的密钥，你先拿私钥解开加密的密钥，然后才能解开消息，保证密钥不被泄露。（注：有点绕；此处私钥、公钥是非对称加密的说法；密钥是对称加密的说法。）</p>\n"},{"title":"可靠性和容错技术","author":"郑天祺","date":"2019-10-02T05:39:00.000Z","_content":"\n​\t为了提高计算机系统的可靠性，人们通过长期的研究总结出了两种技术：避错技术和容错技术。\n\n一、避免技术\n\n​\t避错技术试图构造一个不包含故障的完美系统，其手段是采用精确的设计和质量控制方法尽量避免把故障引入系统。避错系统对元器件的制造工艺、精确的阈值有很高的要求。实际上做到这点是不可能的，因此避错技术对系统的可靠性的提高受到很大的限制。\n\n二、容错技术\n\n​\t容错是指当出现某些指定的硬件故障或软件故障时，系统仍能执行规定的一组程序，或者说程序不会因为系统故障而中止或被修改，并且执行结果也不包含系统故障引起的差错。容错的思想是在系统体系结构上精心设计，利用外加资源的冗余技术掩蔽故障带来的影响，从而自动恢复系统或达到安全停机的目的。\n\n​\t所以我们重点研究容错技术：\n\n​\t容错的目标是降低或者最小化故障对系统可用性、可靠性、安全性、持续性等得影响。\n\n​\t容错按系统级别划分，分为三个级别，硬件容错、软件容错以及系统容错。硬件容错常用的方法包括使用冗余、多备份技术、增加内存、能源系统冗余等。硬件错误通常能够够在两个物理机上进行隔离处理。软件容错主要是正对软件的鲁棒性特征进行增强。常见的方法有checkpoint/restart，recovery blocks，N-Version Programs等。对于系统容错，设计一个独立与目标系统的子系统，通过定义定义规则来容忍系统缺陷。对缺陷的处理，有以下几类技术：\n\n1. 使用缺陷避免技术来避一些错误。使用成熟的设计方法论、验证以及确认方法论、代码检查、上线前的演练等；\n2. 在可能会存在的缺陷时，可以选择缺陷移除技术。例如测试、集成测试、回归测试、背靠背测试等； \n3. 或者是在遭遇错误是，缺陷回避的方式，是的潜在的缺陷不会被激活。常见技术是通过重新配置系统来达到避免的目标； \n4. 缺陷容忍技术，系统能够对缺陷进行侦测、诊断、孤立、覆盖、不错、以及系统恢复。使用以上多种技术混合。","source":"_posts/可靠性和容错技术.md","raw":"title: 可靠性和容错技术\nauthor: 郑天祺\ntags:\n  - 可靠\n  - 容错\ncategories:\n  - 可信\ndate: 2019-10-02 13:39:00\n\n---\n\n​\t为了提高计算机系统的可靠性，人们通过长期的研究总结出了两种技术：避错技术和容错技术。\n\n一、避免技术\n\n​\t避错技术试图构造一个不包含故障的完美系统，其手段是采用精确的设计和质量控制方法尽量避免把故障引入系统。避错系统对元器件的制造工艺、精确的阈值有很高的要求。实际上做到这点是不可能的，因此避错技术对系统的可靠性的提高受到很大的限制。\n\n二、容错技术\n\n​\t容错是指当出现某些指定的硬件故障或软件故障时，系统仍能执行规定的一组程序，或者说程序不会因为系统故障而中止或被修改，并且执行结果也不包含系统故障引起的差错。容错的思想是在系统体系结构上精心设计，利用外加资源的冗余技术掩蔽故障带来的影响，从而自动恢复系统或达到安全停机的目的。\n\n​\t所以我们重点研究容错技术：\n\n​\t容错的目标是降低或者最小化故障对系统可用性、可靠性、安全性、持续性等得影响。\n\n​\t容错按系统级别划分，分为三个级别，硬件容错、软件容错以及系统容错。硬件容错常用的方法包括使用冗余、多备份技术、增加内存、能源系统冗余等。硬件错误通常能够够在两个物理机上进行隔离处理。软件容错主要是正对软件的鲁棒性特征进行增强。常见的方法有checkpoint/restart，recovery blocks，N-Version Programs等。对于系统容错，设计一个独立与目标系统的子系统，通过定义定义规则来容忍系统缺陷。对缺陷的处理，有以下几类技术：\n\n1. 使用缺陷避免技术来避一些错误。使用成熟的设计方法论、验证以及确认方法论、代码检查、上线前的演练等；\n2. 在可能会存在的缺陷时，可以选择缺陷移除技术。例如测试、集成测试、回归测试、背靠背测试等； \n3. 或者是在遭遇错误是，缺陷回避的方式，是的潜在的缺陷不会被激活。常见技术是通过重新配置系统来达到避免的目标； \n4. 缺陷容忍技术，系统能够对缺陷进行侦测、诊断、孤立、覆盖、不错、以及系统恢复。使用以上多种技术混合。","slug":"可靠性和容错技术","published":1,"updated":"2019-10-02T06:48:35.455Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1i001zvguqyln2p5u0","content":"<p>​\t为了提高计算机系统的可靠性，人们通过长期的研究总结出了两种技术：避错技术和容错技术。</p>\n<p>一、避免技术</p>\n<p>​\t避错技术试图构造一个不包含故障的完美系统，其手段是采用精确的设计和质量控制方法尽量避免把故障引入系统。避错系统对元器件的制造工艺、精确的阈值有很高的要求。实际上做到这点是不可能的，因此避错技术对系统的可靠性的提高受到很大的限制。</p>\n<p>二、容错技术</p>\n<p>​\t容错是指当出现某些指定的硬件故障或软件故障时，系统仍能执行规定的一组程序，或者说程序不会因为系统故障而中止或被修改，并且执行结果也不包含系统故障引起的差错。容错的思想是在系统体系结构上精心设计，利用外加资源的冗余技术掩蔽故障带来的影响，从而自动恢复系统或达到安全停机的目的。</p>\n<p>​\t所以我们重点研究容错技术：</p>\n<p>​\t容错的目标是降低或者最小化故障对系统可用性、可靠性、安全性、持续性等得影响。</p>\n<p>​\t容错按系统级别划分，分为三个级别，硬件容错、软件容错以及系统容错。硬件容错常用的方法包括使用冗余、多备份技术、增加内存、能源系统冗余等。硬件错误通常能够够在两个物理机上进行隔离处理。软件容错主要是正对软件的鲁棒性特征进行增强。常见的方法有checkpoint/restart，recovery blocks，N-Version Programs等。对于系统容错，设计一个独立与目标系统的子系统，通过定义定义规则来容忍系统缺陷。对缺陷的处理，有以下几类技术：</p>\n<ol>\n<li>使用缺陷避免技术来避一些错误。使用成熟的设计方法论、验证以及确认方法论、代码检查、上线前的演练等；</li>\n<li>在可能会存在的缺陷时，可以选择缺陷移除技术。例如测试、集成测试、回归测试、背靠背测试等；</li>\n<li>或者是在遭遇错误是，缺陷回避的方式，是的潜在的缺陷不会被激活。常见技术是通过重新配置系统来达到避免的目标；</li>\n<li>缺陷容忍技术，系统能够对缺陷进行侦测、诊断、孤立、覆盖、不错、以及系统恢复。使用以上多种技术混合。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>​\t为了提高计算机系统的可靠性，人们通过长期的研究总结出了两种技术：避错技术和容错技术。</p>\n<p>一、避免技术</p>\n<p>​\t避错技术试图构造一个不包含故障的完美系统，其手段是采用精确的设计和质量控制方法尽量避免把故障引入系统。避错系统对元器件的制造工艺、精确的阈值有很高的要求。实际上做到这点是不可能的，因此避错技术对系统的可靠性的提高受到很大的限制。</p>\n<p>二、容错技术</p>\n<p>​\t容错是指当出现某些指定的硬件故障或软件故障时，系统仍能执行规定的一组程序，或者说程序不会因为系统故障而中止或被修改，并且执行结果也不包含系统故障引起的差错。容错的思想是在系统体系结构上精心设计，利用外加资源的冗余技术掩蔽故障带来的影响，从而自动恢复系统或达到安全停机的目的。</p>\n<p>​\t所以我们重点研究容错技术：</p>\n<p>​\t容错的目标是降低或者最小化故障对系统可用性、可靠性、安全性、持续性等得影响。</p>\n<p>​\t容错按系统级别划分，分为三个级别，硬件容错、软件容错以及系统容错。硬件容错常用的方法包括使用冗余、多备份技术、增加内存、能源系统冗余等。硬件错误通常能够够在两个物理机上进行隔离处理。软件容错主要是正对软件的鲁棒性特征进行增强。常见的方法有checkpoint/restart，recovery blocks，N-Version Programs等。对于系统容错，设计一个独立与目标系统的子系统，通过定义定义规则来容忍系统缺陷。对缺陷的处理，有以下几类技术：</p>\n<ol>\n<li>使用缺陷避免技术来避一些错误。使用成熟的设计方法论、验证以及确认方法论、代码检查、上线前的演练等；</li>\n<li>在可能会存在的缺陷时，可以选择缺陷移除技术。例如测试、集成测试、回归测试、背靠背测试等；</li>\n<li>或者是在遭遇错误是，缺陷回避的方式，是的潜在的缺陷不会被激活。常见技术是通过重新配置系统来达到避免的目标；</li>\n<li>缺陷容忍技术，系统能够对缺陷进行侦测、诊断、孤立、覆盖、不错、以及系统恢复。使用以上多种技术混合。</li>\n</ol>\n"},{"title":"可信基本概念","author":"郑天祺","date":"2019-09-01T06:46:00.000Z","_content":"\n可信的基本思想是在计算机系统中首先建立一个信任根，在计算机系统启动和运行过程中再建立一条信任链，实现对计算机系统局部或全局的可信验证，从而发现不可信实体，及时恢复或阻断运行，从而确保系统安全。\n\n后来由产生可信操作系统、可信应用、可信网络到可信浏览器等等等等整套可信的体系。\n\n# 1、可信历史：\n\n## （1）可信1.0（软件容错）\n\n​\t可信计算技术的发展最早可追溯到２０世纪８０年代，以世界容错组织为代表，通过纯软件实现的容错、故障诊断等机制，验证计算机部件的运行状态，从而实现计算机部件的冗余备份和故障切换。但是众所周知，纯软件实现的安全机制极易被攻击，所以说软件容错是有弊端的。\n\n## （2）可信2.0（硬件可信）\n\n​\t2000年左右，以 TCG 组织（Trusted Computing Group）为代表，TCG组织制定了TPM（Trusted Platform Module）的标准，很多安全芯片都是符合这个规范的。而且由于其硬件实现安全防护，正逐渐成为PC，尤其是便携式PC的标准配置。\n\n​\t通过为计算机增加硬件实现的信任根 TPM 构建开机启动的信任链，从而实现终端计算机的可信启动，标志着可信计算进入了2.0时代。\n\n## （3）可信3.0（主动防御体系）\n\n​\t沈昌祥院士在可信3.0战略中提出：可信 3.0 已经形成了自主创新的体系，并在很多领域开展了规模应用。\n\n​\t**总结一下:**\n\n### \t（a）TPCM\n\n​\tTPCM（可信平台控制模块，一个硬件）作为自主可控的可信节点植入可信根。这个信任根置于主板，先于中央处理器（CPU）启动并对基本输入输出系统（BIOS）进行验证。构成了宿主机 CPU 加可信平台控制模块的双节点，实现信任链在 “加电第一时刻” 开始建立；\n\n### \t（b） 可信基础支撑软件框架\n\n​\t宿主软件系统 + 可信软件基的双系统体系结构；\n\n### \t（c）三层三元对等的可信连接框架\n\n​\t提高了网络连接的整体可信性、安全性和可管理性；\n\n### \t（d）加密算法均自主设计\n\n​\t命名为SM 国产密码算法，并自主设计了双数字证书认证结构。\n\n### \t（f）主动免疫可信架构信任链传递示意图：\n\n​\t![](/img/主动免疫可信架构信任链传递示意图.png)\n\n## 2、可信的应用\n\n## （1）基础架构图\n\n沈昌祥院士提到可信云的基础架构：\n\n![](/img/可信在云平台的基础架构.png)\n\n## （2）可信的安全保障机制\n\n### （a）运行环境\n\n通过建立云架构下的可信链，为虚拟运行环境提供可信保障；\n\n### （b）监控技术\n\n通过建立基于可信第三方的监控技术，可以有效监控云服务的执行，解决云服务不可信问题；\n\n### （c）隔离技术\n\n通过基于可信根支撑的隔离技术，可以在云环境建立起具有可信保障的多层隔离防线，为虚拟机提供安全可信的隔离环境；\n\n### （d）接入技术\n\n通过可信接入技术提供可信的云环境接入方法，解决开放云环境所带来的一系列安全问题。\n\n","source":"_posts/可信基本概念.md","raw":"title: 可信基本概念\nauthor: 郑天祺\ntags:\n  - 可信\ncategories:\n  - 可信\ndate: 2019-09-01 14:46:00\n\n---\n\n可信的基本思想是在计算机系统中首先建立一个信任根，在计算机系统启动和运行过程中再建立一条信任链，实现对计算机系统局部或全局的可信验证，从而发现不可信实体，及时恢复或阻断运行，从而确保系统安全。\n\n后来由产生可信操作系统、可信应用、可信网络到可信浏览器等等等等整套可信的体系。\n\n# 1、可信历史：\n\n## （1）可信1.0（软件容错）\n\n​\t可信计算技术的发展最早可追溯到２０世纪８０年代，以世界容错组织为代表，通过纯软件实现的容错、故障诊断等机制，验证计算机部件的运行状态，从而实现计算机部件的冗余备份和故障切换。但是众所周知，纯软件实现的安全机制极易被攻击，所以说软件容错是有弊端的。\n\n## （2）可信2.0（硬件可信）\n\n​\t2000年左右，以 TCG 组织（Trusted Computing Group）为代表，TCG组织制定了TPM（Trusted Platform Module）的标准，很多安全芯片都是符合这个规范的。而且由于其硬件实现安全防护，正逐渐成为PC，尤其是便携式PC的标准配置。\n\n​\t通过为计算机增加硬件实现的信任根 TPM 构建开机启动的信任链，从而实现终端计算机的可信启动，标志着可信计算进入了2.0时代。\n\n## （3）可信3.0（主动防御体系）\n\n​\t沈昌祥院士在可信3.0战略中提出：可信 3.0 已经形成了自主创新的体系，并在很多领域开展了规模应用。\n\n​\t**总结一下:**\n\n### \t（a）TPCM\n\n​\tTPCM（可信平台控制模块，一个硬件）作为自主可控的可信节点植入可信根。这个信任根置于主板，先于中央处理器（CPU）启动并对基本输入输出系统（BIOS）进行验证。构成了宿主机 CPU 加可信平台控制模块的双节点，实现信任链在 “加电第一时刻” 开始建立；\n\n### \t（b） 可信基础支撑软件框架\n\n​\t宿主软件系统 + 可信软件基的双系统体系结构；\n\n### \t（c）三层三元对等的可信连接框架\n\n​\t提高了网络连接的整体可信性、安全性和可管理性；\n\n### \t（d）加密算法均自主设计\n\n​\t命名为SM 国产密码算法，并自主设计了双数字证书认证结构。\n\n### \t（f）主动免疫可信架构信任链传递示意图：\n\n​\t![](/img/主动免疫可信架构信任链传递示意图.png)\n\n## 2、可信的应用\n\n## （1）基础架构图\n\n沈昌祥院士提到可信云的基础架构：\n\n![](/img/可信在云平台的基础架构.png)\n\n## （2）可信的安全保障机制\n\n### （a）运行环境\n\n通过建立云架构下的可信链，为虚拟运行环境提供可信保障；\n\n### （b）监控技术\n\n通过建立基于可信第三方的监控技术，可以有效监控云服务的执行，解决云服务不可信问题；\n\n### （c）隔离技术\n\n通过基于可信根支撑的隔离技术，可以在云环境建立起具有可信保障的多层隔离防线，为虚拟机提供安全可信的隔离环境；\n\n### （d）接入技术\n\n通过可信接入技术提供可信的云环境接入方法，解决开放云环境所带来的一系列安全问题。\n\n","slug":"可信基本概念","published":1,"updated":"2019-10-15T10:10:52.269Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1k0022vguq0oj2n2u2","content":"<p>可信的基本思想是在计算机系统中首先建立一个信任根，在计算机系统启动和运行过程中再建立一条信任链，实现对计算机系统局部或全局的可信验证，从而发现不可信实体，及时恢复或阻断运行，从而确保系统安全。</p>\n<p>后来由产生可信操作系统、可信应用、可信网络到可信浏览器等等等等整套可信的体系。</p>\n<h1>1、可信历史：</h1>\n<h2>（1）可信1.0（软件容错）</h2>\n<p>​\t可信计算技术的发展最早可追溯到２０世纪８０年代，以世界容错组织为代表，通过纯软件实现的容错、故障诊断等机制，验证计算机部件的运行状态，从而实现计算机部件的冗余备份和故障切换。但是众所周知，纯软件实现的安全机制极易被攻击，所以说软件容错是有弊端的。</p>\n<h2>（2）可信2.0（硬件可信）</h2>\n<p>​\t2000年左右，以 TCG 组织（Trusted Computing Group）为代表，TCG组织制定了TPM（Trusted Platform Module）的标准，很多安全芯片都是符合这个规范的。而且由于其硬件实现安全防护，正逐渐成为PC，尤其是便携式PC的标准配置。</p>\n<p>​\t通过为计算机增加硬件实现的信任根 TPM 构建开机启动的信任链，从而实现终端计算机的可信启动，标志着可信计算进入了2.0时代。</p>\n<h2>（3）可信3.0（主动防御体系）</h2>\n<p>​\t沈昌祥院士在可信3.0战略中提出：可信 3.0 已经形成了自主创新的体系，并在很多领域开展了规模应用。</p>\n<p>​\t<strong>总结一下:</strong></p>\n<h3>（a）TPCM</h3>\n<p>​\tTPCM（可信平台控制模块，一个硬件）作为自主可控的可信节点植入可信根。这个信任根置于主板，先于中央处理器（CPU）启动并对基本输入输出系统（BIOS）进行验证。构成了宿主机 CPU 加可信平台控制模块的双节点，实现信任链在 “加电第一时刻” 开始建立；</p>\n<h3>（b） 可信基础支撑软件框架</h3>\n<p>​\t宿主软件系统 + 可信软件基的双系统体系结构；</p>\n<h3>（c）三层三元对等的可信连接框架</h3>\n<p>​\t提高了网络连接的整体可信性、安全性和可管理性；</p>\n<h3>（d）加密算法均自主设计</h3>\n<p>​\t命名为SM 国产密码算法，并自主设计了双数字证书认证结构。</p>\n<h3>（f）主动免疫可信架构信任链传递示意图：</h3>\n<p>​\t<img src=\"/img/%E4%B8%BB%E5%8A%A8%E5%85%8D%E7%96%AB%E5%8F%AF%E4%BF%A1%E6%9E%B6%E6%9E%84%E4%BF%A1%E4%BB%BB%E9%93%BE%E4%BC%A0%E9%80%92%E7%A4%BA%E6%84%8F%E5%9B%BE.png\" alt></p>\n<h2>2、可信的应用</h2>\n<h2>（1）基础架构图</h2>\n<p>沈昌祥院士提到可信云的基础架构：</p>\n<p><img src=\"/img/%E5%8F%AF%E4%BF%A1%E5%9C%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png\" alt></p>\n<h2>（2）可信的安全保障机制</h2>\n<h3>（a）运行环境</h3>\n<p>通过建立云架构下的可信链，为虚拟运行环境提供可信保障；</p>\n<h3>（b）监控技术</h3>\n<p>通过建立基于可信第三方的监控技术，可以有效监控云服务的执行，解决云服务不可信问题；</p>\n<h3>（c）隔离技术</h3>\n<p>通过基于可信根支撑的隔离技术，可以在云环境建立起具有可信保障的多层隔离防线，为虚拟机提供安全可信的隔离环境；</p>\n<h3>（d）接入技术</h3>\n<p>通过可信接入技术提供可信的云环境接入方法，解决开放云环境所带来的一系列安全问题。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>可信的基本思想是在计算机系统中首先建立一个信任根，在计算机系统启动和运行过程中再建立一条信任链，实现对计算机系统局部或全局的可信验证，从而发现不可信实体，及时恢复或阻断运行，从而确保系统安全。</p>\n<p>后来由产生可信操作系统、可信应用、可信网络到可信浏览器等等等等整套可信的体系。</p>\n<h1>1、可信历史：</h1>\n<h2>（1）可信1.0（软件容错）</h2>\n<p>​\t可信计算技术的发展最早可追溯到２０世纪８０年代，以世界容错组织为代表，通过纯软件实现的容错、故障诊断等机制，验证计算机部件的运行状态，从而实现计算机部件的冗余备份和故障切换。但是众所周知，纯软件实现的安全机制极易被攻击，所以说软件容错是有弊端的。</p>\n<h2>（2）可信2.0（硬件可信）</h2>\n<p>​\t2000年左右，以 TCG 组织（Trusted Computing Group）为代表，TCG组织制定了TPM（Trusted Platform Module）的标准，很多安全芯片都是符合这个规范的。而且由于其硬件实现安全防护，正逐渐成为PC，尤其是便携式PC的标准配置。</p>\n<p>​\t通过为计算机增加硬件实现的信任根 TPM 构建开机启动的信任链，从而实现终端计算机的可信启动，标志着可信计算进入了2.0时代。</p>\n<h2>（3）可信3.0（主动防御体系）</h2>\n<p>​\t沈昌祥院士在可信3.0战略中提出：可信 3.0 已经形成了自主创新的体系，并在很多领域开展了规模应用。</p>\n<p>​\t<strong>总结一下:</strong></p>\n<h3>（a）TPCM</h3>\n<p>​\tTPCM（可信平台控制模块，一个硬件）作为自主可控的可信节点植入可信根。这个信任根置于主板，先于中央处理器（CPU）启动并对基本输入输出系统（BIOS）进行验证。构成了宿主机 CPU 加可信平台控制模块的双节点，实现信任链在 “加电第一时刻” 开始建立；</p>\n<h3>（b） 可信基础支撑软件框架</h3>\n<p>​\t宿主软件系统 + 可信软件基的双系统体系结构；</p>\n<h3>（c）三层三元对等的可信连接框架</h3>\n<p>​\t提高了网络连接的整体可信性、安全性和可管理性；</p>\n<h3>（d）加密算法均自主设计</h3>\n<p>​\t命名为SM 国产密码算法，并自主设计了双数字证书认证结构。</p>\n<h3>（f）主动免疫可信架构信任链传递示意图：</h3>\n<p>​\t<img src=\"/img/%E4%B8%BB%E5%8A%A8%E5%85%8D%E7%96%AB%E5%8F%AF%E4%BF%A1%E6%9E%B6%E6%9E%84%E4%BF%A1%E4%BB%BB%E9%93%BE%E4%BC%A0%E9%80%92%E7%A4%BA%E6%84%8F%E5%9B%BE.png\" alt></p>\n<h2>2、可信的应用</h2>\n<h2>（1）基础架构图</h2>\n<p>沈昌祥院士提到可信云的基础架构：</p>\n<p><img src=\"/img/%E5%8F%AF%E4%BF%A1%E5%9C%A8%E4%BA%91%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84.png\" alt></p>\n<h2>（2）可信的安全保障机制</h2>\n<h3>（a）运行环境</h3>\n<p>通过建立云架构下的可信链，为虚拟运行环境提供可信保障；</p>\n<h3>（b）监控技术</h3>\n<p>通过建立基于可信第三方的监控技术，可以有效监控云服务的执行，解决云服务不可信问题；</p>\n<h3>（c）隔离技术</h3>\n<p>通过基于可信根支撑的隔离技术，可以在云环境建立起具有可信保障的多层隔离防线，为虚拟机提供安全可信的隔离环境；</p>\n<h3>（d）接入技术</h3>\n<p>通过可信接入技术提供可信的云环境接入方法，解决开放云环境所带来的一系列安全问题。</p>\n"},{"title":"对象存储与指针压缩","author":"郑天祺","date":"2019-11-20T11:50:00.000Z","_content":"\n​\t我们知道在Java中基本数据类型的大小，例如int类型占4个字节、long类型占8个字节，那么Integer对象和Long对象会占用多少内存呢？\n\n​\t一、对象存储：\n\n​\t一个Java对象在内存中包括对象头、实例数据和补齐填充3个部分：\n\n![image-20191120195326698](/img/对象存储1.png)\n\n​     \n\n​\t(1) 对齐填充 :\n\n​\tJava对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。\n\n​\t例如，一个包含两个属性的对象：int和byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。\n\n![image-20191120195453758](/img/java对象存储2.png)\n\n32位系统 对象头占用空间= 4 + 4 = 8 byte\n\n64位系统 对象头占用空间= 8 + 8 =16 byte\n\n64位开启指针压缩 对象头占用空间= 4 + 8 = 12 byte\n\n注：\n\n​\t若为数组对象，对象头占用空间 + 4 byte\n\n​\t静态属性不算在对象大小内\n\n​\t从JDK 1.6 update14开始，64位的JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。\n\n​\tJDK 1.8，默认该参数就是开启的。\n\n​    (2)  对象的实际数据  \n\n​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定\n\n![image-20191120195618441](/img/java对象存储3.png)\n\n​\t对于reference类型来说，在32位系统上占用4bytes, 在64位系统上占用8bytes。\n\n​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定，\n\n​\t比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。\n\n二、指针压缩\n\n​    从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。\n\n​    对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的\n\nOOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用CompressOops后，会压缩的对象：\n\n​\t每个Class的属性指针（静态成员变量）；\n\n​\t每个对象的属性指针；\n\n​\t普通对象数组的每个元素指针。\n\n​\t当然，压缩也不是所有的指针都会压缩，对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen（1.8废弃）的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。\n\n​\t1.新生代：Eden+From Survivor+To Survivor\n\n​\t2.老年代：OldGen\n\n​\t3.永久代（方法区的实现） : PermGen----->替换为Metaspace(本地内存中)\n\n​\t(1) 验证对象头大小\n\n![image-20191120195845734](/img/指针压缩1.png)\n\n​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；\n\n​\t实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之内）\n\n​\t共24 byte\n\n​\t(2) 验证对象头大小 非压缩情况下\n\n![image-20191120200005300](/img/指针压缩2.png)\n\n​\t对象头大小=Class Pointer的空间大小为8字节+MarkWord为8字节=16字节；\n\n​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）\n\n​\t共32byte\n\n​\t(3) 验证对象头对齐填充\n\n![image-20191120200059442](/img/指针压缩3.png)\n\n​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；\n\n​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）\n\n​\t共20byte 所以需要有4字节的填充\n\n​\t(4) 验证对象头 数组\n\n![image-20191120200152966](/img/指针压缩4.png)\n\n​\tShallow Size比较简单，这里对象头大小为12字节， 实际数据大小为4字节，所以Shallow Size为16。\n\n​\t对于Retained Size来说，要计算数组占用的大小，对于数组来说，它的对象头部多了一个用来存储数组长度的空间，该空间大小为4字节，所以数组对象的大小 = 引用对象头大小12字节 + 存储数组长度的空间大小4字节 + 数组的长度\\*数组中对象的RetainedSize + padding大小\n\n​\tlong[] arr = new long[6];，它是一个长度为6的long类型的数组，由于long类型的大小为8字节，所以数组中的实际数据是6*8=48字节，那么数组对象的大小=12+4+6*8+0=64，最终的Retained Size=Shallow Size + 数组对象大小=16+64=80。 \n\n\n\n主要参考：http://www.ideabuffer.cn/2017/05/06/Java对象内存布局/","source":"_posts/对象存储与指针压缩.md","raw":"title: 对象存储与指针压缩\nauthor: 郑天祺\ntags:\n  - 内存模型\ncategories:\n  - java基础\ndate: 2019-11-20 19:50:00\n\n---\n\n​\t我们知道在Java中基本数据类型的大小，例如int类型占4个字节、long类型占8个字节，那么Integer对象和Long对象会占用多少内存呢？\n\n​\t一、对象存储：\n\n​\t一个Java对象在内存中包括对象头、实例数据和补齐填充3个部分：\n\n![image-20191120195326698](/img/对象存储1.png)\n\n​     \n\n​\t(1) 对齐填充 :\n\n​\tJava对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。\n\n​\t例如，一个包含两个属性的对象：int和byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。\n\n![image-20191120195453758](/img/java对象存储2.png)\n\n32位系统 对象头占用空间= 4 + 4 = 8 byte\n\n64位系统 对象头占用空间= 8 + 8 =16 byte\n\n64位开启指针压缩 对象头占用空间= 4 + 8 = 12 byte\n\n注：\n\n​\t若为数组对象，对象头占用空间 + 4 byte\n\n​\t静态属性不算在对象大小内\n\n​\t从JDK 1.6 update14开始，64位的JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。\n\n​\tJDK 1.8，默认该参数就是开启的。\n\n​    (2)  对象的实际数据  \n\n​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定\n\n![image-20191120195618441](/img/java对象存储3.png)\n\n​\t对于reference类型来说，在32位系统上占用4bytes, 在64位系统上占用8bytes。\n\n​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定，\n\n​\t比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。\n\n二、指针压缩\n\n​    从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。\n\n​    对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的\n\nOOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用CompressOops后，会压缩的对象：\n\n​\t每个Class的属性指针（静态成员变量）；\n\n​\t每个对象的属性指针；\n\n​\t普通对象数组的每个元素指针。\n\n​\t当然，压缩也不是所有的指针都会压缩，对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen（1.8废弃）的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。\n\n​\t1.新生代：Eden+From Survivor+To Survivor\n\n​\t2.老年代：OldGen\n\n​\t3.永久代（方法区的实现） : PermGen----->替换为Metaspace(本地内存中)\n\n​\t(1) 验证对象头大小\n\n![image-20191120195845734](/img/指针压缩1.png)\n\n​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；\n\n​\t实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之内）\n\n​\t共24 byte\n\n​\t(2) 验证对象头大小 非压缩情况下\n\n![image-20191120200005300](/img/指针压缩2.png)\n\n​\t对象头大小=Class Pointer的空间大小为8字节+MarkWord为8字节=16字节；\n\n​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）\n\n​\t共32byte\n\n​\t(3) 验证对象头对齐填充\n\n![image-20191120200059442](/img/指针压缩3.png)\n\n​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；\n\n​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）\n\n​\t共20byte 所以需要有4字节的填充\n\n​\t(4) 验证对象头 数组\n\n![image-20191120200152966](/img/指针压缩4.png)\n\n​\tShallow Size比较简单，这里对象头大小为12字节， 实际数据大小为4字节，所以Shallow Size为16。\n\n​\t对于Retained Size来说，要计算数组占用的大小，对于数组来说，它的对象头部多了一个用来存储数组长度的空间，该空间大小为4字节，所以数组对象的大小 = 引用对象头大小12字节 + 存储数组长度的空间大小4字节 + 数组的长度\\*数组中对象的RetainedSize + padding大小\n\n​\tlong[] arr = new long[6];，它是一个长度为6的long类型的数组，由于long类型的大小为8字节，所以数组中的实际数据是6*8=48字节，那么数组对象的大小=12+4+6*8+0=64，最终的Retained Size=Shallow Size + 数组对象大小=16+64=80。 \n\n\n\n主要参考：http://www.ideabuffer.cn/2017/05/06/Java对象内存布局/","slug":"对象存储与指针压缩","published":1,"updated":"2019-11-20T12:03:43.218Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1n0027vguqr0p1teb1","content":"<p>​\t我们知道在Java中基本数据类型的大小，例如int类型占4个字节、long类型占8个字节，那么Integer对象和Long对象会占用多少内存呢？</p>\n<p>​\t一、对象存储：</p>\n<p>​\t一个Java对象在内存中包括对象头、实例数据和补齐填充3个部分：</p>\n<p><img src=\"/img/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A81.png\" alt=\"image-20191120195326698\"></p>\n<p>​</p>\n<p>​\t(1) 对齐填充 :</p>\n<p>​\tJava对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。</p>\n<p>​\t例如，一个包含两个属性的对象：int和byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。</p>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A82.png\" alt=\"image-20191120195453758\"></p>\n<p>32位系统 对象头占用空间= 4 + 4 = 8 byte</p>\n<p>64位系统 对象头占用空间= 8 + 8 =16 byte</p>\n<p>64位开启指针压缩 对象头占用空间= 4 + 8 = 12 byte</p>\n<p>注：</p>\n<p>​\t若为数组对象，对象头占用空间 + 4 byte</p>\n<p>​\t静态属性不算在对象大小内</p>\n<p>​\t从JDK 1.6 update14开始，64位的JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。</p>\n<p>​\tJDK 1.8，默认该参数就是开启的。</p>\n<p>​    (2)  对象的实际数据</p>\n<p>​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定</p>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A83.png\" alt=\"image-20191120195618441\"></p>\n<p>​\t对于reference类型来说，在32位系统上占用4bytes, 在64位系统上占用8bytes。</p>\n<p>​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定，</p>\n<p>​\t比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。</p>\n<p>二、指针压缩</p>\n<p>​    从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。</p>\n<p>​    对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的</p>\n<p>OOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用CompressOops后，会压缩的对象：</p>\n<p>​\t每个Class的属性指针（静态成员变量）；</p>\n<p>​\t每个对象的属性指针；</p>\n<p>​\t普通对象数组的每个元素指针。</p>\n<p>​\t当然，压缩也不是所有的指针都会压缩，对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen（1.8废弃）的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。</p>\n<p>​\t1.新生代：Eden+From Survivor+To Survivor</p>\n<p>​\t2.老年代：OldGen</p>\n<p>​\t3.永久代（方法区的实现） : PermGen-----&gt;替换为Metaspace(本地内存中)</p>\n<p>​\t(1) 验证对象头大小</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A91.png\" alt=\"image-20191120195845734\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；</p>\n<p>​\t实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之内）</p>\n<p>​\t共24 byte</p>\n<p>​\t(2) 验证对象头大小 非压缩情况下</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A92.png\" alt=\"image-20191120200005300\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为8字节+MarkWord为8字节=16字节；</p>\n<p>​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）</p>\n<p>​\t共32byte</p>\n<p>​\t(3) 验证对象头对齐填充</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A93.png\" alt=\"image-20191120200059442\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；</p>\n<p>​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）</p>\n<p>​\t共20byte 所以需要有4字节的填充</p>\n<p>​\t(4) 验证对象头 数组</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A94.png\" alt=\"image-20191120200152966\"></p>\n<p>​\tShallow Size比较简单，这里对象头大小为12字节， 实际数据大小为4字节，所以Shallow Size为16。</p>\n<p>​\t对于Retained Size来说，要计算数组占用的大小，对于数组来说，它的对象头部多了一个用来存储数组长度的空间，该空间大小为4字节，所以数组对象的大小 = 引用对象头大小12字节 + 存储数组长度的空间大小4字节 + 数组的长度*数组中对象的RetainedSize + padding大小</p>\n<p>​\tlong[] arr = new long[6];，它是一个长度为6的long类型的数组，由于long类型的大小为8字节，所以数组中的实际数据是6<em>8=48字节，那么数组对象的大小=12+4+6</em>8+0=64，最终的Retained Size=Shallow Size + 数组对象大小=16+64=80。</p>\n<p>主要参考：http://www.ideabuffer.cn/2017/05/06/Java对象内存布局/</p>\n","site":{"data":{}},"excerpt":"","more":"<p>​\t我们知道在Java中基本数据类型的大小，例如int类型占4个字节、long类型占8个字节，那么Integer对象和Long对象会占用多少内存呢？</p>\n<p>​\t一、对象存储：</p>\n<p>​\t一个Java对象在内存中包括对象头、实例数据和补齐填充3个部分：</p>\n<p><img src=\"/img/%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A81.png\" alt=\"image-20191120195326698\"></p>\n<p>​</p>\n<p>​\t(1) 对齐填充 :</p>\n<p>​\tJava对象占用空间是8字节对齐的，即所有Java对象占用bytes数必须是8的倍数。</p>\n<p>​\t例如，一个包含两个属性的对象：int和byte，这个对象需要占用8+4+1=13个字节，这时就需要加上大小为3字节的padding进行8字节对齐，最终占用大小为16个字节。</p>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A82.png\" alt=\"image-20191120195453758\"></p>\n<p>32位系统 对象头占用空间= 4 + 4 = 8 byte</p>\n<p>64位系统 对象头占用空间= 8 + 8 =16 byte</p>\n<p>64位开启指针压缩 对象头占用空间= 4 + 8 = 12 byte</p>\n<p>注：</p>\n<p>​\t若为数组对象，对象头占用空间 + 4 byte</p>\n<p>​\t静态属性不算在对象大小内</p>\n<p>​\t从JDK 1.6 update14开始，64位的JVM正式支持了 -XX:+UseCompressedOops 这个可以压缩指针，起到节约内存占用的新参数。</p>\n<p>​\tJDK 1.8，默认该参数就是开启的。</p>\n<p>​    (2)  对象的实际数据</p>\n<p>​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定</p>\n<p><img src=\"/img/java%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A83.png\" alt=\"image-20191120195618441\"></p>\n<p>​\t对于reference类型来说，在32位系统上占用4bytes, 在64位系统上占用8bytes。</p>\n<p>​\t对象实际数据包括了对象的所有成员变量，其大小由各个成员变量的大小决定，</p>\n<p>​\t比如：byte和boolean是1个字节，short和char是2个字节，int和float是4个字节，long和double是8个字节，reference是4个字节（64位系统中是8个字节）。</p>\n<p>二、指针压缩</p>\n<p>​    从上文的分析中可以看到，64位JVM消耗的内存会比32位的要多大约1.5倍，这是因为对象指针在64位JVM下有更宽的寻址。</p>\n<p>​    对于那些将要从32位平台移植到64位的应用来说，平白无辜多了1/2的内存占用，这是开发者不愿意看到的</p>\n<p>OOP的全称为：Ordinary Object Pointer，就是普通对象指针。启用CompressOops后，会压缩的对象：</p>\n<p>​\t每个Class的属性指针（静态成员变量）；</p>\n<p>​\t每个对象的属性指针；</p>\n<p>​\t普通对象数组的每个元素指针。</p>\n<p>​\t当然，压缩也不是所有的指针都会压缩，对一些特殊类型的指针，JVM是不会优化的，例如指向PermGen（1.8废弃）的Class对象指针、本地变量、堆栈元素、入参、返回值和NULL指针不会被压缩。</p>\n<p>​\t1.新生代：Eden+From Survivor+To Survivor</p>\n<p>​\t2.老年代：OldGen</p>\n<p>​\t3.永久代（方法区的实现） : PermGen-----&gt;替换为Metaspace(本地内存中)</p>\n<p>​\t(1) 验证对象头大小</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A91.png\" alt=\"image-20191120195845734\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；</p>\n<p>​\t实际数据大小=int类型4字节+long类型8字节=12字节（静态变量不在计算范围之内）</p>\n<p>​\t共24 byte</p>\n<p>​\t(2) 验证对象头大小 非压缩情况下</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A92.png\" alt=\"image-20191120200005300\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为8字节+MarkWord为8字节=16字节；</p>\n<p>​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）</p>\n<p>​\t共32byte</p>\n<p>​\t(3) 验证对象头对齐填充</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A93.png\" alt=\"image-20191120200059442\"></p>\n<p>​\t对象头大小=Class Pointer的空间大小为4字节+MarkWord为8字节=12字节；</p>\n<p>​\t实际数据大小=int类型4字节+int类型4字节=8字节（静态变量不在计算范围之内）</p>\n<p>​\t共20byte 所以需要有4字节的填充</p>\n<p>​\t(4) 验证对象头 数组</p>\n<p><img src=\"/img/%E6%8C%87%E9%92%88%E5%8E%8B%E7%BC%A94.png\" alt=\"image-20191120200152966\"></p>\n<p>​\tShallow Size比较简单，这里对象头大小为12字节， 实际数据大小为4字节，所以Shallow Size为16。</p>\n<p>​\t对于Retained Size来说，要计算数组占用的大小，对于数组来说，它的对象头部多了一个用来存储数组长度的空间，该空间大小为4字节，所以数组对象的大小 = 引用对象头大小12字节 + 存储数组长度的空间大小4字节 + 数组的长度*数组中对象的RetainedSize + padding大小</p>\n<p>​\tlong[] arr = new long[6];，它是一个长度为6的long类型的数组，由于long类型的大小为8字节，所以数组中的实际数据是6<em>8=48字节，那么数组对象的大小=12+4+6</em>8+0=64，最终的Retained Size=Shallow Size + 数组对象大小=16+64=80。</p>\n<p>主要参考：http://www.ideabuffer.cn/2017/05/06/Java对象内存布局/</p>\n"},{"title":"图解公钥私钥","author":"郑天祺","date":"2019-09-24T13:32:00.000Z","_content":"\n\n1、鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n\n![1569332117257](/img/公钥私钥1.png)\n\n2、鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。\n\n![1569332140572](/img/公钥私钥2.png)\n\n3、苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n\n![1569332191207](/img/公钥私钥3.png)\n\n4、鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n\n![1569332213926](/img/公钥私钥4.png)\n\n5、鲍勃给苏珊回信，决定采用\"数字签名\"。他写完后先用Hash函数，生成信件的摘要（digest）。\n\n![1569332234555](/img/公钥私钥5.png)\n\n6、然后，鲍勃使用私钥，对这个摘要加密，生成\"数字签名\"（signature）。\n\n![1569332255195](/img/公钥私钥6.png)\n\n7、鲍勃将这个签名，附在信件下面，一起发给苏珊。\n\n![1569332274920](/img/公钥私钥7.png)\n\n8、苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n\n![1569332297876](/img/公钥私钥8.png)\n\n9、苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n\n![1569332325389](/img/公钥私钥9.png)\n\n10、复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\"数字签名\"，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n\n![1569332348936](/img/公钥私钥10.png)\n\n11、后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\"证书中心\"（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\"数字证书\"（Digital Certificate）。\n\n![1569332371090](/img/公钥私钥11.png)\n\n12、鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n\n![1569332395630](/img/公钥私钥12.png)\n\n13、苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的。\n\n![1569332424970](/img/公钥私钥13.png)\n\n14、下面，我们看一个应用\"数字证书\"的实例：https协议。这个协议主要用于网页加密。\n\n![1569332446930](/img/HTTPS1.png)\n\n15、首先，客户端向服务器发出加密请求。\n\n![1569332470793](/img/HTTPS2.png)\n\n16、服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。\n\n![1569332492570](/img/HTTPS3.png)\n\n17、客户端（浏览器）的\"证书管理器\"，有\"受信任的根证书颁发机构\"列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。\n\n![1569332511083](/img/HTTPS4.png)\n\n18、如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。\n\n![1569332532928](/img/HTTPS5.png)\n\n19、如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。\n\n![1569332579189](/img/HTTPS6.png)\n\n","source":"_posts/图解公钥与私钥.md","raw":"title: 图解公钥私钥\nauthor: 郑天祺\ntags:\n\n  - 可信\n  - 密码学\ncategories:\n  - 可信\ndate: 2019-09-24 21:32:00\n---\n\n\n1、鲍勃有两把钥匙，一把是公钥，另一把是私钥。\n\n![1569332117257](/img/公钥私钥1.png)\n\n2、鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。\n\n![1569332140572](/img/公钥私钥2.png)\n\n3、苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。\n\n![1569332191207](/img/公钥私钥3.png)\n\n4、鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。\n\n![1569332213926](/img/公钥私钥4.png)\n\n5、鲍勃给苏珊回信，决定采用\"数字签名\"。他写完后先用Hash函数，生成信件的摘要（digest）。\n\n![1569332234555](/img/公钥私钥5.png)\n\n6、然后，鲍勃使用私钥，对这个摘要加密，生成\"数字签名\"（signature）。\n\n![1569332255195](/img/公钥私钥6.png)\n\n7、鲍勃将这个签名，附在信件下面，一起发给苏珊。\n\n![1569332274920](/img/公钥私钥7.png)\n\n8、苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。\n\n![1569332297876](/img/公钥私钥8.png)\n\n9、苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。\n\n![1569332325389](/img/公钥私钥9.png)\n\n10、复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成\"数字签名\"，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。\n\n![1569332348936](/img/公钥私钥10.png)\n\n11、后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找\"证书中心\"（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成\"数字证书\"（Digital Certificate）。\n\n![1569332371090](/img/公钥私钥11.png)\n\n12、鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。\n\n![1569332395630](/img/公钥私钥12.png)\n\n13、苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明\"数字签名\"是否真的是鲍勃签的。\n\n![1569332424970](/img/公钥私钥13.png)\n\n14、下面，我们看一个应用\"数字证书\"的实例：https协议。这个协议主要用于网页加密。\n\n![1569332446930](/img/HTTPS1.png)\n\n15、首先，客户端向服务器发出加密请求。\n\n![1569332470793](/img/HTTPS2.png)\n\n16、服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。\n\n![1569332492570](/img/HTTPS3.png)\n\n17、客户端（浏览器）的\"证书管理器\"，有\"受信任的根证书颁发机构\"列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。\n\n![1569332511083](/img/HTTPS4.png)\n\n18、如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。\n\n![1569332532928](/img/HTTPS5.png)\n\n19、如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。\n\n![1569332579189](/img/HTTPS6.png)\n\n","slug":"图解公钥与私钥","published":1,"updated":"2019-09-24T13:51:57.731Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1o002avguq28dayryw","content":"<p>1、鲍勃有两把钥匙，一把是公钥，另一把是私钥。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A51.png\" alt=\"1569332117257\"></p>\n<p>2、鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A52.png\" alt=\"1569332140572\"></p>\n<p>3、苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A53.png\" alt=\"1569332191207\"></p>\n<p>4、鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A54.png\" alt=\"1569332213926\"></p>\n<p>5、鲍勃给苏珊回信，决定采用&quot;数字签名&quot;。他写完后先用Hash函数，生成信件的摘要（digest）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A55.png\" alt=\"1569332234555\"></p>\n<p>6、然后，鲍勃使用私钥，对这个摘要加密，生成&quot;数字签名&quot;（signature）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A56.png\" alt=\"1569332255195\"></p>\n<p>7、鲍勃将这个签名，附在信件下面，一起发给苏珊。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A57.png\" alt=\"1569332274920\"></p>\n<p>8、苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A58.png\" alt=\"1569332297876\"></p>\n<p>9、苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A59.png\" alt=\"1569332325389\"></p>\n<p>10、复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成&quot;数字签名&quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A510.png\" alt=\"1569332348936\"></p>\n<p>11、后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找&quot;证书中心&quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成&quot;数字证书&quot;（Digital Certificate）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A511.png\" alt=\"1569332371090\"></p>\n<p>12、鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A512.png\" alt=\"1569332395630\"></p>\n<p>13、苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明&quot;数字签名&quot;是否真的是鲍勃签的。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A513.png\" alt=\"1569332424970\"></p>\n<p>14、下面，我们看一个应用&quot;数字证书&quot;的实例：https协议。这个协议主要用于网页加密。</p>\n<p><img src=\"/img/HTTPS1.png\" alt=\"1569332446930\"></p>\n<p>15、首先，客户端向服务器发出加密请求。</p>\n<p><img src=\"/img/HTTPS2.png\" alt=\"1569332470793\"></p>\n<p>16、服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。</p>\n<p><img src=\"/img/HTTPS3.png\" alt=\"1569332492570\"></p>\n<p>17、客户端（浏览器）的&quot;证书管理器&quot;，有&quot;受信任的根证书颁发机构&quot;列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。</p>\n<p><img src=\"/img/HTTPS4.png\" alt=\"1569332511083\"></p>\n<p>18、如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。</p>\n<p><img src=\"/img/HTTPS5.png\" alt=\"1569332532928\"></p>\n<p>19、如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。</p>\n<p><img src=\"/img/HTTPS6.png\" alt=\"1569332579189\"></p>\n","site":{"data":{}},"excerpt":"","more":"<p>1、鲍勃有两把钥匙，一把是公钥，另一把是私钥。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A51.png\" alt=\"1569332117257\"></p>\n<p>2、鲍勃把公钥送给他的朋友们----帕蒂、道格、苏珊----每人一把。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A52.png\" alt=\"1569332140572\"></p>\n<p>3、苏珊要给鲍勃写一封保密的信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A53.png\" alt=\"1569332191207\"></p>\n<p>4、鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A54.png\" alt=\"1569332213926\"></p>\n<p>5、鲍勃给苏珊回信，决定采用&quot;数字签名&quot;。他写完后先用Hash函数，生成信件的摘要（digest）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A55.png\" alt=\"1569332234555\"></p>\n<p>6、然后，鲍勃使用私钥，对这个摘要加密，生成&quot;数字签名&quot;（signature）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A56.png\" alt=\"1569332255195\"></p>\n<p>7、鲍勃将这个签名，附在信件下面，一起发给苏珊。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A57.png\" alt=\"1569332274920\"></p>\n<p>8、苏珊收信后，取下数字签名，用鲍勃的公钥解密，得到信件的摘要。由此证明，这封信确实是鲍勃发出的。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A58.png\" alt=\"1569332297876\"></p>\n<p>9、苏珊再对信件本身使用Hash函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A59.png\" alt=\"1569332325389\"></p>\n<p>10、复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成&quot;数字签名&quot;，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A510.png\" alt=\"1569332348936\"></p>\n<p>11、后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找&quot;证书中心&quot;（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成&quot;数字证书&quot;（Digital Certificate）。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A511.png\" alt=\"1569332371090\"></p>\n<p>12、鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A512.png\" alt=\"1569332395630\"></p>\n<p>13、苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明&quot;数字签名&quot;是否真的是鲍勃签的。</p>\n<p><img src=\"/img/%E5%85%AC%E9%92%A5%E7%A7%81%E9%92%A513.png\" alt=\"1569332424970\"></p>\n<p>14、下面，我们看一个应用&quot;数字证书&quot;的实例：https协议。这个协议主要用于网页加密。</p>\n<p><img src=\"/img/HTTPS1.png\" alt=\"1569332446930\"></p>\n<p>15、首先，客户端向服务器发出加密请求。</p>\n<p><img src=\"/img/HTTPS2.png\" alt=\"1569332470793\"></p>\n<p>16、服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。</p>\n<p><img src=\"/img/HTTPS3.png\" alt=\"1569332492570\"></p>\n<p>17、客户端（浏览器）的&quot;证书管理器&quot;，有&quot;受信任的根证书颁发机构&quot;列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。</p>\n<p><img src=\"/img/HTTPS4.png\" alt=\"1569332511083\"></p>\n<p>18、如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。</p>\n<p><img src=\"/img/HTTPS5.png\" alt=\"1569332532928\"></p>\n<p>19、如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。</p>\n<p><img src=\"/img/HTTPS6.png\" alt=\"1569332579189\"></p>\n"},{"title":"可重入锁","author":"郑天祺","date":"2019-08-31T05:05:00.000Z","_content":"\n## 1、可重入锁：\n\n​\t也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。\n​\t\"独占\"，就是在同一时刻只能有一个线程获取到锁，而其它获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁。\n\n​\t“可重入“，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。\n\n​\t在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。\n\n## 2、Synchronized和ReentrantLock\n\n**1）性能区别：**\n\n​         在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实    synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。\n\n2）原理区别：\n\n​         Synchronized: 进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。 \n\n​         ReentrantLock: 是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：\n\n1. 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。通过lock.lockInterruptibly()来实现这个机制。\n2. 公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。\n3. 锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。\n\n3) demo\n\n```java\n public class SynchronizedTest implements Runnable {\n     public synchronized void get() {\n         System.out.println(Thread.currentThread().getName());\n         set();\n     }\n     public synchronized void set() {\n         System.out.println(Thread.currentThread().getName());\n     }\n     @Override\n     public void run() {\n         get();\n     }\n     public static void main(String[] args) {\n         SynchronizedTest synchronizedTest = new SynchronizedTest();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n     }\n }\n\n \n\npublic class ReentrantLockTest implements Runnable {\n     ReentrantLock lock = new ReentrantLock();\n\n    public void get() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         set();\n         lock.unlock();\n     }\n\n    public void set() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         lock.unlock();\n     }\n\n    @Override\n     public void run() {\n         get();\n     }\n\n    public static void main(String[] args) {\n         ReentrantLockTest lock = new ReentrantLockTest();\n         new Thread(lock).start();\n         new Thread(lock).start();\n         new Thread(lock).start();\n     }\n }\n\n \n```\n\n","source":"_posts/可重入锁.md","raw":"title: 可重入锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:05:00\n\n---\n\n## 1、可重入锁：\n\n​\t也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。\n​\t\"独占\"，就是在同一时刻只能有一个线程获取到锁，而其它获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁。\n\n​\t“可重入“，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。\n\n​\t在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。\n\n## 2、Synchronized和ReentrantLock\n\n**1）性能区别：**\n\n​         在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实    synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。\n\n2）原理区别：\n\n​         Synchronized: 进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。 \n\n​         ReentrantLock: 是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：\n\n1. 等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。通过lock.lockInterruptibly()来实现这个机制。\n2. 公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。\n3. 锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。\n\n3) demo\n\n```java\n public class SynchronizedTest implements Runnable {\n     public synchronized void get() {\n         System.out.println(Thread.currentThread().getName());\n         set();\n     }\n     public synchronized void set() {\n         System.out.println(Thread.currentThread().getName());\n     }\n     @Override\n     public void run() {\n         get();\n     }\n     public static void main(String[] args) {\n         SynchronizedTest synchronizedTest = new SynchronizedTest();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n     }\n }\n\n \n\npublic class ReentrantLockTest implements Runnable {\n     ReentrantLock lock = new ReentrantLock();\n\n    public void get() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         set();\n         lock.unlock();\n     }\n\n    public void set() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         lock.unlock();\n     }\n\n    @Override\n     public void run() {\n         get();\n     }\n\n    public static void main(String[] args) {\n         ReentrantLockTest lock = new ReentrantLockTest();\n         new Thread(lock).start();\n         new Thread(lock).start();\n         new Thread(lock).start();\n     }\n }\n\n \n```\n\n","slug":"可重入锁","published":1,"updated":"2019-10-15T10:07:40.790Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1q002dvguqgy5hfxsu","content":"<h2>1、可重入锁：</h2>\n<p>​\t也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。\n​\t&quot;独占&quot;，就是在同一时刻只能有一个线程获取到锁，而其它获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁。</p>\n<p>​\t“可重入“，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。</p>\n<p>​\t在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。</p>\n<h2>2、Synchronized和ReentrantLock</h2>\n<p><strong>1）性能区别：</strong></p>\n<p>​         在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实    synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。</p>\n<p>2）原理区别：</p>\n<p>​         Synchronized: 进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。</p>\n<p>​         ReentrantLock: 是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：</p>\n<ol>\n<li>等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。通过lock.lockInterruptibly()来实现这个机制。</li>\n<li>公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。</li>\n<li>锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。</li>\n</ol>\n<ol start=\"3\">\n<li>demo</li>\n</ol>\n<pre><code class=\"language-java\"> public class SynchronizedTest implements Runnable {\n     public synchronized void get() {\n         System.out.println(Thread.currentThread().getName());\n         set();\n     }\n     public synchronized void set() {\n         System.out.println(Thread.currentThread().getName());\n     }\n     @Override\n     public void run() {\n         get();\n     }\n     public static void main(String[] args) {\n         SynchronizedTest synchronizedTest = new SynchronizedTest();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n     }\n }\n\n \n\npublic class ReentrantLockTest implements Runnable {\n     ReentrantLock lock = new ReentrantLock();\n\n    public void get() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         set();\n         lock.unlock();\n     }\n\n    public void set() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         lock.unlock();\n     }\n\n    @Override\n     public void run() {\n         get();\n     }\n\n    public static void main(String[] args) {\n         ReentrantLockTest lock = new ReentrantLockTest();\n         new Thread(lock).start();\n         new Thread(lock).start();\n         new Thread(lock).start();\n     }\n }\n\n \n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、可重入锁：</h2>\n<p>​\t也叫做递归锁，指的是同一线程 外层函数获得锁之后 ，内层递归函数仍然有获取该锁的代码，但不受影响。\n​\t&quot;独占&quot;，就是在同一时刻只能有一个线程获取到锁，而其它获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁。</p>\n<p>​\t“可重入“，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。</p>\n<p>​\t在JAVA环境下 ReentrantLock 和synchronized 都是可重入锁。</p>\n<h2>2、Synchronized和ReentrantLock</h2>\n<p><strong>1）性能区别：</strong></p>\n<p>​         在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，官方甚至建议使用synchronized，其实    synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。</p>\n<p>2）原理区别：</p>\n<p>​         Synchronized: 进过编译，会在同步块的前后分别形成monitorenter和monitorexit这个两个字节码指令。在执行monitorenter指令时，首先要尝试获取对象锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象锁，把锁的计算器加1，相应的，在执行monitorexit指令时会将锁计算器就减1，当计算器为0时，锁就被释放了。如果获取对象锁失败，那当前线程就要阻塞，直到对象锁被另一个线程释放为止。</p>\n<p>​         ReentrantLock: 是java.util.concurrent包下提供的一套互斥锁，相比Synchronized，ReentrantLock类提供了一些高级功能，主要有以下3项：</p>\n<ol>\n<li>等待可中断，持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。通过lock.lockInterruptibly()来实现这个机制。</li>\n<li>公平锁，多个线程等待同一个锁时，必须按照申请锁的时间顺序获得锁，Synchronized锁非公平锁，ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。</li>\n<li>锁绑定多个条件，一个ReentrantLock对象可以同时绑定对个对象。ReenTrantLock提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。</li>\n</ol>\n<ol start=\"3\">\n<li>demo</li>\n</ol>\n<pre><code class=\"language-java\"> public class SynchronizedTest implements Runnable {\n     public synchronized void get() {\n         System.out.println(Thread.currentThread().getName());\n         set();\n     }\n     public synchronized void set() {\n         System.out.println(Thread.currentThread().getName());\n     }\n     @Override\n     public void run() {\n         get();\n     }\n     public static void main(String[] args) {\n         SynchronizedTest synchronizedTest = new SynchronizedTest();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n         new Thread(synchronizedTest).start();\n     }\n }\n\n \n\npublic class ReentrantLockTest implements Runnable {\n     ReentrantLock lock = new ReentrantLock();\n\n    public void get() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         set();\n         lock.unlock();\n     }\n\n    public void set() {\n         lock.lock();\n         System.out.println(Thread.currentThread());\n         lock.unlock();\n     }\n\n    @Override\n     public void run() {\n         get();\n     }\n\n    public static void main(String[] args) {\n         ReentrantLockTest lock = new ReentrantLockTest();\n         new Thread(lock).start();\n         new Thread(lock).start();\n         new Thread(lock).start();\n     }\n }\n\n \n</code></pre>\n"},{"title":"文件上传之Content-Type","author":"郑天祺","date":"2019-08-31T08:15:00.000Z","_content":"\n## 1、Content-Type介绍\n\n**Content-Type**是指http/https发送信息至服务器时的内容编码类型，contentType用于表明发送数据流的类型，服务器根据编码类型使用特定的解析方式，获取数据流中的数据。\n\n在网络请求中，常见的Content-Type有：\n\n### \t1.1、常见的页面资源类型\n\n​\ttext/html，text/plain，text/css，text/javascript，image/jpeg，image/png，image/gif等；\n\n​\t常见的页面提交或上传文件类型\t\n\n​\tapplication/x-www-form-urlencoded，multipart/form-data，application/json，application/xml等。\n\n### \t1.2、form表单可以定义enctype属性，该属性是发送到服务器之前应该如何对表单数据进行编码\n\n（1）默认为application/x-www-form-urlencoded编码（包含POST和GET）\n\n​\t\t\t其中：数据会变成key1=value1&key2=value2的形式；\n\n​\t\t\t\t\t\t有特殊字符需要utf-8；\n\n​\t\t\t\t\t\t请求类型为GET时，格式化后的字符串直接拼接到url的后面；\n\n​\t\t\t\t\t\t请求类型为POST时，格式化后的字符串会放在http body的Form Data中发送。\n\n （2）multipart/form-data\n\n​\t\t\t其中：使用表单上传文件时必须指定enctype属性值为multipart/form-data；\n\n​\t\t\t\t\t\t请求体被分割成多部分，每部分使用 --boundary分割（分成小部分？查其他资料）\n\n此处为form方式文件上传后端接收demo：\n\n```java\n@PostMapping(value=\"/publish\")\npublic void formUpload(@RequestParam(\"programImg\") CommonsMultipartFile file){\n\n\t\tString programImgName =  file.getOriginalFilename();\t\t\n        byte[] fileData =  file.getBytes();\n}\n```\n​\t（3）application/json\n\n​\t\t\t和form类似，json可以比formData的数据结构更加复杂\n\n​\t\t\t文件上传可以把文件编码成Base64，使用键值方式上传\n\n此处为json方式文件上传后端接收demo：\n\n```java\n@PostMapping(value = \"/upload\")\npublic void jsonUpload(@RequestBody HashMap<String, String> requestMap) {\n    \n        String fileData = requestMap.get(\"fileData\");\n        String fileName = requestMap.get(\"fileName\");\n        // 此处前端上传的Base64后端无法直接解开，因为它的串包含一个头，需要把头去掉。\n\t\tfileData = StringUtils.split(fileData, \",\")[1];\n        byte[] buffer = new BASE64Decoder().decodeBuffer(fileData);\n}\n```\n\n​\t\t\n\n","source":"_posts/文件上传.md","raw":"title: 文件上传之Content-Type\nauthor: 郑天祺\ntags:\n  - 文件上传\ncategories:\n  - java基础\ndate: 2019-08-31 16:15:00\n\n---\n\n## 1、Content-Type介绍\n\n**Content-Type**是指http/https发送信息至服务器时的内容编码类型，contentType用于表明发送数据流的类型，服务器根据编码类型使用特定的解析方式，获取数据流中的数据。\n\n在网络请求中，常见的Content-Type有：\n\n### \t1.1、常见的页面资源类型\n\n​\ttext/html，text/plain，text/css，text/javascript，image/jpeg，image/png，image/gif等；\n\n​\t常见的页面提交或上传文件类型\t\n\n​\tapplication/x-www-form-urlencoded，multipart/form-data，application/json，application/xml等。\n\n### \t1.2、form表单可以定义enctype属性，该属性是发送到服务器之前应该如何对表单数据进行编码\n\n（1）默认为application/x-www-form-urlencoded编码（包含POST和GET）\n\n​\t\t\t其中：数据会变成key1=value1&key2=value2的形式；\n\n​\t\t\t\t\t\t有特殊字符需要utf-8；\n\n​\t\t\t\t\t\t请求类型为GET时，格式化后的字符串直接拼接到url的后面；\n\n​\t\t\t\t\t\t请求类型为POST时，格式化后的字符串会放在http body的Form Data中发送。\n\n （2）multipart/form-data\n\n​\t\t\t其中：使用表单上传文件时必须指定enctype属性值为multipart/form-data；\n\n​\t\t\t\t\t\t请求体被分割成多部分，每部分使用 --boundary分割（分成小部分？查其他资料）\n\n此处为form方式文件上传后端接收demo：\n\n```java\n@PostMapping(value=\"/publish\")\npublic void formUpload(@RequestParam(\"programImg\") CommonsMultipartFile file){\n\n\t\tString programImgName =  file.getOriginalFilename();\t\t\n        byte[] fileData =  file.getBytes();\n}\n```\n​\t（3）application/json\n\n​\t\t\t和form类似，json可以比formData的数据结构更加复杂\n\n​\t\t\t文件上传可以把文件编码成Base64，使用键值方式上传\n\n此处为json方式文件上传后端接收demo：\n\n```java\n@PostMapping(value = \"/upload\")\npublic void jsonUpload(@RequestBody HashMap<String, String> requestMap) {\n    \n        String fileData = requestMap.get(\"fileData\");\n        String fileName = requestMap.get(\"fileName\");\n        // 此处前端上传的Base64后端无法直接解开，因为它的串包含一个头，需要把头去掉。\n\t\tfileData = StringUtils.split(fileData, \",\")[1];\n        byte[] buffer = new BASE64Decoder().decodeBuffer(fileData);\n}\n```\n\n​\t\t\n\n","slug":"文件上传","published":1,"updated":"2019-10-15T12:09:54.589Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1s002gvguq49abzq2w","content":"<h2>1、Content-Type介绍</h2>\n<p><strong>Content-Type</strong>是指http/https发送信息至服务器时的内容编码类型，contentType用于表明发送数据流的类型，服务器根据编码类型使用特定的解析方式，获取数据流中的数据。</p>\n<p>在网络请求中，常见的Content-Type有：</p>\n<h3>1.1、常见的页面资源类型</h3>\n<p>​\ttext/html，text/plain，text/css，text/javascript，image/jpeg，image/png，image/gif等；</p>\n<p>​\t常见的页面提交或上传文件类型</p>\n<p>​\tapplication/x-www-form-urlencoded，multipart/form-data，application/json，application/xml等。</p>\n<h3>1.2、form表单可以定义enctype属性，该属性是发送到服务器之前应该如何对表单数据进行编码</h3>\n<p>（1）默认为application/x-www-form-urlencoded编码（包含POST和GET）</p>\n<p>​\t\t\t其中：数据会变成key1=value1&amp;key2=value2的形式；</p>\n<p>​\t\t\t\t\t\t有特殊字符需要utf-8；</p>\n<p>​\t\t\t\t\t\t请求类型为GET时，格式化后的字符串直接拼接到url的后面；</p>\n<p>​\t\t\t\t\t\t请求类型为POST时，格式化后的字符串会放在http body的Form Data中发送。</p>\n<p>（2）multipart/form-data</p>\n<p>​\t\t\t其中：使用表单上传文件时必须指定enctype属性值为multipart/form-data；</p>\n<p>​\t\t\t\t\t\t请求体被分割成多部分，每部分使用 --boundary分割（分成小部分？查其他资料）</p>\n<p>此处为form方式文件上传后端接收demo：</p>\n<pre><code class=\"language-java\">@PostMapping(value=&quot;/publish&quot;)\npublic void formUpload(@RequestParam(&quot;programImg&quot;) CommonsMultipartFile file){\n\n\t\tString programImgName =  file.getOriginalFilename();\t\t\n        byte[] fileData =  file.getBytes();\n}\n</code></pre>\n<p>​\t（3）application/json</p>\n<p>​\t\t\t和form类似，json可以比formData的数据结构更加复杂</p>\n<p>​\t\t\t文件上传可以把文件编码成Base64，使用键值方式上传</p>\n<p>此处为json方式文件上传后端接收demo：</p>\n<pre><code class=\"language-java\">@PostMapping(value = &quot;/upload&quot;)\npublic void jsonUpload(@RequestBody HashMap&lt;String, String&gt; requestMap) {\n    \n        String fileData = requestMap.get(&quot;fileData&quot;);\n        String fileName = requestMap.get(&quot;fileName&quot;);\n        // 此处前端上传的Base64后端无法直接解开，因为它的串包含一个头，需要把头去掉。\n\t\tfileData = StringUtils.split(fileData, &quot;,&quot;)[1];\n        byte[] buffer = new BASE64Decoder().decodeBuffer(fileData);\n}\n</code></pre>\n<p>​</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、Content-Type介绍</h2>\n<p><strong>Content-Type</strong>是指http/https发送信息至服务器时的内容编码类型，contentType用于表明发送数据流的类型，服务器根据编码类型使用特定的解析方式，获取数据流中的数据。</p>\n<p>在网络请求中，常见的Content-Type有：</p>\n<h3>1.1、常见的页面资源类型</h3>\n<p>​\ttext/html，text/plain，text/css，text/javascript，image/jpeg，image/png，image/gif等；</p>\n<p>​\t常见的页面提交或上传文件类型</p>\n<p>​\tapplication/x-www-form-urlencoded，multipart/form-data，application/json，application/xml等。</p>\n<h3>1.2、form表单可以定义enctype属性，该属性是发送到服务器之前应该如何对表单数据进行编码</h3>\n<p>（1）默认为application/x-www-form-urlencoded编码（包含POST和GET）</p>\n<p>​\t\t\t其中：数据会变成key1=value1&amp;key2=value2的形式；</p>\n<p>​\t\t\t\t\t\t有特殊字符需要utf-8；</p>\n<p>​\t\t\t\t\t\t请求类型为GET时，格式化后的字符串直接拼接到url的后面；</p>\n<p>​\t\t\t\t\t\t请求类型为POST时，格式化后的字符串会放在http body的Form Data中发送。</p>\n<p>（2）multipart/form-data</p>\n<p>​\t\t\t其中：使用表单上传文件时必须指定enctype属性值为multipart/form-data；</p>\n<p>​\t\t\t\t\t\t请求体被分割成多部分，每部分使用 --boundary分割（分成小部分？查其他资料）</p>\n<p>此处为form方式文件上传后端接收demo：</p>\n<pre><code class=\"language-java\">@PostMapping(value=&quot;/publish&quot;)\npublic void formUpload(@RequestParam(&quot;programImg&quot;) CommonsMultipartFile file){\n\n\t\tString programImgName =  file.getOriginalFilename();\t\t\n        byte[] fileData =  file.getBytes();\n}\n</code></pre>\n<p>​\t（3）application/json</p>\n<p>​\t\t\t和form类似，json可以比formData的数据结构更加复杂</p>\n<p>​\t\t\t文件上传可以把文件编码成Base64，使用键值方式上传</p>\n<p>此处为json方式文件上传后端接收demo：</p>\n<pre><code class=\"language-java\">@PostMapping(value = &quot;/upload&quot;)\npublic void jsonUpload(@RequestBody HashMap&lt;String, String&gt; requestMap) {\n    \n        String fileData = requestMap.get(&quot;fileData&quot;);\n        String fileName = requestMap.get(&quot;fileName&quot;);\n        // 此处前端上传的Base64后端无法直接解开，因为它的串包含一个头，需要把头去掉。\n\t\tfileData = StringUtils.split(fileData, &quot;,&quot;)[1];\n        byte[] buffer = new BASE64Decoder().decodeBuffer(fileData);\n}\n</code></pre>\n<p>​</p>\n"},{"title":"悲观锁、乐观锁","author":"郑天祺","date":"2019-08-31T05:16:00.000Z","_content":"\n## 1、悲观锁\n\n假设会发生并发冲突，屏蔽一切可能违反数据完整性的操作（具有强烈的独占和排他性）\n\n​           依赖数据库的锁机制实现，以保证操作最大程度的独占性。\n\n​     百度百科：正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。\n\n## 2、缺点\n\n数据库性能的大量开销，特别是对长事务而言，这样的开销无法承受\n\n \n\n## 3、实现方法\n\n​    **Mysql中 :**\n\n​    在sql后面加上 for update或者for update nowait\n\n​    for update和for update nowait区别：\n\n​         1. for update 锁定当前操作数据，其他事务等待\n\n​         2. for update nowait 锁定当前数据，其他事务发现数据被锁定，立即返回\"ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源\"\n\n​         例如：select * from account where name=\"123\" for update\n\n​         优点：无论是在单机还是分布式中，只要使用的是同一个数据库，那么悲观锁就能起到作用。\n\n​         缺点：锁定数据后，必将影响其他操作，在大流量的情况下，操作速度变慢\n\n​    **JAVA中 ：**\n\n​        独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。\n\n \n\n## 4、使用场景举例\n\n以MySQL InnoDB为例\n\n   Demo：\n\n​     \n\n```java\n   begin;\n\n        select amount from item where item_id = 1 for update;\n\n // 通过amount来做出一些行为,例如告诉用户库存不足,购买失败,然后只有amount > 1才进入更新库存操作\n\n        update item set amount = amount - 1 where item_id = 1;\n\n        commit;\n```\n\n​    由于是串行执行,其他事务的for update必须等该当前事务的 for update 语句执行,所以我们不必担心我们获得的amount被修改过,因为它永远是最新的\n\n \n\n### 0、乐观锁：\n\n不是真正的锁，而是一种实现 : 是一种实现的\n\n### 1、乐观锁：\n\n假设不会发生并发冲突，只有在提交操作时检查是否违反数据完整性，乐观锁不能解决脏读问题\n\n​            乐观锁大多都基于数据版本（version）记录机制实现，何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据表增加一个“version”字段来实现。读取出数据时，将此版本一同读出，之后更新时，对此版本后 +1。此时，将提交的版本数据与数据库表对应记录的当前版本信息对比时，如果提交的数据版本号大于数据库当前版本号，则予以更新，否则认为是过期数据。\n\n###  2、优缺点：\n\n​        优点 ：可以多个事务同时进行，然后根据返回的不同结果做相应的操作，避免了长事务中的数据库加锁开销。\n\n​        缺点 ：乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。\n\n在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。\n\n### 3、步骤 : \n\n```java\n\t// 1.查询出商品信息\n\tselect (status,status,version) from t_goods where id=#{id}\n\t// 2.根据商品信息生成订单\n\t// 3.修改商品\n\tupdate t_goods\n\tset status=2,version=version+1 where id=#{id} and versio{139}};\n```\n\n","source":"_posts/悲观锁、乐观锁.md","raw":"title: 悲观锁、乐观锁\nauthor: 郑天祺\ntags:\n  - 锁\n  - mysql\ncategories:\n  - 数据库\ndate: 2019-08-31 13:16:00\n\n---\n\n## 1、悲观锁\n\n假设会发生并发冲突，屏蔽一切可能违反数据完整性的操作（具有强烈的独占和排他性）\n\n​           依赖数据库的锁机制实现，以保证操作最大程度的独占性。\n\n​     百度百科：正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。\n\n## 2、缺点\n\n数据库性能的大量开销，特别是对长事务而言，这样的开销无法承受\n\n \n\n## 3、实现方法\n\n​    **Mysql中 :**\n\n​    在sql后面加上 for update或者for update nowait\n\n​    for update和for update nowait区别：\n\n​         1. for update 锁定当前操作数据，其他事务等待\n\n​         2. for update nowait 锁定当前数据，其他事务发现数据被锁定，立即返回\"ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源\"\n\n​         例如：select * from account where name=\"123\" for update\n\n​         优点：无论是在单机还是分布式中，只要使用的是同一个数据库，那么悲观锁就能起到作用。\n\n​         缺点：锁定数据后，必将影响其他操作，在大流量的情况下，操作速度变慢\n\n​    **JAVA中 ：**\n\n​        独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。\n\n \n\n## 4、使用场景举例\n\n以MySQL InnoDB为例\n\n   Demo：\n\n​     \n\n```java\n   begin;\n\n        select amount from item where item_id = 1 for update;\n\n // 通过amount来做出一些行为,例如告诉用户库存不足,购买失败,然后只有amount > 1才进入更新库存操作\n\n        update item set amount = amount - 1 where item_id = 1;\n\n        commit;\n```\n\n​    由于是串行执行,其他事务的for update必须等该当前事务的 for update 语句执行,所以我们不必担心我们获得的amount被修改过,因为它永远是最新的\n\n \n\n### 0、乐观锁：\n\n不是真正的锁，而是一种实现 : 是一种实现的\n\n### 1、乐观锁：\n\n假设不会发生并发冲突，只有在提交操作时检查是否违反数据完整性，乐观锁不能解决脏读问题\n\n​            乐观锁大多都基于数据版本（version）记录机制实现，何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据表增加一个“version”字段来实现。读取出数据时，将此版本一同读出，之后更新时，对此版本后 +1。此时，将提交的版本数据与数据库表对应记录的当前版本信息对比时，如果提交的数据版本号大于数据库当前版本号，则予以更新，否则认为是过期数据。\n\n###  2、优缺点：\n\n​        优点 ：可以多个事务同时进行，然后根据返回的不同结果做相应的操作，避免了长事务中的数据库加锁开销。\n\n​        缺点 ：乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。\n\n在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。\n\n### 3、步骤 : \n\n```java\n\t// 1.查询出商品信息\n\tselect (status,status,version) from t_goods where id=#{id}\n\t// 2.根据商品信息生成订单\n\t// 3.修改商品\n\tupdate t_goods\n\tset status=2,version=version+1 where id=#{id} and versio{139}};\n```\n\n","slug":"悲观锁、乐观锁","published":1,"updated":"2019-10-15T12:17:44.237Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1u002jvguqkb7rr2a3","content":"<h2>1、悲观锁</h2>\n<p>假设会发生并发冲突，屏蔽一切可能违反数据完整性的操作（具有强烈的独占和排他性）</p>\n<p>​           依赖数据库的锁机制实现，以保证操作最大程度的独占性。</p>\n<p>​     百度百科：正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。</p>\n<h2>2、缺点</h2>\n<p>数据库性能的大量开销，特别是对长事务而言，这样的开销无法承受</p>\n<h2>3、实现方法</h2>\n<p>​    <strong>Mysql中 :</strong></p>\n<p>​    在sql后面加上 for update或者for update nowait</p>\n<p>​    for update和for update nowait区别：</p>\n<p>​         1. for update 锁定当前操作数据，其他事务等待</p>\n<p>​         2. for update nowait 锁定当前数据，其他事务发现数据被锁定，立即返回&quot;ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源&quot;</p>\n<p>​         例如：select * from account where name=&quot;123&quot; for update</p>\n<p>​         优点：无论是在单机还是分布式中，只要使用的是同一个数据库，那么悲观锁就能起到作用。</p>\n<p>​         缺点：锁定数据后，必将影响其他操作，在大流量的情况下，操作速度变慢</p>\n<p>​    <strong>JAVA中 ：</strong></p>\n<p>​        独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。</p>\n<h2>4、使用场景举例</h2>\n<p>以MySQL InnoDB为例</p>\n<p>Demo：</p>\n<p>​</p>\n<pre><code class=\"language-java\">   begin;\n\n        select amount from item where item_id = 1 for update;\n\n // 通过amount来做出一些行为,例如告诉用户库存不足,购买失败,然后只有amount &gt; 1才进入更新库存操作\n\n        update item set amount = amount - 1 where item_id = 1;\n\n        commit;\n</code></pre>\n<p>​    由于是串行执行,其他事务的for update必须等该当前事务的 for update 语句执行,所以我们不必担心我们获得的amount被修改过,因为它永远是最新的</p>\n<h3>0、乐观锁：</h3>\n<p>不是真正的锁，而是一种实现 : 是一种实现的</p>\n<h3>1、乐观锁：</h3>\n<p>假设不会发生并发冲突，只有在提交操作时检查是否违反数据完整性，乐观锁不能解决脏读问题</p>\n<p>​            乐观锁大多都基于数据版本（version）记录机制实现，何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据表增加一个“version”字段来实现。读取出数据时，将此版本一同读出，之后更新时，对此版本后 +1。此时，将提交的版本数据与数据库表对应记录的当前版本信息对比时，如果提交的数据版本号大于数据库当前版本号，则予以更新，否则认为是过期数据。</p>\n<h3>2、优缺点：</h3>\n<p>​        优点 ：可以多个事务同时进行，然后根据返回的不同结果做相应的操作，避免了长事务中的数据库加锁开销。</p>\n<p>​        缺点 ：乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。</p>\n<p>在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。</p>\n<h3>3、步骤 :</h3>\n<pre><code class=\"language-java\">\t// 1.查询出商品信息\n\tselect (status,status,version) from t_goods where id=#{id}\n\t// 2.根据商品信息生成订单\n\t// 3.修改商品\n\tupdate t_goods\n\tset status=2,version=version+1 where id=#{id} and versio{139}};\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、悲观锁</h2>\n<p>假设会发生并发冲突，屏蔽一切可能违反数据完整性的操作（具有强烈的独占和排他性）</p>\n<p>​           依赖数据库的锁机制实现，以保证操作最大程度的独占性。</p>\n<p>​     百度百科：正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机制，也无法保证外部系统不会修改数据）。</p>\n<h2>2、缺点</h2>\n<p>数据库性能的大量开销，特别是对长事务而言，这样的开销无法承受</p>\n<h2>3、实现方法</h2>\n<p>​    <strong>Mysql中 :</strong></p>\n<p>​    在sql后面加上 for update或者for update nowait</p>\n<p>​    for update和for update nowait区别：</p>\n<p>​         1. for update 锁定当前操作数据，其他事务等待</p>\n<p>​         2. for update nowait 锁定当前数据，其他事务发现数据被锁定，立即返回&quot;ORA-00054错误，内容是资源正忙, 但指定以 NOWAIT 方式获取资源&quot;</p>\n<p>​         例如：select * from account where name=&quot;123&quot; for update</p>\n<p>​         优点：无论是在单机还是分布式中，只要使用的是同一个数据库，那么悲观锁就能起到作用。</p>\n<p>​         缺点：锁定数据后，必将影响其他操作，在大流量的情况下，操作速度变慢</p>\n<p>​    <strong>JAVA中 ：</strong></p>\n<p>​        独占锁是一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况，并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。</p>\n<h2>4、使用场景举例</h2>\n<p>以MySQL InnoDB为例</p>\n<p>Demo：</p>\n<p>​</p>\n<pre><code class=\"language-java\">   begin;\n\n        select amount from item where item_id = 1 for update;\n\n // 通过amount来做出一些行为,例如告诉用户库存不足,购买失败,然后只有amount &gt; 1才进入更新库存操作\n\n        update item set amount = amount - 1 where item_id = 1;\n\n        commit;\n</code></pre>\n<p>​    由于是串行执行,其他事务的for update必须等该当前事务的 for update 语句执行,所以我们不必担心我们获得的amount被修改过,因为它永远是最新的</p>\n<h3>0、乐观锁：</h3>\n<p>不是真正的锁，而是一种实现 : 是一种实现的</p>\n<h3>1、乐观锁：</h3>\n<p>假设不会发生并发冲突，只有在提交操作时检查是否违反数据完整性，乐观锁不能解决脏读问题</p>\n<p>​            乐观锁大多都基于数据版本（version）记录机制实现，何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据表增加一个“version”字段来实现。读取出数据时，将此版本一同读出，之后更新时，对此版本后 +1。此时，将提交的版本数据与数据库表对应记录的当前版本信息对比时，如果提交的数据版本号大于数据库当前版本号，则予以更新，否则认为是过期数据。</p>\n<h3>2、优缺点：</h3>\n<p>​        优点 ：可以多个事务同时进行，然后根据返回的不同结果做相应的操作，避免了长事务中的数据库加锁开销。</p>\n<p>​        缺点 ：乐观锁机制往往基于系统中的数据存储逻辑，因此也具备一定的局限性，如在上例中，由于乐观锁机制是在我们的系统中实现，来自外部系统的用户余额更新操作不受我们系统的控制，因此可能会造成脏数据被更新到数据库中。</p>\n<p>在系统设计阶段，我们应该充分考虑到这些情况出现的可能性，并进行相应调整（如将乐观锁策略在数据库存储过程中实过程中实现，对外只开放基于此存储过程的数据更新途径，而不是将数据库表直接对外公开）。</p>\n<h3>3、步骤 :</h3>\n<pre><code class=\"language-java\">\t// 1.查询出商品信息\n\tselect (status,status,version) from t_goods where id=#{id}\n\t// 2.根据商品信息生成订单\n\t// 3.修改商品\n\tupdate t_goods\n\tset status=2,version=version+1 where id=#{id} and versio{139}};\n</code></pre>\n"},{"title":"理解IO阻塞与非阻塞","author":"郑天祺","date":"2019-08-30T09:34:00.000Z","_content":"\n## 1、饭店吃饭的例子\n\nA君喜欢下馆子吃饭，服务员点完餐后，A君一直坐在座位上等待厨师炒菜，什么事情也没有干，过了一会服务员端上饭菜后，A君就开吃了 -- 【阻塞I/O】\n\nB君也喜欢下馆子，服务员点完餐后，B君看这个服务员长得不错便前去搭讪，一直和服务员聊人生理想，并时不时的打听自己的饭做好了没有，过了一会饭也做好了，B君也撩到了美女服务员的微信号 -- 【非阻塞I/O 】  \n\n## 2、阻塞与非阻塞调用对比\n\n![](/img/阻塞与非阻塞调用对比.png)\n\n## 3、阻塞IO\n\n![](/img/阻塞IO.png)\n\n## 4、非阻塞IO\n\n![](/img/非阻塞IO.png)\n\n## 5、I/O复用模型\n\n​\t前面讲的非阻塞仍然需要进程不断的轮询重试。能不能实现当数据可读了以后给程序一个通知呢？所以这里引入了一个IO多路复用模型，I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。\n\n​\t常见的IO多路复用方式有【select、poll、epoll】，都是Linux  API提供的IO复用方式\n\n## 6、I/O复用select模型\n\n![](/img/IO复用select模型.png)\n\n## 7、select、epoll模型对比\n\n![](/img/select、epoll模型对比.png)\n\n这个模式有二个缺点\n1. 由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。\n2. 同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少。\n\n## 8、多路复用的好处\n\nI/O多路复用可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销","source":"_posts/理解IO阻塞与非阻塞.md","raw":"title: 理解IO阻塞与非阻塞\nauthor: 郑天祺\ntags:\n  - IO\n  - 阻塞与非阻塞\ncategories:\n  - 网络\ndate: 2019-08-30 17:34:00\n\n---\n\n## 1、饭店吃饭的例子\n\nA君喜欢下馆子吃饭，服务员点完餐后，A君一直坐在座位上等待厨师炒菜，什么事情也没有干，过了一会服务员端上饭菜后，A君就开吃了 -- 【阻塞I/O】\n\nB君也喜欢下馆子，服务员点完餐后，B君看这个服务员长得不错便前去搭讪，一直和服务员聊人生理想，并时不时的打听自己的饭做好了没有，过了一会饭也做好了，B君也撩到了美女服务员的微信号 -- 【非阻塞I/O 】  \n\n## 2、阻塞与非阻塞调用对比\n\n![](/img/阻塞与非阻塞调用对比.png)\n\n## 3、阻塞IO\n\n![](/img/阻塞IO.png)\n\n## 4、非阻塞IO\n\n![](/img/非阻塞IO.png)\n\n## 5、I/O复用模型\n\n​\t前面讲的非阻塞仍然需要进程不断的轮询重试。能不能实现当数据可读了以后给程序一个通知呢？所以这里引入了一个IO多路复用模型，I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。\n\n​\t常见的IO多路复用方式有【select、poll、epoll】，都是Linux  API提供的IO复用方式\n\n## 6、I/O复用select模型\n\n![](/img/IO复用select模型.png)\n\n## 7、select、epoll模型对比\n\n![](/img/select、epoll模型对比.png)\n\n这个模式有二个缺点\n1. 由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。\n2. 同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少。\n\n## 8、多路复用的好处\n\nI/O多路复用可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销","slug":"理解IO阻塞与非阻塞","published":1,"updated":"2019-08-30T10:01:49.767Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1w002mvguqgtvl7qwy","content":"<h2>1、饭店吃饭的例子</h2>\n<p>A君喜欢下馆子吃饭，服务员点完餐后，A君一直坐在座位上等待厨师炒菜，什么事情也没有干，过了一会服务员端上饭菜后，A君就开吃了 -- 【阻塞I/O】</p>\n<p>B君也喜欢下馆子，服务员点完餐后，B君看这个服务员长得不错便前去搭讪，一直和服务员聊人生理想，并时不时的打听自己的饭做好了没有，过了一会饭也做好了，B君也撩到了美女服务员的微信号 -- 【非阻塞I/O 】</p>\n<h2>2、阻塞与非阻塞调用对比</h2>\n<p><img src=\"/img/%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%E8%B0%83%E7%94%A8%E5%AF%B9%E6%AF%94.png\" alt></p>\n<h2>3、阻塞IO</h2>\n<p><img src=\"/img/%E9%98%BB%E5%A1%9EIO.png\" alt></p>\n<h2>4、非阻塞IO</h2>\n<p><img src=\"/img/%E9%9D%9E%E9%98%BB%E5%A1%9EIO.png\" alt></p>\n<h2>5、I/O复用模型</h2>\n<p>​\t前面讲的非阻塞仍然需要进程不断的轮询重试。能不能实现当数据可读了以后给程序一个通知呢？所以这里引入了一个IO多路复用模型，I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。</p>\n<p>​\t常见的IO多路复用方式有【select、poll、epoll】，都是Linux  API提供的IO复用方式</p>\n<h2>6、I/O复用select模型</h2>\n<p><img src=\"/img/IO%E5%A4%8D%E7%94%A8select%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2>7、select、epoll模型对比</h2>\n<p><img src=\"/img/select%E3%80%81epoll%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.png\" alt></p>\n<p>这个模式有二个缺点</p>\n<ol>\n<li>由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。</li>\n<li>同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少。</li>\n</ol>\n<h2>8、多路复用的好处</h2>\n<p>I/O多路复用可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、饭店吃饭的例子</h2>\n<p>A君喜欢下馆子吃饭，服务员点完餐后，A君一直坐在座位上等待厨师炒菜，什么事情也没有干，过了一会服务员端上饭菜后，A君就开吃了 -- 【阻塞I/O】</p>\n<p>B君也喜欢下馆子，服务员点完餐后，B君看这个服务员长得不错便前去搭讪，一直和服务员聊人生理想，并时不时的打听自己的饭做好了没有，过了一会饭也做好了，B君也撩到了美女服务员的微信号 -- 【非阻塞I/O 】</p>\n<h2>2、阻塞与非阻塞调用对比</h2>\n<p><img src=\"/img/%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E%E8%B0%83%E7%94%A8%E5%AF%B9%E6%AF%94.png\" alt></p>\n<h2>3、阻塞IO</h2>\n<p><img src=\"/img/%E9%98%BB%E5%A1%9EIO.png\" alt></p>\n<h2>4、非阻塞IO</h2>\n<p><img src=\"/img/%E9%9D%9E%E9%98%BB%E5%A1%9EIO.png\" alt></p>\n<h2>5、I/O复用模型</h2>\n<p>​\t前面讲的非阻塞仍然需要进程不断的轮询重试。能不能实现当数据可读了以后给程序一个通知呢？所以这里引入了一个IO多路复用模型，I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作。</p>\n<p>​\t常见的IO多路复用方式有【select、poll、epoll】，都是Linux  API提供的IO复用方式</p>\n<h2>6、I/O复用select模型</h2>\n<p><img src=\"/img/IO%E5%A4%8D%E7%94%A8select%E6%A8%A1%E5%9E%8B.png\" alt></p>\n<h2>7、select、epoll模型对比</h2>\n<p><img src=\"/img/select%E3%80%81epoll%E6%A8%A1%E5%9E%8B%E5%AF%B9%E6%AF%94.png\" alt></p>\n<p>这个模式有二个缺点</p>\n<ol>\n<li>由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。</li>\n<li>同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少。</li>\n</ol>\n<h2>8、多路复用的好处</h2>\n<p>I/O多路复用可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销</p>\n"},{"title":"数字签名","author":"郑天祺","date":"2019-09-01T12:23:00.000Z","_content":"# 一、数字签名概念\n\n​\t数字签名技术是消息传递进行加密获得的签名。如HTTP请求时将请求体加密。数字签名可以用于证实数字内容的完整性和来源。常见的数字签名算法：**椭圆曲线数字签名算法**。。。\n\n# 二、数字签名的流程\n\n## （1）椭圆曲线数字签名算法:\n\n### 生成数字签名\n\n```java\n获取消息m的数字摘要Hm 即 Hm = h(m);;\n使用RFC6979协议，通过私钥pk和m生成确定随机数k;\n计算R = k * G，其中R为曲线上的一点，取其横坐标r作为数字签名的一部分，然后计算s，即s = (Hm + r * pk) / k;\n得到消息m的数字签名为Sig = <r, s>\n```\n\n### 验证数字签名\n\n```java\n根据Sig，使用对应的公钥P验证其签名;\n判断等式s * R = Hm * G + r * P是否成立，成立则通过验证\n```\n\n### 验证方法解释\n\n```java\n由椭圆公式：r 得到 R ;\n因为：s = (Hm + r * pk) / k 得到 s * k = (Hm + r * pk);\n又因为：P = pk * G;\n所以：s * (k * G) = Hm * G + r * (pk * G) ;\n推出 s * R = Hm * G + r * P\n```\n\n### 原理解释：\n\nhttps://www.cnblogs.com/wsonepiece/p/3977021.html\n\n## （2）Schnorr数字签名算法\n\n### 生成数字签名\n\n```java\n计算消息m的数字摘要: Hm = H(m)\n生成确定性随机数k，计算 R = k * G , 取R的横坐标 r 作为签名的一部分\n计算签名另一部分：s = k + h(P || R || m) * pk\n得到数字签名 Sig = <r , s>\n```\n\n### 验证数字签名\n\n```java\n利用公钥P验证其签名\ns * G = R + h(P || R || m) * P 是否成立，成立则通过验证\n多个签名：\n(s1 + .. + S50) * G = R1 + .. + R50 + h1 * P1 + .. h50 * P50\n```\n\n### 验证方法解释\n\n```java\n因为：s = k + h(P || R || m) * pk ;\n又因为：P = pk * G ;\n所以：s * G = k * G + h(P || R || m) * (pk * G) \n所以：s * G = R + h * (P || R || m) * P\n由r 得到 R\n```","source":"_posts/数字签名.md","raw":"title: 数字签名\nauthor: 郑天祺\ntags:\n  - 可信\n  - 加密算法\ncategories:\n  - 可信\ndate: 2019-09-01 20:23:00\n---\n# 一、数字签名概念\n\n​\t数字签名技术是消息传递进行加密获得的签名。如HTTP请求时将请求体加密。数字签名可以用于证实数字内容的完整性和来源。常见的数字签名算法：**椭圆曲线数字签名算法**。。。\n\n# 二、数字签名的流程\n\n## （1）椭圆曲线数字签名算法:\n\n### 生成数字签名\n\n```java\n获取消息m的数字摘要Hm 即 Hm = h(m);;\n使用RFC6979协议，通过私钥pk和m生成确定随机数k;\n计算R = k * G，其中R为曲线上的一点，取其横坐标r作为数字签名的一部分，然后计算s，即s = (Hm + r * pk) / k;\n得到消息m的数字签名为Sig = <r, s>\n```\n\n### 验证数字签名\n\n```java\n根据Sig，使用对应的公钥P验证其签名;\n判断等式s * R = Hm * G + r * P是否成立，成立则通过验证\n```\n\n### 验证方法解释\n\n```java\n由椭圆公式：r 得到 R ;\n因为：s = (Hm + r * pk) / k 得到 s * k = (Hm + r * pk);\n又因为：P = pk * G;\n所以：s * (k * G) = Hm * G + r * (pk * G) ;\n推出 s * R = Hm * G + r * P\n```\n\n### 原理解释：\n\nhttps://www.cnblogs.com/wsonepiece/p/3977021.html\n\n## （2）Schnorr数字签名算法\n\n### 生成数字签名\n\n```java\n计算消息m的数字摘要: Hm = H(m)\n生成确定性随机数k，计算 R = k * G , 取R的横坐标 r 作为签名的一部分\n计算签名另一部分：s = k + h(P || R || m) * pk\n得到数字签名 Sig = <r , s>\n```\n\n### 验证数字签名\n\n```java\n利用公钥P验证其签名\ns * G = R + h(P || R || m) * P 是否成立，成立则通过验证\n多个签名：\n(s1 + .. + S50) * G = R1 + .. + R50 + h1 * P1 + .. h50 * P50\n```\n\n### 验证方法解释\n\n```java\n因为：s = k + h(P || R || m) * pk ;\n又因为：P = pk * G ;\n所以：s * G = k * G + h(P || R || m) * (pk * G) \n所以：s * G = R + h * (P || R || m) * P\n由r 得到 R\n```","slug":"数字签名","published":1,"updated":"2019-10-15T12:28:53.710Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm1y002pvguq541al7bv","content":"<h1>一、数字签名概念</h1>\n<p>​\t数字签名技术是消息传递进行加密获得的签名。如HTTP请求时将请求体加密。数字签名可以用于证实数字内容的完整性和来源。常见的数字签名算法：<strong>椭圆曲线数字签名算法</strong>。。。</p>\n<h1>二、数字签名的流程</h1>\n<h2>（1）椭圆曲线数字签名算法:</h2>\n<h3>生成数字签名</h3>\n<pre><code class=\"language-java\">获取消息m的数字摘要Hm 即 Hm = h(m);;\n使用RFC6979协议，通过私钥pk和m生成确定随机数k;\n计算R = k * G，其中R为曲线上的一点，取其横坐标r作为数字签名的一部分，然后计算s，即s = (Hm + r * pk) / k;\n得到消息m的数字签名为Sig = &lt;r, s&gt;\n</code></pre>\n<h3>验证数字签名</h3>\n<pre><code class=\"language-java\">根据Sig，使用对应的公钥P验证其签名;\n判断等式s * R = Hm * G + r * P是否成立，成立则通过验证\n</code></pre>\n<h3>验证方法解释</h3>\n<pre><code class=\"language-java\">由椭圆公式：r 得到 R ;\n因为：s = (Hm + r * pk) / k 得到 s * k = (Hm + r * pk);\n又因为：P = pk * G;\n所以：s * (k * G) = Hm * G + r * (pk * G) ;\n推出 s * R = Hm * G + r * P\n</code></pre>\n<h3>原理解释：</h3>\n<p>https://www.cnblogs.com/wsonepiece/p/3977021.html</p>\n<h2>（2）Schnorr数字签名算法</h2>\n<h3>生成数字签名</h3>\n<pre><code class=\"language-java\">计算消息m的数字摘要: Hm = H(m)\n生成确定性随机数k，计算 R = k * G , 取R的横坐标 r 作为签名的一部分\n计算签名另一部分：s = k + h(P || R || m) * pk\n得到数字签名 Sig = &lt;r , s&gt;\n</code></pre>\n<h3>验证数字签名</h3>\n<pre><code class=\"language-java\">利用公钥P验证其签名\ns * G = R + h(P || R || m) * P 是否成立，成立则通过验证\n多个签名：\n(s1 + .. + S50) * G = R1 + .. + R50 + h1 * P1 + .. h50 * P50\n</code></pre>\n<h3>验证方法解释</h3>\n<pre><code class=\"language-java\">因为：s = k + h(P || R || m) * pk ;\n又因为：P = pk * G ;\n所以：s * G = k * G + h(P || R || m) * (pk * G) \n所以：s * G = R + h * (P || R || m) * P\n由r 得到 R\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、数字签名概念</h1>\n<p>​\t数字签名技术是消息传递进行加密获得的签名。如HTTP请求时将请求体加密。数字签名可以用于证实数字内容的完整性和来源。常见的数字签名算法：<strong>椭圆曲线数字签名算法</strong>。。。</p>\n<h1>二、数字签名的流程</h1>\n<h2>（1）椭圆曲线数字签名算法:</h2>\n<h3>生成数字签名</h3>\n<pre><code class=\"language-java\">获取消息m的数字摘要Hm 即 Hm = h(m);;\n使用RFC6979协议，通过私钥pk和m生成确定随机数k;\n计算R = k * G，其中R为曲线上的一点，取其横坐标r作为数字签名的一部分，然后计算s，即s = (Hm + r * pk) / k;\n得到消息m的数字签名为Sig = &lt;r, s&gt;\n</code></pre>\n<h3>验证数字签名</h3>\n<pre><code class=\"language-java\">根据Sig，使用对应的公钥P验证其签名;\n判断等式s * R = Hm * G + r * P是否成立，成立则通过验证\n</code></pre>\n<h3>验证方法解释</h3>\n<pre><code class=\"language-java\">由椭圆公式：r 得到 R ;\n因为：s = (Hm + r * pk) / k 得到 s * k = (Hm + r * pk);\n又因为：P = pk * G;\n所以：s * (k * G) = Hm * G + r * (pk * G) ;\n推出 s * R = Hm * G + r * P\n</code></pre>\n<h3>原理解释：</h3>\n<p>https://www.cnblogs.com/wsonepiece/p/3977021.html</p>\n<h2>（2）Schnorr数字签名算法</h2>\n<h3>生成数字签名</h3>\n<pre><code class=\"language-java\">计算消息m的数字摘要: Hm = H(m)\n生成确定性随机数k，计算 R = k * G , 取R的横坐标 r 作为签名的一部分\n计算签名另一部分：s = k + h(P || R || m) * pk\n得到数字签名 Sig = &lt;r , s&gt;\n</code></pre>\n<h3>验证数字签名</h3>\n<pre><code class=\"language-java\">利用公钥P验证其签名\ns * G = R + h(P || R || m) * P 是否成立，成立则通过验证\n多个签名：\n(s1 + .. + S50) * G = R1 + .. + R50 + h1 * P1 + .. h50 * P50\n</code></pre>\n<h3>验证方法解释</h3>\n<pre><code class=\"language-java\">因为：s = k + h(P || R || m) * pk ;\n又因为：P = pk * G ;\n所以：s * G = k * G + h(P || R || m) * (pk * G) \n所以：s * G = R + h * (P || R || m) * P\n由r 得到 R\n</code></pre>\n"},{"title":"自旋锁","author":"郑天祺","date":"2019-08-31T04:54:00.000Z","_content":"\n# 自旋锁\n\n## 1、自旋锁概念（spinlock）\n\n是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。\n\n获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成busy-waiting。\n\n## 2、自旋锁的优点 :\n\n自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）\n\n## 3、自旋锁应用 :\n\n由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。\n\n如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。\n\n \n\n## 4、简单自旋锁的实现 ：\n\n```java\npublic class SimpleSpinLock {\n     /**\n      * 持有锁的线程，null表示锁未被线程持有\n      */\n     private static AtomicReference<Thread> ref = new AtomicReference<>();\n\npublic void Lock() {\n         Thread currentThread = Thread.currentThread();\n         // 当ref为null的时候compareAndSet返回true，反之为false\n         // 通过循环不断的自旋判断锁是否被其他线程持有\n         while (!ref.compareAndSet(null, currentThread)) {\n         }\n     }\n\n   public void unLock() {\n        Thread currentThread = Thread.currentThread();\n         if (ref.get() != currentThread) {\n         }\n         ref.set(null);\n     }\n }\n\ntest：\n\npublic class SimpleSpinLockTest {\n\n    private static int n = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(100, 100, 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(), new DefaultNameThreadFactory(\"SimpleSpinLock\"));\n         CountDownLatch countDownLatch = new CountDownLatch(100);\n         SimpleSpinLock simpleSpinLock = new SimpleSpinLock();\n         for (int i = 0; i < 100; i++) {\n             pool.submit(() -> {\n                 simpleSpinLock.Lock();\n                 n++;\n                 simpleSpinLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(n);\n     }\n }\n```\n\n \n\n## 5、可重入的自旋锁和不可重入的自旋锁 ：\n\n仔细分析一下上述就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。\n\n由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数----》其他章节可重入锁\n\n## 6、  另有三种常见的形式 :\n\nTicketLock ，CLHlock 和 MCSlock：https://www.cnblogs.com/stevenczp/p/7136416.html\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n  \n\n \n\n ","source":"_posts/自旋锁.md","raw":"title: 自旋锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 12:54:00\n\n---\n\n# 自旋锁\n\n## 1、自旋锁概念（spinlock）\n\n是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。\n\n获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成busy-waiting。\n\n## 2、自旋锁的优点 :\n\n自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）\n\n## 3、自旋锁应用 :\n\n由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。\n\n如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。\n\n \n\n## 4、简单自旋锁的实现 ：\n\n```java\npublic class SimpleSpinLock {\n     /**\n      * 持有锁的线程，null表示锁未被线程持有\n      */\n     private static AtomicReference<Thread> ref = new AtomicReference<>();\n\npublic void Lock() {\n         Thread currentThread = Thread.currentThread();\n         // 当ref为null的时候compareAndSet返回true，反之为false\n         // 通过循环不断的自旋判断锁是否被其他线程持有\n         while (!ref.compareAndSet(null, currentThread)) {\n         }\n     }\n\n   public void unLock() {\n        Thread currentThread = Thread.currentThread();\n         if (ref.get() != currentThread) {\n         }\n         ref.set(null);\n     }\n }\n\ntest：\n\npublic class SimpleSpinLockTest {\n\n    private static int n = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(100, 100, 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(), new DefaultNameThreadFactory(\"SimpleSpinLock\"));\n         CountDownLatch countDownLatch = new CountDownLatch(100);\n         SimpleSpinLock simpleSpinLock = new SimpleSpinLock();\n         for (int i = 0; i < 100; i++) {\n             pool.submit(() -> {\n                 simpleSpinLock.Lock();\n                 n++;\n                 simpleSpinLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(n);\n     }\n }\n```\n\n \n\n## 5、可重入的自旋锁和不可重入的自旋锁 ：\n\n仔细分析一下上述就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。\n\n由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数----》其他章节可重入锁\n\n## 6、  另有三种常见的形式 :\n\nTicketLock ，CLHlock 和 MCSlock：https://www.cnblogs.com/stevenczp/p/7136416.html\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n  \n\n \n\n ","slug":"自旋锁","published":1,"updated":"2019-08-31T04:59:21.273Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm20002tvguqtqtlmtiv","content":"<h1>自旋锁</h1>\n<h2>1、自旋锁概念（spinlock）</h2>\n<p>是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。</p>\n<p>获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成busy-waiting。</p>\n<h2>2、自旋锁的优点 :</h2>\n<p>自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）</p>\n<h2>3、自旋锁应用 :</h2>\n<p>由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。</p>\n<p>如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。</p>\n<h2>4、简单自旋锁的实现 ：</h2>\n<pre><code class=\"language-java\">public class SimpleSpinLock {\n     /**\n      * 持有锁的线程，null表示锁未被线程持有\n      */\n     private static AtomicReference&lt;Thread&gt; ref = new AtomicReference&lt;&gt;();\n\npublic void Lock() {\n         Thread currentThread = Thread.currentThread();\n         // 当ref为null的时候compareAndSet返回true，反之为false\n         // 通过循环不断的自旋判断锁是否被其他线程持有\n         while (!ref.compareAndSet(null, currentThread)) {\n         }\n     }\n\n   public void unLock() {\n        Thread currentThread = Thread.currentThread();\n         if (ref.get() != currentThread) {\n         }\n         ref.set(null);\n     }\n }\n\ntest：\n\npublic class SimpleSpinLockTest {\n\n    private static int n = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(100, 100, 1, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new DefaultNameThreadFactory(&quot;SimpleSpinLock&quot;));\n         CountDownLatch countDownLatch = new CountDownLatch(100);\n         SimpleSpinLock simpleSpinLock = new SimpleSpinLock();\n         for (int i = 0; i &lt; 100; i++) {\n             pool.submit(() -&gt; {\n                 simpleSpinLock.Lock();\n                 n++;\n                 simpleSpinLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(n);\n     }\n }\n</code></pre>\n<h2>5、可重入的自旋锁和不可重入的自旋锁 ：</h2>\n<p>仔细分析一下上述就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。</p>\n<p>由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数----》其他章节可重入锁</p>\n<h2>6、  另有三种常见的形式 :</h2>\n<p>TicketLock ，CLHlock 和 MCSlock：https://www.cnblogs.com/stevenczp/p/7136416.html</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>自旋锁</h1>\n<h2>1、自旋锁概念（spinlock）</h2>\n<p>是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。</p>\n<p>获取锁的线程一直处于活跃状态，但是并没有执行任何有效的任务，使用这种锁会造成busy-waiting。</p>\n<h2>2、自旋锁的优点 :</h2>\n<p>自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能）</p>\n<h2>3、自旋锁应用 :</h2>\n<p>由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行，占用CPU时间。</p>\n<p>如果线程竞争不激烈，并且保持锁的时间段。适合使用自旋锁。</p>\n<h2>4、简单自旋锁的实现 ：</h2>\n<pre><code class=\"language-java\">public class SimpleSpinLock {\n     /**\n      * 持有锁的线程，null表示锁未被线程持有\n      */\n     private static AtomicReference&lt;Thread&gt; ref = new AtomicReference&lt;&gt;();\n\npublic void Lock() {\n         Thread currentThread = Thread.currentThread();\n         // 当ref为null的时候compareAndSet返回true，反之为false\n         // 通过循环不断的自旋判断锁是否被其他线程持有\n         while (!ref.compareAndSet(null, currentThread)) {\n         }\n     }\n\n   public void unLock() {\n        Thread currentThread = Thread.currentThread();\n         if (ref.get() != currentThread) {\n         }\n         ref.set(null);\n     }\n }\n\ntest：\n\npublic class SimpleSpinLockTest {\n\n    private static int n = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(100, 100, 1, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new DefaultNameThreadFactory(&quot;SimpleSpinLock&quot;));\n         CountDownLatch countDownLatch = new CountDownLatch(100);\n         SimpleSpinLock simpleSpinLock = new SimpleSpinLock();\n         for (int i = 0; i &lt; 100; i++) {\n             pool.submit(() -&gt; {\n                 simpleSpinLock.Lock();\n                 n++;\n                 simpleSpinLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(n);\n     }\n }\n</code></pre>\n<h2>5、可重入的自旋锁和不可重入的自旋锁 ：</h2>\n<p>仔细分析一下上述就可以看出，它是不支持重入的，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新获取该锁，第二次就不能成功获取到。</p>\n<p>由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数----》其他章节可重入锁</p>\n<h2>6、  另有三种常见的形式 :</h2>\n<p>TicketLock ，CLHlock 和 MCSlock：https://www.cnblogs.com/stevenczp/p/7136416.html</p>\n"},{"title":"读写锁","author":"郑天祺","date":"2019-08-31T05:08:00.000Z","_content":"\n# 4、读写锁\n\n## 1、读写锁介绍：\n\n​        ReadWriteLock同Lock一样也是一个接口，提供了readLock和writeLock两种锁的操作机制，一个是只读的锁，一个是写锁。 \n\n​        理论上，读写锁比互斥锁允许对于共享数据更大程度的并发。与互斥锁相比，读写锁是否能够提高性能取决于读写数据的频率、读取和写入操作的持续时间、以及读线程和写线程之间的竞争。 \n\n​        一些业务场景中，大部分 只是读数据，写数据很少，如果仅仅是读数据的话并不会影响数据正确性（出现脏读），而如果在这种业务场景下，依然使用独占锁的话，很显然这将是出现性能瓶颈的地方。 针对这种读多写少的情况，java还提供了另外一个实现Lock接口的ReentrantReadWriteLock(读写锁)。读写所允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。\n\n​    \n\n​        读-读能共存，\n​         读-写不能共存，\n​         写-写不能共存。 \n\n连接：https://blog.csdn.net/j080624/article/details/82790372、https://ifeve.com/read-write-locks/\n\n \n\n## 2、总结：\n\n1. **公平性选择**：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平；\n2. **重入性**：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁；\n3. **锁降级**：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁\n\n## 3、写锁的获取：\n\n​        写锁是独占式锁，而实现写锁的同步语义是通过重写 AQS 中的 tryAcquire() 方法实现的，源码：\n\n```java\nprotected final boolean tryAcquire(int acquires) {\n     Thread current = Thread.currentThread();\n     // 1. 获取 写锁 当前的同步状态\n     int c = getState();\n     // 2. 获取 写锁 获取的次数\n     int w = exclusiveCount(c);\n     if (c != 0) {\n         // (Note: if c != 0 and w == 0 then shared count != 0)\n         // 3.1 当 读锁 已被读线程获取 或者 当前线程不是已经获取 写锁 的线程的话\n         // 当前线程获取 写锁失败\n         if (w == 0 || current != getExclusiveOwnerThread())\n             return false;\n         if (w + exclusiveCount(acquires) > MAX_COUNT)\n             throw new Error(\"Maximum lock count exceeded\");\n         // Reentrant acquire\n         // 3.2 当前线程 获取写锁，支持可重复加锁\n         setState(c + acquires);\n         return true;\n     }\n     // 3.3 写锁 未被任何线程获取，当前线程可获取 写锁\n     if (writerShouldBlock() ||!compareAndSetState(c, c + acquires))\n         return false;\n     setExclusiveOwnerThread(current);\n     return true;\n }\n\n \n\n static int exclusiveCount(int c) { \n\n        return c & EXCLUSIVE_MASK;\n\n }\n```\n\n其中EXCLUSIVE_MASK为:  static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;      EXCLUSIVE _MASK为1左移16位然后减1，即为0x0000FFFF。\n\n而exclusiveCount方法是将同步状态（state为int类型）与0x0000FFFF相与，即取同步状态的低16位。那么低16位代表什么呢？\n\n根据exclusiveCount方法的注释为独占式获取的次数即写锁被获取的次数，现在就可以得出来一个结论同步状态的低16位用来表示写锁的获取次数\n\n```java\nstatic int sharedCount(int c)    { \n\n        return c >>> SHARED_SHIFT; \n\n}\n```\n\n该方法是获取读锁被获取的次数，是将同步状态（int c）右移16次，即取同步状态的高16位，现在我们可以得出另外一个结论同步状态的高16位用来表示读锁被获取的次数。\n\n![img](/img/读写锁.png)\n\n当读锁已经被读线程获取或者写锁已经被其他写线程获取，则写锁获取失败；否则，获取成功并支持重入，增加写状态。\n\n \n\n \n\n## 4、写锁的释放：\n\n​    写锁释放通过重写AQS的tryRelease方法，源码为：\n\n```java\nprotected final boolean tryRelease(int releases) {\n     if (!isHeldExclusively())\n         throw new IllegalMonitorStateException();\n     //1. 同步状态减去写状态\n     int nextc = getState() - releases;\n     //2. 当前写状态是否为0，为0则释放写锁\n     boolean free = exclusiveCount(nextc) == 0;\n     if (free)\n         setExclusiveOwnerThread(null);\n     //3. 不为0则更新同步状态\n     setState(nextc);\n     return free;\n }\n```\n\n​    减少写状态int nextc = getState() - releases，只需要用当前同步状态直接减去写状态的原因：写状态是由同步状态的低16位表示的。\n\n \n\n## 5、读锁的获取\n\n​        读锁不是独占式锁，即同一时刻该锁可以被多个读线程获取也就是一种共享式锁。\n\n```java\nprotected final int tryAcquireShared(int unused) {\n     Thread current = Thread.currentThread();\n     int c = getState();\n     //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前\n     // 线程获取读锁失败返回-1\n     if (exclusiveCount(c) != 0 &&\n         getExclusiveOwnerThread() != current)\n         return -1;\n     int r = sharedCount(c);\n     if (!readerShouldBlock() &&\n         r < MAX_COUNT &&\n         //2. 当前线程获取读锁\n         compareAndSetState(c, c + SHARED_UNIT)) {\n         //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法\n         //返回当前获取读锁的次数\n         if (r == 0) {\n             firstReader = current;\n             firstReaderHoldCount = 1;\n         } else if (firstReader == current) {\n             firstReaderHoldCount++;\n         } else {\n             HoldCounter rh = cachedHoldCounter;\n             if (rh == null || rh.tid != getThreadId(current))\n                 cachedHoldCounter = rh = readHolds.get();\n             else if (rh.count == 0)\n                 readHolds.set(rh);\n             rh.count++;\n         }\n         return 1;\n     }\n     //4. 处理在第二步中CAS操作失败的自旋已经实现重入性\n     return fullTryAcquireShared(current);\n }\n```\n\n​    当写锁被其他线程获取后，读锁获取失败，否则获取成功利用CAS更新同步状态。\n\n## 6、读锁的释放\n\n```java\nprotected final boolean tryReleaseShared(int unused) {\n     Thread current = Thread.currentThread();\n     // 前面还是为了实现getReadHoldCount等新功能\n     if (firstReader == current) {\n         // assert firstReaderHoldCount > 0;\n         if (firstReaderHoldCount == 1)\n             firstReader = null;\n         else\n             firstReaderHoldCount--;\n     } else {\n         HoldCounter rh = cachedHoldCounter;\n         if (rh == null || rh.tid != getThreadId(current))\n             rh = readHolds.get();\n         int count = rh.count;\n         if (count <= 1) {\n             readHolds.remove();\n             if (count <= 0)\n                 throw unmatchedUnlockException();\n         }\n         --rh.count;\n     }     for (;;) {\n         int c = getState();\n         // 读锁释放 将同步状态减去读状态即可\n         int nextc = c - SHARED_UNIT;\n         if (compareAndSetState(c, nextc))\n             // Releasing the read lock has no effect on readers,\n             // but it may allow waiting writers to proceed if\n             // both read and write locks are now free.\n             return nextc == 0;\n     }\n }\n```\n\n\n\n##  7、锁降级\n\n​        读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中：\n\n```java\nvoid processCachedData() {\n         rwl.readLock().lock();\n         if (!cacheValid) {\n             // Must release read lock before acquiring write lock\n             rwl.readLock().unlock();\n             rwl.writeLock().lock();\n             try {\n                 // Recheck state because another thread might have\n                 // acquired write lock and changed state before we did.\n                 if (!cacheValid) {\n                     data = ...\n             cacheValid = true;\n           }\n           // Downgrade by acquiring read lock before releasing write lock\n           rwl.readLock().lock();\n         } finally {\n           rwl.writeLock().unlock(); // Unlock write, still hold read\n         }\n       }\n       try {\n         use(data);\n       } finally {\n         rwl.readLock().unlock();\n       }\n     }\n }\n```\n\n ","source":"_posts/读写锁.md","raw":"title: 读写锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:08:00\n\n---\n\n# 4、读写锁\n\n## 1、读写锁介绍：\n\n​        ReadWriteLock同Lock一样也是一个接口，提供了readLock和writeLock两种锁的操作机制，一个是只读的锁，一个是写锁。 \n\n​        理论上，读写锁比互斥锁允许对于共享数据更大程度的并发。与互斥锁相比，读写锁是否能够提高性能取决于读写数据的频率、读取和写入操作的持续时间、以及读线程和写线程之间的竞争。 \n\n​        一些业务场景中，大部分 只是读数据，写数据很少，如果仅仅是读数据的话并不会影响数据正确性（出现脏读），而如果在这种业务场景下，依然使用独占锁的话，很显然这将是出现性能瓶颈的地方。 针对这种读多写少的情况，java还提供了另外一个实现Lock接口的ReentrantReadWriteLock(读写锁)。读写所允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。\n\n​    \n\n​        读-读能共存，\n​         读-写不能共存，\n​         写-写不能共存。 \n\n连接：https://blog.csdn.net/j080624/article/details/82790372、https://ifeve.com/read-write-locks/\n\n \n\n## 2、总结：\n\n1. **公平性选择**：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平；\n2. **重入性**：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁；\n3. **锁降级**：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁\n\n## 3、写锁的获取：\n\n​        写锁是独占式锁，而实现写锁的同步语义是通过重写 AQS 中的 tryAcquire() 方法实现的，源码：\n\n```java\nprotected final boolean tryAcquire(int acquires) {\n     Thread current = Thread.currentThread();\n     // 1. 获取 写锁 当前的同步状态\n     int c = getState();\n     // 2. 获取 写锁 获取的次数\n     int w = exclusiveCount(c);\n     if (c != 0) {\n         // (Note: if c != 0 and w == 0 then shared count != 0)\n         // 3.1 当 读锁 已被读线程获取 或者 当前线程不是已经获取 写锁 的线程的话\n         // 当前线程获取 写锁失败\n         if (w == 0 || current != getExclusiveOwnerThread())\n             return false;\n         if (w + exclusiveCount(acquires) > MAX_COUNT)\n             throw new Error(\"Maximum lock count exceeded\");\n         // Reentrant acquire\n         // 3.2 当前线程 获取写锁，支持可重复加锁\n         setState(c + acquires);\n         return true;\n     }\n     // 3.3 写锁 未被任何线程获取，当前线程可获取 写锁\n     if (writerShouldBlock() ||!compareAndSetState(c, c + acquires))\n         return false;\n     setExclusiveOwnerThread(current);\n     return true;\n }\n\n \n\n static int exclusiveCount(int c) { \n\n        return c & EXCLUSIVE_MASK;\n\n }\n```\n\n其中EXCLUSIVE_MASK为:  static final int EXCLUSIVE_MASK = (1 << SHARED_SHIFT) - 1;      EXCLUSIVE _MASK为1左移16位然后减1，即为0x0000FFFF。\n\n而exclusiveCount方法是将同步状态（state为int类型）与0x0000FFFF相与，即取同步状态的低16位。那么低16位代表什么呢？\n\n根据exclusiveCount方法的注释为独占式获取的次数即写锁被获取的次数，现在就可以得出来一个结论同步状态的低16位用来表示写锁的获取次数\n\n```java\nstatic int sharedCount(int c)    { \n\n        return c >>> SHARED_SHIFT; \n\n}\n```\n\n该方法是获取读锁被获取的次数，是将同步状态（int c）右移16次，即取同步状态的高16位，现在我们可以得出另外一个结论同步状态的高16位用来表示读锁被获取的次数。\n\n![img](/img/读写锁.png)\n\n当读锁已经被读线程获取或者写锁已经被其他写线程获取，则写锁获取失败；否则，获取成功并支持重入，增加写状态。\n\n \n\n \n\n## 4、写锁的释放：\n\n​    写锁释放通过重写AQS的tryRelease方法，源码为：\n\n```java\nprotected final boolean tryRelease(int releases) {\n     if (!isHeldExclusively())\n         throw new IllegalMonitorStateException();\n     //1. 同步状态减去写状态\n     int nextc = getState() - releases;\n     //2. 当前写状态是否为0，为0则释放写锁\n     boolean free = exclusiveCount(nextc) == 0;\n     if (free)\n         setExclusiveOwnerThread(null);\n     //3. 不为0则更新同步状态\n     setState(nextc);\n     return free;\n }\n```\n\n​    减少写状态int nextc = getState() - releases，只需要用当前同步状态直接减去写状态的原因：写状态是由同步状态的低16位表示的。\n\n \n\n## 5、读锁的获取\n\n​        读锁不是独占式锁，即同一时刻该锁可以被多个读线程获取也就是一种共享式锁。\n\n```java\nprotected final int tryAcquireShared(int unused) {\n     Thread current = Thread.currentThread();\n     int c = getState();\n     //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前\n     // 线程获取读锁失败返回-1\n     if (exclusiveCount(c) != 0 &&\n         getExclusiveOwnerThread() != current)\n         return -1;\n     int r = sharedCount(c);\n     if (!readerShouldBlock() &&\n         r < MAX_COUNT &&\n         //2. 当前线程获取读锁\n         compareAndSetState(c, c + SHARED_UNIT)) {\n         //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法\n         //返回当前获取读锁的次数\n         if (r == 0) {\n             firstReader = current;\n             firstReaderHoldCount = 1;\n         } else if (firstReader == current) {\n             firstReaderHoldCount++;\n         } else {\n             HoldCounter rh = cachedHoldCounter;\n             if (rh == null || rh.tid != getThreadId(current))\n                 cachedHoldCounter = rh = readHolds.get();\n             else if (rh.count == 0)\n                 readHolds.set(rh);\n             rh.count++;\n         }\n         return 1;\n     }\n     //4. 处理在第二步中CAS操作失败的自旋已经实现重入性\n     return fullTryAcquireShared(current);\n }\n```\n\n​    当写锁被其他线程获取后，读锁获取失败，否则获取成功利用CAS更新同步状态。\n\n## 6、读锁的释放\n\n```java\nprotected final boolean tryReleaseShared(int unused) {\n     Thread current = Thread.currentThread();\n     // 前面还是为了实现getReadHoldCount等新功能\n     if (firstReader == current) {\n         // assert firstReaderHoldCount > 0;\n         if (firstReaderHoldCount == 1)\n             firstReader = null;\n         else\n             firstReaderHoldCount--;\n     } else {\n         HoldCounter rh = cachedHoldCounter;\n         if (rh == null || rh.tid != getThreadId(current))\n             rh = readHolds.get();\n         int count = rh.count;\n         if (count <= 1) {\n             readHolds.remove();\n             if (count <= 0)\n                 throw unmatchedUnlockException();\n         }\n         --rh.count;\n     }     for (;;) {\n         int c = getState();\n         // 读锁释放 将同步状态减去读状态即可\n         int nextc = c - SHARED_UNIT;\n         if (compareAndSetState(c, nextc))\n             // Releasing the read lock has no effect on readers,\n             // but it may allow waiting writers to proceed if\n             // both read and write locks are now free.\n             return nextc == 0;\n     }\n }\n```\n\n\n\n##  7、锁降级\n\n​        读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中：\n\n```java\nvoid processCachedData() {\n         rwl.readLock().lock();\n         if (!cacheValid) {\n             // Must release read lock before acquiring write lock\n             rwl.readLock().unlock();\n             rwl.writeLock().lock();\n             try {\n                 // Recheck state because another thread might have\n                 // acquired write lock and changed state before we did.\n                 if (!cacheValid) {\n                     data = ...\n             cacheValid = true;\n           }\n           // Downgrade by acquiring read lock before releasing write lock\n           rwl.readLock().lock();\n         } finally {\n           rwl.writeLock().unlock(); // Unlock write, still hold read\n         }\n       }\n       try {\n         use(data);\n       } finally {\n         rwl.readLock().unlock();\n       }\n     }\n }\n```\n\n ","slug":"读写锁","published":1,"updated":"2019-10-15T10:05:19.181Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm23002xvguqbxnjc28l","content":"<h1>4、读写锁</h1>\n<h2>1、读写锁介绍：</h2>\n<p>​        ReadWriteLock同Lock一样也是一个接口，提供了readLock和writeLock两种锁的操作机制，一个是只读的锁，一个是写锁。</p>\n<p>​        理论上，读写锁比互斥锁允许对于共享数据更大程度的并发。与互斥锁相比，读写锁是否能够提高性能取决于读写数据的频率、读取和写入操作的持续时间、以及读线程和写线程之间的竞争。</p>\n<p>​        一些业务场景中，大部分 只是读数据，写数据很少，如果仅仅是读数据的话并不会影响数据正确性（出现脏读），而如果在这种业务场景下，依然使用独占锁的话，很显然这将是出现性能瓶颈的地方。 针对这种读多写少的情况，java还提供了另外一个实现Lock接口的ReentrantReadWriteLock(读写锁)。读写所允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。</p>\n<p>​</p>\n<p>​        读-读能共存，\n​         读-写不能共存，\n​         写-写不能共存。</p>\n<p>连接：https://blog.csdn.net/j080624/article/details/82790372、https://ifeve.com/read-write-locks/</p>\n<h2>2、总结：</h2>\n<ol>\n<li><strong>公平性选择</strong>：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平；</li>\n<li><strong>重入性</strong>：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁；</li>\n<li><strong>锁降级</strong>：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁</li>\n</ol>\n<h2>3、写锁的获取：</h2>\n<p>​        写锁是独占式锁，而实现写锁的同步语义是通过重写 AQS 中的 tryAcquire() 方法实现的，源码：</p>\n<pre><code class=\"language-java\">protected final boolean tryAcquire(int acquires) {\n     Thread current = Thread.currentThread();\n     // 1. 获取 写锁 当前的同步状态\n     int c = getState();\n     // 2. 获取 写锁 获取的次数\n     int w = exclusiveCount(c);\n     if (c != 0) {\n         // (Note: if c != 0 and w == 0 then shared count != 0)\n         // 3.1 当 读锁 已被读线程获取 或者 当前线程不是已经获取 写锁 的线程的话\n         // 当前线程获取 写锁失败\n         if (w == 0 || current != getExclusiveOwnerThread())\n             return false;\n         if (w + exclusiveCount(acquires) &gt; MAX_COUNT)\n             throw new Error(&quot;Maximum lock count exceeded&quot;);\n         // Reentrant acquire\n         // 3.2 当前线程 获取写锁，支持可重复加锁\n         setState(c + acquires);\n         return true;\n     }\n     // 3.3 写锁 未被任何线程获取，当前线程可获取 写锁\n     if (writerShouldBlock() ||!compareAndSetState(c, c + acquires))\n         return false;\n     setExclusiveOwnerThread(current);\n     return true;\n }\n\n \n\n static int exclusiveCount(int c) { \n\n        return c &amp; EXCLUSIVE_MASK;\n\n }\n</code></pre>\n<p>其中EXCLUSIVE_MASK为:  static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;      EXCLUSIVE _MASK为1左移16位然后减1，即为0x0000FFFF。</p>\n<p>而exclusiveCount方法是将同步状态（state为int类型）与0x0000FFFF相与，即取同步状态的低16位。那么低16位代表什么呢？</p>\n<p>根据exclusiveCount方法的注释为独占式获取的次数即写锁被获取的次数，现在就可以得出来一个结论同步状态的低16位用来表示写锁的获取次数</p>\n<pre><code class=\"language-java\">static int sharedCount(int c)    { \n\n        return c &gt;&gt;&gt; SHARED_SHIFT; \n\n}\n</code></pre>\n<p>该方法是获取读锁被获取的次数，是将同步状态（int c）右移16次，即取同步状态的高16位，现在我们可以得出另外一个结论同步状态的高16位用来表示读锁被获取的次数。</p>\n<p><img src=\"/img/%E8%AF%BB%E5%86%99%E9%94%81.png\" alt=\"img\"></p>\n<p>当读锁已经被读线程获取或者写锁已经被其他写线程获取，则写锁获取失败；否则，获取成功并支持重入，增加写状态。</p>\n<h2>4、写锁的释放：</h2>\n<p>​    写锁释放通过重写AQS的tryRelease方法，源码为：</p>\n<pre><code class=\"language-java\">protected final boolean tryRelease(int releases) {\n     if (!isHeldExclusively())\n         throw new IllegalMonitorStateException();\n     //1. 同步状态减去写状态\n     int nextc = getState() - releases;\n     //2. 当前写状态是否为0，为0则释放写锁\n     boolean free = exclusiveCount(nextc) == 0;\n     if (free)\n         setExclusiveOwnerThread(null);\n     //3. 不为0则更新同步状态\n     setState(nextc);\n     return free;\n }\n</code></pre>\n<p>​    减少写状态int nextc = getState() - releases，只需要用当前同步状态直接减去写状态的原因：写状态是由同步状态的低16位表示的。</p>\n<h2>5、读锁的获取</h2>\n<p>​        读锁不是独占式锁，即同一时刻该锁可以被多个读线程获取也就是一种共享式锁。</p>\n<pre><code class=\"language-java\">protected final int tryAcquireShared(int unused) {\n     Thread current = Thread.currentThread();\n     int c = getState();\n     //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前\n     // 线程获取读锁失败返回-1\n     if (exclusiveCount(c) != 0 &amp;&amp;\n         getExclusiveOwnerThread() != current)\n         return -1;\n     int r = sharedCount(c);\n     if (!readerShouldBlock() &amp;&amp;\n         r &lt; MAX_COUNT &amp;&amp;\n         //2. 当前线程获取读锁\n         compareAndSetState(c, c + SHARED_UNIT)) {\n         //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法\n         //返回当前获取读锁的次数\n         if (r == 0) {\n             firstReader = current;\n             firstReaderHoldCount = 1;\n         } else if (firstReader == current) {\n             firstReaderHoldCount++;\n         } else {\n             HoldCounter rh = cachedHoldCounter;\n             if (rh == null || rh.tid != getThreadId(current))\n                 cachedHoldCounter = rh = readHolds.get();\n             else if (rh.count == 0)\n                 readHolds.set(rh);\n             rh.count++;\n         }\n         return 1;\n     }\n     //4. 处理在第二步中CAS操作失败的自旋已经实现重入性\n     return fullTryAcquireShared(current);\n }\n</code></pre>\n<p>​    当写锁被其他线程获取后，读锁获取失败，否则获取成功利用CAS更新同步状态。</p>\n<h2>6、读锁的释放</h2>\n<pre><code class=\"language-java\">protected final boolean tryReleaseShared(int unused) {\n     Thread current = Thread.currentThread();\n     // 前面还是为了实现getReadHoldCount等新功能\n     if (firstReader == current) {\n         // assert firstReaderHoldCount &gt; 0;\n         if (firstReaderHoldCount == 1)\n             firstReader = null;\n         else\n             firstReaderHoldCount--;\n     } else {\n         HoldCounter rh = cachedHoldCounter;\n         if (rh == null || rh.tid != getThreadId(current))\n             rh = readHolds.get();\n         int count = rh.count;\n         if (count &lt;= 1) {\n             readHolds.remove();\n             if (count &lt;= 0)\n                 throw unmatchedUnlockException();\n         }\n         --rh.count;\n     }     for (;;) {\n         int c = getState();\n         // 读锁释放 将同步状态减去读状态即可\n         int nextc = c - SHARED_UNIT;\n         if (compareAndSetState(c, nextc))\n             // Releasing the read lock has no effect on readers,\n             // but it may allow waiting writers to proceed if\n             // both read and write locks are now free.\n             return nextc == 0;\n     }\n }\n</code></pre>\n<h2>7、锁降级</h2>\n<p>​        读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中：</p>\n<pre><code class=\"language-java\">void processCachedData() {\n         rwl.readLock().lock();\n         if (!cacheValid) {\n             // Must release read lock before acquiring write lock\n             rwl.readLock().unlock();\n             rwl.writeLock().lock();\n             try {\n                 // Recheck state because another thread might have\n                 // acquired write lock and changed state before we did.\n                 if (!cacheValid) {\n                     data = ...\n             cacheValid = true;\n           }\n           // Downgrade by acquiring read lock before releasing write lock\n           rwl.readLock().lock();\n         } finally {\n           rwl.writeLock().unlock(); // Unlock write, still hold read\n         }\n       }\n       try {\n         use(data);\n       } finally {\n         rwl.readLock().unlock();\n       }\n     }\n }\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>4、读写锁</h1>\n<h2>1、读写锁介绍：</h2>\n<p>​        ReadWriteLock同Lock一样也是一个接口，提供了readLock和writeLock两种锁的操作机制，一个是只读的锁，一个是写锁。</p>\n<p>​        理论上，读写锁比互斥锁允许对于共享数据更大程度的并发。与互斥锁相比，读写锁是否能够提高性能取决于读写数据的频率、读取和写入操作的持续时间、以及读线程和写线程之间的竞争。</p>\n<p>​        一些业务场景中，大部分 只是读数据，写数据很少，如果仅仅是读数据的话并不会影响数据正确性（出现脏读），而如果在这种业务场景下，依然使用独占锁的话，很显然这将是出现性能瓶颈的地方。 针对这种读多写少的情况，java还提供了另外一个实现Lock接口的ReentrantReadWriteLock(读写锁)。读写所允许同一时刻被多个读线程访问，但是在写线程访问时，所有的读线程和其他的写线程都会被阻塞。</p>\n<p>​</p>\n<p>​        读-读能共存，\n​         读-写不能共存，\n​         写-写不能共存。</p>\n<p>连接：https://blog.csdn.net/j080624/article/details/82790372、https://ifeve.com/read-write-locks/</p>\n<h2>2、总结：</h2>\n<ol>\n<li><strong>公平性选择</strong>：支持非公平性（默认）和公平的锁获取方式，吞吐量还是非公平优于公平；</li>\n<li><strong>重入性</strong>：支持重入，读锁获取后能再次获取，写锁获取之后能够再次获取写锁，同时也能够获取读锁；</li>\n<li><strong>锁降级</strong>：遵循获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁</li>\n</ol>\n<h2>3、写锁的获取：</h2>\n<p>​        写锁是独占式锁，而实现写锁的同步语义是通过重写 AQS 中的 tryAcquire() 方法实现的，源码：</p>\n<pre><code class=\"language-java\">protected final boolean tryAcquire(int acquires) {\n     Thread current = Thread.currentThread();\n     // 1. 获取 写锁 当前的同步状态\n     int c = getState();\n     // 2. 获取 写锁 获取的次数\n     int w = exclusiveCount(c);\n     if (c != 0) {\n         // (Note: if c != 0 and w == 0 then shared count != 0)\n         // 3.1 当 读锁 已被读线程获取 或者 当前线程不是已经获取 写锁 的线程的话\n         // 当前线程获取 写锁失败\n         if (w == 0 || current != getExclusiveOwnerThread())\n             return false;\n         if (w + exclusiveCount(acquires) &gt; MAX_COUNT)\n             throw new Error(&quot;Maximum lock count exceeded&quot;);\n         // Reentrant acquire\n         // 3.2 当前线程 获取写锁，支持可重复加锁\n         setState(c + acquires);\n         return true;\n     }\n     // 3.3 写锁 未被任何线程获取，当前线程可获取 写锁\n     if (writerShouldBlock() ||!compareAndSetState(c, c + acquires))\n         return false;\n     setExclusiveOwnerThread(current);\n     return true;\n }\n\n \n\n static int exclusiveCount(int c) { \n\n        return c &amp; EXCLUSIVE_MASK;\n\n }\n</code></pre>\n<p>其中EXCLUSIVE_MASK为:  static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;      EXCLUSIVE _MASK为1左移16位然后减1，即为0x0000FFFF。</p>\n<p>而exclusiveCount方法是将同步状态（state为int类型）与0x0000FFFF相与，即取同步状态的低16位。那么低16位代表什么呢？</p>\n<p>根据exclusiveCount方法的注释为独占式获取的次数即写锁被获取的次数，现在就可以得出来一个结论同步状态的低16位用来表示写锁的获取次数</p>\n<pre><code class=\"language-java\">static int sharedCount(int c)    { \n\n        return c &gt;&gt;&gt; SHARED_SHIFT; \n\n}\n</code></pre>\n<p>该方法是获取读锁被获取的次数，是将同步状态（int c）右移16次，即取同步状态的高16位，现在我们可以得出另外一个结论同步状态的高16位用来表示读锁被获取的次数。</p>\n<p><img src=\"/img/%E8%AF%BB%E5%86%99%E9%94%81.png\" alt=\"img\"></p>\n<p>当读锁已经被读线程获取或者写锁已经被其他写线程获取，则写锁获取失败；否则，获取成功并支持重入，增加写状态。</p>\n<h2>4、写锁的释放：</h2>\n<p>​    写锁释放通过重写AQS的tryRelease方法，源码为：</p>\n<pre><code class=\"language-java\">protected final boolean tryRelease(int releases) {\n     if (!isHeldExclusively())\n         throw new IllegalMonitorStateException();\n     //1. 同步状态减去写状态\n     int nextc = getState() - releases;\n     //2. 当前写状态是否为0，为0则释放写锁\n     boolean free = exclusiveCount(nextc) == 0;\n     if (free)\n         setExclusiveOwnerThread(null);\n     //3. 不为0则更新同步状态\n     setState(nextc);\n     return free;\n }\n</code></pre>\n<p>​    减少写状态int nextc = getState() - releases，只需要用当前同步状态直接减去写状态的原因：写状态是由同步状态的低16位表示的。</p>\n<h2>5、读锁的获取</h2>\n<p>​        读锁不是独占式锁，即同一时刻该锁可以被多个读线程获取也就是一种共享式锁。</p>\n<pre><code class=\"language-java\">protected final int tryAcquireShared(int unused) {\n     Thread current = Thread.currentThread();\n     int c = getState();\n     //1. 如果写锁已经被获取并且获取写锁的线程不是当前线程的话，当前\n     // 线程获取读锁失败返回-1\n     if (exclusiveCount(c) != 0 &amp;&amp;\n         getExclusiveOwnerThread() != current)\n         return -1;\n     int r = sharedCount(c);\n     if (!readerShouldBlock() &amp;&amp;\n         r &lt; MAX_COUNT &amp;&amp;\n         //2. 当前线程获取读锁\n         compareAndSetState(c, c + SHARED_UNIT)) {\n         //3. 下面的代码主要是新增的一些功能，比如getReadHoldCount()方法\n         //返回当前获取读锁的次数\n         if (r == 0) {\n             firstReader = current;\n             firstReaderHoldCount = 1;\n         } else if (firstReader == current) {\n             firstReaderHoldCount++;\n         } else {\n             HoldCounter rh = cachedHoldCounter;\n             if (rh == null || rh.tid != getThreadId(current))\n                 cachedHoldCounter = rh = readHolds.get();\n             else if (rh.count == 0)\n                 readHolds.set(rh);\n             rh.count++;\n         }\n         return 1;\n     }\n     //4. 处理在第二步中CAS操作失败的自旋已经实现重入性\n     return fullTryAcquireShared(current);\n }\n</code></pre>\n<p>​    当写锁被其他线程获取后，读锁获取失败，否则获取成功利用CAS更新同步状态。</p>\n<h2>6、读锁的释放</h2>\n<pre><code class=\"language-java\">protected final boolean tryReleaseShared(int unused) {\n     Thread current = Thread.currentThread();\n     // 前面还是为了实现getReadHoldCount等新功能\n     if (firstReader == current) {\n         // assert firstReaderHoldCount &gt; 0;\n         if (firstReaderHoldCount == 1)\n             firstReader = null;\n         else\n             firstReaderHoldCount--;\n     } else {\n         HoldCounter rh = cachedHoldCounter;\n         if (rh == null || rh.tid != getThreadId(current))\n             rh = readHolds.get();\n         int count = rh.count;\n         if (count &lt;= 1) {\n             readHolds.remove();\n             if (count &lt;= 0)\n                 throw unmatchedUnlockException();\n         }\n         --rh.count;\n     }     for (;;) {\n         int c = getState();\n         // 读锁释放 将同步状态减去读状态即可\n         int nextc = c - SHARED_UNIT;\n         if (compareAndSetState(c, nextc))\n             // Releasing the read lock has no effect on readers,\n             // but it may allow waiting writers to proceed if\n             // both read and write locks are now free.\n             return nextc == 0;\n     }\n }\n</code></pre>\n<h2>7、锁降级</h2>\n<p>​        读写锁支持锁降级，遵循按照获取写锁，获取读锁再释放写锁的次序，写锁能够降级成为读锁，不支持锁升级，关于锁降级下面的示例代码摘自ReentrantWriteReadLock源码中：</p>\n<pre><code class=\"language-java\">void processCachedData() {\n         rwl.readLock().lock();\n         if (!cacheValid) {\n             // Must release read lock before acquiring write lock\n             rwl.readLock().unlock();\n             rwl.writeLock().lock();\n             try {\n                 // Recheck state because another thread might have\n                 // acquired write lock and changed state before we did.\n                 if (!cacheValid) {\n                     data = ...\n             cacheValid = true;\n           }\n           // Downgrade by acquiring read lock before releasing write lock\n           rwl.readLock().lock();\n         } finally {\n           rwl.writeLock().unlock(); // Unlock write, still hold read\n         }\n       }\n       try {\n         use(data);\n       } finally {\n         rwl.readLock().unlock();\n       }\n     }\n }\n</code></pre>\n"},{"title":"重放攻击","author":"郑天祺","date":"2019-09-04T11:54:00.000Z","_content":"\n# 1、概念\n\n​\t重放攻击(Replay Attacks)又称重播攻击、回放攻击，是指攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，破坏认证的正确性。\n\n​\t重放攻击可以由发起者，也可以由拦截并重发该数据的敌方进行。攻击者利用网络监听或者其他方式盗取认证凭据，之后再把它重新发给认证服务器。\n\n​\t重放攻击在任何网络通过程中都可能发生，是计算机世界黑客常用的攻击方式之一。 \n\n（来自百度百科）\n\n# 2、来源\n\n一个存在安全漏洞的登录系统：\n\n1. 前端web页面用户输入账号、密码，点击登录。\n\n2. 请求提交之前，web端首先通过客户端脚本如javascript对密码原文进行md5加密。\n\n3. 提交账号、md5之后的密码\n\n4. 请求提交至后端，验证账号与密码是否与数据库中的一致，一致则认为登录成功，反之失败。\n\n解析：\n\n​\t目前的腾讯电脑管家，360等软件，会将你的网络请求原封不动的发送到他们的后端保存一份、当然不止这些安全软件，其他软件也可以做到。这样就会将你的账户就很容易被别人使用。\n\n​\t这样的话md5加密就起不到任何作用了。\n\nSo：\n\n​\t我们考虑加入盐值，登录时候，session(或者redis缓存)中存一份随机数（称为盐值）。同样的盐值页面中也存在一份。所以我们不仅仅考虑用户名和md5密码了，还需要一份盐值作为网络请求的身份参照物，这样做稍微安全一些。\n\nMore：\n\n​\t存在简单md5暴力破解的时候，我们需要增强密码强度。但是用户不喜欢这样，就需要我们自己加盐值。\n\n如：MD5(固定盐值+密码)\n\nMore and More：\n\n加时间戳和流水号；\n\n一应答机制和一次性口令机制（应用广泛）\n\n# 3、分类\n\n重放攻击可以是登录认证，也可以是其他方式，\n\n从用户端考虑或从服务端考虑也会不同，\n\n当然会会有不同的分类。\n\n任性不提。。。\n\n# 4、一次应答机制\n\n​\t用验证码代替时间戳，将密码通过md5算法加密，再将验证码加在后面，然后再用md5算法加密，在网络传输过程中以密文的形式传输到后台管理。\n\n​\t后台数据库保存的是用md5算法加密的密码，将该密文加上保存在session(或redis)失效范围内的验证码用md5算法加密，得到的密文与请求中的口令对比，如配对，则验证成功，否则，验证失败。","source":"_posts/重放攻击.md","raw":"title: 重放攻击\nauthor: 郑天祺\ntags:\n  - 网络安全\n  - 可信\ncategories:\n  - 可信\ndate: 2019-09-04 19:54:00\n\n---\n\n# 1、概念\n\n​\t重放攻击(Replay Attacks)又称重播攻击、回放攻击，是指攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，破坏认证的正确性。\n\n​\t重放攻击可以由发起者，也可以由拦截并重发该数据的敌方进行。攻击者利用网络监听或者其他方式盗取认证凭据，之后再把它重新发给认证服务器。\n\n​\t重放攻击在任何网络通过程中都可能发生，是计算机世界黑客常用的攻击方式之一。 \n\n（来自百度百科）\n\n# 2、来源\n\n一个存在安全漏洞的登录系统：\n\n1. 前端web页面用户输入账号、密码，点击登录。\n\n2. 请求提交之前，web端首先通过客户端脚本如javascript对密码原文进行md5加密。\n\n3. 提交账号、md5之后的密码\n\n4. 请求提交至后端，验证账号与密码是否与数据库中的一致，一致则认为登录成功，反之失败。\n\n解析：\n\n​\t目前的腾讯电脑管家，360等软件，会将你的网络请求原封不动的发送到他们的后端保存一份、当然不止这些安全软件，其他软件也可以做到。这样就会将你的账户就很容易被别人使用。\n\n​\t这样的话md5加密就起不到任何作用了。\n\nSo：\n\n​\t我们考虑加入盐值，登录时候，session(或者redis缓存)中存一份随机数（称为盐值）。同样的盐值页面中也存在一份。所以我们不仅仅考虑用户名和md5密码了，还需要一份盐值作为网络请求的身份参照物，这样做稍微安全一些。\n\nMore：\n\n​\t存在简单md5暴力破解的时候，我们需要增强密码强度。但是用户不喜欢这样，就需要我们自己加盐值。\n\n如：MD5(固定盐值+密码)\n\nMore and More：\n\n加时间戳和流水号；\n\n一应答机制和一次性口令机制（应用广泛）\n\n# 3、分类\n\n重放攻击可以是登录认证，也可以是其他方式，\n\n从用户端考虑或从服务端考虑也会不同，\n\n当然会会有不同的分类。\n\n任性不提。。。\n\n# 4、一次应答机制\n\n​\t用验证码代替时间戳，将密码通过md5算法加密，再将验证码加在后面，然后再用md5算法加密，在网络传输过程中以密文的形式传输到后台管理。\n\n​\t后台数据库保存的是用md5算法加密的密码，将该密文加上保存在session(或redis)失效范围内的验证码用md5算法加密，得到的密文与请求中的口令对比，如配对，则验证成功，否则，验证失败。","slug":"重放攻击","published":1,"updated":"2019-09-04T13:24:43.315Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm250031vguqpa48ujwv","content":"<h1>1、概念</h1>\n<p>​\t重放攻击(Replay Attacks)又称重播攻击、回放攻击，是指攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，破坏认证的正确性。</p>\n<p>​\t重放攻击可以由发起者，也可以由拦截并重发该数据的敌方进行。攻击者利用网络监听或者其他方式盗取认证凭据，之后再把它重新发给认证服务器。</p>\n<p>​\t重放攻击在任何网络通过程中都可能发生，是计算机世界黑客常用的攻击方式之一。</p>\n<p>（来自百度百科）</p>\n<h1>2、来源</h1>\n<p>一个存在安全漏洞的登录系统：</p>\n<ol>\n<li>\n<p>前端web页面用户输入账号、密码，点击登录。</p>\n</li>\n<li>\n<p>请求提交之前，web端首先通过客户端脚本如javascript对密码原文进行md5加密。</p>\n</li>\n<li>\n<p>提交账号、md5之后的密码</p>\n</li>\n<li>\n<p>请求提交至后端，验证账号与密码是否与数据库中的一致，一致则认为登录成功，反之失败。</p>\n</li>\n</ol>\n<p>解析：</p>\n<p>​\t目前的腾讯电脑管家，360等软件，会将你的网络请求原封不动的发送到他们的后端保存一份、当然不止这些安全软件，其他软件也可以做到。这样就会将你的账户就很容易被别人使用。</p>\n<p>​\t这样的话md5加密就起不到任何作用了。</p>\n<p>So：</p>\n<p>​\t我们考虑加入盐值，登录时候，session(或者redis缓存)中存一份随机数（称为盐值）。同样的盐值页面中也存在一份。所以我们不仅仅考虑用户名和md5密码了，还需要一份盐值作为网络请求的身份参照物，这样做稍微安全一些。</p>\n<p>More：</p>\n<p>​\t存在简单md5暴力破解的时候，我们需要增强密码强度。但是用户不喜欢这样，就需要我们自己加盐值。</p>\n<p>如：MD5(固定盐值+密码)</p>\n<p>More and More：</p>\n<p>加时间戳和流水号；</p>\n<p>一应答机制和一次性口令机制（应用广泛）</p>\n<h1>3、分类</h1>\n<p>重放攻击可以是登录认证，也可以是其他方式，</p>\n<p>从用户端考虑或从服务端考虑也会不同，</p>\n<p>当然会会有不同的分类。</p>\n<p>任性不提。。。</p>\n<h1>4、一次应答机制</h1>\n<p>​\t用验证码代替时间戳，将密码通过md5算法加密，再将验证码加在后面，然后再用md5算法加密，在网络传输过程中以密文的形式传输到后台管理。</p>\n<p>​\t后台数据库保存的是用md5算法加密的密码，将该密文加上保存在session(或redis)失效范围内的验证码用md5算法加密，得到的密文与请求中的口令对比，如配对，则验证成功，否则，验证失败。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1>1、概念</h1>\n<p>​\t重放攻击(Replay Attacks)又称重播攻击、回放攻击，是指攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，破坏认证的正确性。</p>\n<p>​\t重放攻击可以由发起者，也可以由拦截并重发该数据的敌方进行。攻击者利用网络监听或者其他方式盗取认证凭据，之后再把它重新发给认证服务器。</p>\n<p>​\t重放攻击在任何网络通过程中都可能发生，是计算机世界黑客常用的攻击方式之一。</p>\n<p>（来自百度百科）</p>\n<h1>2、来源</h1>\n<p>一个存在安全漏洞的登录系统：</p>\n<ol>\n<li>\n<p>前端web页面用户输入账号、密码，点击登录。</p>\n</li>\n<li>\n<p>请求提交之前，web端首先通过客户端脚本如javascript对密码原文进行md5加密。</p>\n</li>\n<li>\n<p>提交账号、md5之后的密码</p>\n</li>\n<li>\n<p>请求提交至后端，验证账号与密码是否与数据库中的一致，一致则认为登录成功，反之失败。</p>\n</li>\n</ol>\n<p>解析：</p>\n<p>​\t目前的腾讯电脑管家，360等软件，会将你的网络请求原封不动的发送到他们的后端保存一份、当然不止这些安全软件，其他软件也可以做到。这样就会将你的账户就很容易被别人使用。</p>\n<p>​\t这样的话md5加密就起不到任何作用了。</p>\n<p>So：</p>\n<p>​\t我们考虑加入盐值，登录时候，session(或者redis缓存)中存一份随机数（称为盐值）。同样的盐值页面中也存在一份。所以我们不仅仅考虑用户名和md5密码了，还需要一份盐值作为网络请求的身份参照物，这样做稍微安全一些。</p>\n<p>More：</p>\n<p>​\t存在简单md5暴力破解的时候，我们需要增强密码强度。但是用户不喜欢这样，就需要我们自己加盐值。</p>\n<p>如：MD5(固定盐值+密码)</p>\n<p>More and More：</p>\n<p>加时间戳和流水号；</p>\n<p>一应答机制和一次性口令机制（应用广泛）</p>\n<h1>3、分类</h1>\n<p>重放攻击可以是登录认证，也可以是其他方式，</p>\n<p>从用户端考虑或从服务端考虑也会不同，</p>\n<p>当然会会有不同的分类。</p>\n<p>任性不提。。。</p>\n<h1>4、一次应答机制</h1>\n<p>​\t用验证码代替时间戳，将密码通过md5算法加密，再将验证码加在后面，然后再用md5算法加密，在网络传输过程中以密文的形式传输到后台管理。</p>\n<p>​\t后台数据库保存的是用md5算法加密的密码，将该密文加上保存在session(或redis)失效范围内的验证码用md5算法加密，得到的密文与请求中的口令对比，如配对，则验证成功，否则，验证失败。</p>\n"},{"title":"池化之线程池","author":"郑天祺","date":"2019-09-01T02:14:00.000Z","_content":"\njava中池化技术是提前保存大量的资源，以备不时之需以及重复使用。\n\n## 1、池化技术\n\nTips：不是深度学习中的卷积和赤化\n\n在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。\n\n进程池、线程池：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。当线程数达到一定数量时，可以在队列中等待。\n\n内存池：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。\n\n## 2、线程池的创建\n\n```java\n// 创建线程工厂实例\nThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"demo-pool-%d\").build();\n// 创建线程池，核心线程数、最大线程数、空闲保持时间、队列长度、拒绝策略可自行定义\nExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS,\n            new LinkedBlockingQueue<Runnable>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());\n```\n\n## 3、线程池的关闭\n\n```java\nExecutorService pool=...；\npool.shutdown();   //用于线程内无迭代，且预期在短时间内能执行完毕的线程任务；\npool.shutdownNow();//用于线程内有迭代逻辑，或执行完成时间无法预估的场景（此类线程任务代码必须进行中断信号的处理）；\n```\n\n\n","source":"_posts/池化之线程池.md","raw":"title: 池化之线程池\nauthor: 郑天祺\ntags:\n  - java\n  - 多线程\ncategories:\n  - java基础\ndate: 2019-09-01 10:14:00\n\n---\n\njava中池化技术是提前保存大量的资源，以备不时之需以及重复使用。\n\n## 1、池化技术\n\nTips：不是深度学习中的卷积和赤化\n\n在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。\n\n进程池、线程池：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。当线程数达到一定数量时，可以在队列中等待。\n\n内存池：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。\n\n## 2、线程池的创建\n\n```java\n// 创建线程工厂实例\nThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(\"demo-pool-%d\").build();\n// 创建线程池，核心线程数、最大线程数、空闲保持时间、队列长度、拒绝策略可自行定义\nExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS,\n            new LinkedBlockingQueue<Runnable>(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());\n```\n\n## 3、线程池的关闭\n\n```java\nExecutorService pool=...；\npool.shutdown();   //用于线程内无迭代，且预期在短时间内能执行完毕的线程任务；\npool.shutdownNow();//用于线程内有迭代逻辑，或执行完成时间无法预估的场景（此类线程任务代码必须进行中断信号的处理）；\n```\n\n\n","slug":"池化之线程池","published":1,"updated":"2019-10-15T10:04:50.697Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm270034vguqu35j3yq0","content":"<p>java中池化技术是提前保存大量的资源，以备不时之需以及重复使用。</p>\n<h2>1、池化技术</h2>\n<p>Tips：不是深度学习中的卷积和赤化</p>\n<p>在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。</p>\n<p>进程池、线程池：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。当线程数达到一定数量时，可以在队列中等待。</p>\n<p>内存池：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。</p>\n<h2>2、线程池的创建</h2>\n<pre><code class=\"language-java\">// 创建线程工厂实例\nThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();\n// 创建线程池，核心线程数、最大线程数、空闲保持时间、队列长度、拒绝策略可自行定义\nExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS,\n            new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());\n</code></pre>\n<h2>3、线程池的关闭</h2>\n<pre><code class=\"language-java\">ExecutorService pool=...；\npool.shutdown();   //用于线程内无迭代，且预期在短时间内能执行完毕的线程任务；\npool.shutdownNow();//用于线程内有迭代逻辑，或执行完成时间无法预估的场景（此类线程任务代码必须进行中断信号的处理）；\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>java中池化技术是提前保存大量的资源，以备不时之需以及重复使用。</p>\n<h2>1、池化技术</h2>\n<p>Tips：不是深度学习中的卷积和赤化</p>\n<p>在实际应用当做，分配内存、创建进程、线程都会设计到一些系统调用，系统调用需要导致程序从用户态切换到内核态，是非常耗时的操作。因此，当程序中需要频繁的进行内存申请释放，进程、线程创建销毁等操作时，通常会使用内存池、进程池、线程池技术来提升程序的性能。</p>\n<p>进程池、线程池：先启动若干数量的线程，并让这些线程都处于睡眠状态，当需要一个开辟一个线程去做具体的工作时，就会唤醒线程池中的某一个睡眠线程，让它去做具体工作，当工作完成后，线程又处于睡眠状态，而不是将线程销毁。当线程数达到一定数量时，可以在队列中等待。</p>\n<p>内存池：内存池是指程序预先从操作系统申请一块足够大内存，此后，当程序中需要申请内存的时候，不是直接向操作系统申请，而是直接从内存池中获取；同理，当程序释放内存的时候，并不真正将内存返回给操作系统，而是返回内存池。当程序退出(或者特定时间)时，内存池才将之前申请的内存真正释放。</p>\n<h2>2、线程池的创建</h2>\n<pre><code class=\"language-java\">// 创建线程工厂实例\nThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();\n// 创建线程池，核心线程数、最大线程数、空闲保持时间、队列长度、拒绝策略可自行定义\nExecutorService pool = new ThreadPoolExecutor(5, 20, 0L, TimeUnit.MILLISECONDS,\n            new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());\n</code></pre>\n<h2>3、线程池的关闭</h2>\n<pre><code class=\"language-java\">ExecutorService pool=...；\npool.shutdown();   //用于线程内无迭代，且预期在短时间内能执行完毕的线程任务；\npool.shutdownNow();//用于线程内有迭代逻辑，或执行完成时间无法预估的场景（此类线程任务代码必须进行中断信号的处理）；\n</code></pre>\n"},{"title":"轻量级锁","author":"郑天祺","date":"2019-08-31T07:08:00.000Z","_content":"\n## 1、轻量级锁\n\n锁撤销升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。\n\n​    下面先简单描述下锁撤销之后，升级为轻量级锁的过程：\n\n​    a) 线程在自己的栈桢中创建锁记录 LockRecord。\n​     b) 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。\n​     c) 将锁记录中的Owner指针指向锁对象。\n​     d) 将锁对象的对象头的MarkWord替换为指向锁记录的指针。\n\n## 2、锁消除\n\n由于偏向锁失效了，那么接下来就得把该锁撤销，锁撤销的开销花费还是挺大的，其大概的过程如下：\n\n​    a) 在一个安全点停止拥有锁的线程。\n\n​    b) 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。\n\n​    c) 唤醒当前线程，将当前锁升级成轻量级锁。\n\n 所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭\n\n## 3、锁膨胀\n\n当出现有两个线程来竞争锁的话，那么偏向锁就失效了，此时锁就会膨胀，升级为轻量级锁。这也是我们经常所说的锁膨胀","source":"_posts/轻量级锁.md","raw":"title: 轻量级锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 15:08:00\n\n---\n\n## 1、轻量级锁\n\n锁撤销升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。\n\n​    下面先简单描述下锁撤销之后，升级为轻量级锁的过程：\n\n​    a) 线程在自己的栈桢中创建锁记录 LockRecord。\n​     b) 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。\n​     c) 将锁记录中的Owner指针指向锁对象。\n​     d) 将锁对象的对象头的MarkWord替换为指向锁记录的指针。\n\n## 2、锁消除\n\n由于偏向锁失效了，那么接下来就得把该锁撤销，锁撤销的开销花费还是挺大的，其大概的过程如下：\n\n​    a) 在一个安全点停止拥有锁的线程。\n\n​    b) 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。\n\n​    c) 唤醒当前线程，将当前锁升级成轻量级锁。\n\n 所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭\n\n## 3、锁膨胀\n\n当出现有两个线程来竞争锁的话，那么偏向锁就失效了，此时锁就会膨胀，升级为轻量级锁。这也是我们经常所说的锁膨胀","slug":"轻量级锁","published":1,"updated":"2019-08-31T07:10:30.223Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm2a0037vguq8ceuvjst","content":"<h2>1、轻量级锁</h2>\n<p>锁撤销升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。</p>\n<p>​    下面先简单描述下锁撤销之后，升级为轻量级锁的过程：</p>\n<p>​    a) 线程在自己的栈桢中创建锁记录 LockRecord。\n​     b) 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。\n​     c) 将锁记录中的Owner指针指向锁对象。\n​     d) 将锁对象的对象头的MarkWord替换为指向锁记录的指针。</p>\n<h2>2、锁消除</h2>\n<p>由于偏向锁失效了，那么接下来就得把该锁撤销，锁撤销的开销花费还是挺大的，其大概的过程如下：</p>\n<p>​    a) 在一个安全点停止拥有锁的线程。</p>\n<p>​    b) 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。</p>\n<p>​    c) 唤醒当前线程，将当前锁升级成轻量级锁。</p>\n<p>所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭</p>\n<h2>3、锁膨胀</h2>\n<p>当出现有两个线程来竞争锁的话，那么偏向锁就失效了，此时锁就会膨胀，升级为轻量级锁。这也是我们经常所说的锁膨胀</p>\n","site":{"data":{}},"excerpt":"","more":"<h2>1、轻量级锁</h2>\n<p>锁撤销升级为轻量级锁之后，那么对象的Markword也会进行相应的的变化。</p>\n<p>​    下面先简单描述下锁撤销之后，升级为轻量级锁的过程：</p>\n<p>​    a) 线程在自己的栈桢中创建锁记录 LockRecord。\n​     b) 将锁对象的对象头中的MarkWord复制到线程的刚刚创建的锁记录中。\n​     c) 将锁记录中的Owner指针指向锁对象。\n​     d) 将锁对象的对象头的MarkWord替换为指向锁记录的指针。</p>\n<h2>2、锁消除</h2>\n<p>由于偏向锁失效了，那么接下来就得把该锁撤销，锁撤销的开销花费还是挺大的，其大概的过程如下：</p>\n<p>​    a) 在一个安全点停止拥有锁的线程。</p>\n<p>​    b) 遍历线程栈，如果存在锁记录的话，需要修复锁记录和Markword，使其变成无锁状态。</p>\n<p>​    c) 唤醒当前线程，将当前锁升级成轻量级锁。</p>\n<p>所以，如果某些同步代码块大多数情况下都是有两个及以上的线程竞争的话，那么偏向锁就会是一种累赘，对于这种情况，我们可以一开始就把偏向锁这个默认功能给关闭</p>\n<h2>3、锁膨胀</h2>\n<p>当出现有两个线程来竞争锁的话，那么偏向锁就失效了，此时锁就会膨胀，升级为轻量级锁。这也是我们经常所说的锁膨胀</p>\n"},{"title":"线程相关的知识","author":"郑天祺","date":"2019-11-20T11:46:00.000Z","_content":"\n# 一、线程之间的通信机制\n\n \n\n在命令式编程中：线程之间的通信机制有两种：共享内存和消息传递。\n\n1）在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。\n\n2）在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信。\n\nJava的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。\n\n简单例子：\n\n​    全局变量A，方法B和C都对A进行操作，B和C就可以利用A进行通讯。\n\n\n\n# 二、JMM （JAVA 内存模型）\n\n \n\nJMM 的一个抽象概念，并不真实存在。\n\n​    在JAVA中：\n\n1）共享变量：所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。\n\n2）局部变量、方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。\n\nJMM决定一个线程和主内存的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。\n\n![img](/img/线程相关1.jpg)\n\n从上图来看，线程 A与线程 B 之间如要通信的话，必须要经历下面 2 个步骤：\n\n1. 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。\n\n2. 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。\n\n![img](/img/线程相关3.jpg)\n\n# 三、重排序\n\n在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：\n\n1） 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n\n2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n\n3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n![img](/img/线程相关4.jpg)\n\n上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。\n\n**综上**，多个线程之间，执行的顺序是会随机改变的，需要我们注意。\n\n# 四、顺序一致性模型\n\n​    在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。\n\n# 五、总线事务\n\n1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。\n\n2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。\n\n3） JMM 不保证对 64 位的 long 型和 double 型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。\n\n这个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和 I/O 设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制：\n\n在一些 32 位的处理器上，如果要求对 64 位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long型变量和 double 型变量的写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long/ double 型变量的写操作拆分为两个 32 位的写操作来执行。这两个 32 位的写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的写将不具有原子性。\n\n![img](/img/线程相关5.jpg)\n\n \n\n ","source":"_posts/线程相关的知识.md","raw":"title: 线程相关的知识\nauthor: 郑天祺\ntags:\n  - 线程\ncategories:\n  - java基础\ndate: 2019-11-20 19:46:00\n\n---\n\n# 一、线程之间的通信机制\n\n \n\n在命令式编程中：线程之间的通信机制有两种：共享内存和消息传递。\n\n1）在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。\n\n2）在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信。\n\nJava的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。\n\n简单例子：\n\n​    全局变量A，方法B和C都对A进行操作，B和C就可以利用A进行通讯。\n\n\n\n# 二、JMM （JAVA 内存模型）\n\n \n\nJMM 的一个抽象概念，并不真实存在。\n\n​    在JAVA中：\n\n1）共享变量：所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。\n\n2）局部变量、方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。\n\nJMM决定一个线程和主内存的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。\n\n![img](/img/线程相关1.jpg)\n\n从上图来看，线程 A与线程 B 之间如要通信的话，必须要经历下面 2 个步骤：\n\n1. 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。\n\n2. 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。\n\n![img](/img/线程相关3.jpg)\n\n# 三、重排序\n\n在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：\n\n1） 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。\n\n2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。\n\n3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n\n![img](/img/线程相关4.jpg)\n\n上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。\n\n**综上**，多个线程之间，执行的顺序是会随机改变的，需要我们注意。\n\n# 四、顺序一致性模型\n\n​    在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。\n\n# 五、总线事务\n\n1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。\n\n2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。\n\n3） JMM 不保证对 64 位的 long 型和 double 型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。\n\n这个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和 I/O 设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制：\n\n在一些 32 位的处理器上，如果要求对 64 位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long型变量和 double 型变量的写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long/ double 型变量的写操作拆分为两个 32 位的写操作来执行。这两个 32 位的写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的写将不具有原子性。\n\n![img](/img/线程相关5.jpg)\n\n \n\n ","slug":"线程相关的知识","published":1,"updated":"2019-11-20T11:50:24.878Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm2c003bvguqfsfrmjc6","content":"<h1>一、线程之间的通信机制</h1>\n<p>在命令式编程中：线程之间的通信机制有两种：共享内存和消息传递。</p>\n<p>1）在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。</p>\n<p>2）在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信。</p>\n<p>Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。</p>\n<p>简单例子：</p>\n<p>​    全局变量A，方法B和C都对A进行操作，B和C就可以利用A进行通讯。</p>\n<h1>二、JMM （JAVA 内存模型）</h1>\n<p>JMM 的一个抽象概念，并不真实存在。</p>\n<p>​    在JAVA中：</p>\n<p>1）共享变量：所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。</p>\n<p>2）局部变量、方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。</p>\n<p>JMM决定一个线程和主内存的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B31.jpg\" alt=\"img\"></p>\n<p>从上图来看，线程 A与线程 B 之间如要通信的话，必须要经历下面 2 个步骤：</p>\n<ol>\n<li>\n<p>首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。</p>\n</li>\n<li>\n<p>然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。</p>\n</li>\n</ol>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B33.jpg\" alt=\"img\"></p>\n<h1>三、重排序</h1>\n<p>在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：</p>\n<p>1） 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p>\n<p>2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p>\n<p>3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B34.jpg\" alt=\"img\"></p>\n<p>上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。</p>\n<p><strong>综上</strong>，多个线程之间，执行的顺序是会随机改变的，需要我们注意。</p>\n<h1>四、顺序一致性模型</h1>\n<p>​    在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。</p>\n<h1>五、总线事务</h1>\n<p>1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。</p>\n<p>2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。</p>\n<p>3） JMM 不保证对 64 位的 long 型和 double 型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。</p>\n<p>这个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和 I/O 设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制：</p>\n<p>在一些 32 位的处理器上，如果要求对 64 位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long型变量和 double 型变量的写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long/ double 型变量的写操作拆分为两个 32 位的写操作来执行。这两个 32 位的写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的写将不具有原子性。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B35.jpg\" alt=\"img\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1>一、线程之间的通信机制</h1>\n<p>在命令式编程中：线程之间的通信机制有两种：共享内存和消息传递。</p>\n<p>1）在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。</p>\n<p>2）在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显示进行通信。</p>\n<p>Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。</p>\n<p>简单例子：</p>\n<p>​    全局变量A，方法B和C都对A进行操作，B和C就可以利用A进行通讯。</p>\n<h1>二、JMM （JAVA 内存模型）</h1>\n<p>JMM 的一个抽象概念，并不真实存在。</p>\n<p>​    在JAVA中：</p>\n<p>1）共享变量：所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享。</p>\n<p>2）局部变量、方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。</p>\n<p>JMM决定一个线程和主内存的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读/写共享变量的副本。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B31.jpg\" alt=\"img\"></p>\n<p>从上图来看，线程 A与线程 B 之间如要通信的话，必须要经历下面 2 个步骤：</p>\n<ol>\n<li>\n<p>首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。</p>\n</li>\n<li>\n<p>然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。</p>\n</li>\n</ol>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B33.jpg\" alt=\"img\"></p>\n<h1>三、重排序</h1>\n<p>在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：</p>\n<p>1） 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。</p>\n<p>2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。</p>\n<p>3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B34.jpg\" alt=\"img\"></p>\n<p>上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。</p>\n<p><strong>综上</strong>，多个线程之间，执行的顺序是会随机改变的，需要我们注意。</p>\n<h1>四、顺序一致性模型</h1>\n<p>​    在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。</p>\n<h1>五、总线事务</h1>\n<p>1）顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。</p>\n<p>2）顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。</p>\n<p>3） JMM 不保证对 64 位的 long 型和 double 型变量的读/写操作具有原子性，而顺序一致性模型保证对所有的内存读/写操作都具有原子性。</p>\n<p>这个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读/写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和 I/O 设备执行内存的读/写。下面让我们通过一个示意图来说明总线的工作机制：</p>\n<p>在一些 32 位的处理器上，如果要求对 64 位数据的写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long型变量和 double 型变量的写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long/ double 型变量的写操作拆分为两个 32 位的写操作来执行。这两个 32 位的写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的写将不具有原子性。</p>\n<p><img src=\"/img/%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B35.jpg\" alt=\"img\"></p>\n"},{"title":"锁粗化","author":"郑天祺","date":"2019-08-31T05:32:00.000Z","_content":"\n转自：https://blog.csdn.net/qq_26222859/article/details/80546917\n\n参考：https://www.jianshu.com/p/f05423a21e78\n\n通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。\n\n```java\npublic void doSomethingMethod(){\n     synchronized(lock){\n         //do some thing\n     }\n     //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕\n     synchronized(lock){\n         //do other thing\n     }\n }\n```\n\n上面的代码是有两块需要同步操作的，但在这两块需要同步操作的代码之间，需要做一些其它的工作，而这些工作只会花费很少的时间，那么我们就可以把这些工作代码放入锁内，将两个同步代码块合并成一个，以降低多次锁请求、同步、释放带来的系统性能消耗，合并后的代码如下 :\n\n```java\npublic void doSomethingMethod(){\n     //进行锁粗化：整合成一次锁请求、同步、释放\n     synchronized(lock){\n         //do some thing\n         //做其它不需要同步但能很快执行完的工作\n         //do other thing\n     }\n }\n```\n\n 注意：这样做是有前提的，就是中间不需要同步的代码能够很快速地完成，如果不需要同步的代码需要花很长时间，就会导致同步块的执行需要花费很长的时间，这样做也就不合理了。\n\n另一种需要锁粗化的极端的情况是：\n\n```java\nfor(int i=0;i<size;i++){\n     synchronized(lock){\n     }\n }\n```\n\n 上面代码每次循环都会进行锁的请求、同步与释放，看起来貌似没什么问题，且在jdk内部会对这类代码锁的请求做一些优化，但是还不如把加锁代码写在循环体的外面，这样一次锁的请求就可以达到我们的要求，除非有特殊的需要：循环需要花很长时间，但其它线程等不起，要给它们执行的机会。\n\n锁粗化后的代码如下：\n\n```java\nsynchronized(lock){\n     for(int i=0;i<size;i++){\n     }\n }\n```\n\n","source":"_posts/锁粗化.md","raw":"title: 锁粗化\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:32:00\n---\n\n转自：https://blog.csdn.net/qq_26222859/article/details/80546917\n\n参考：https://www.jianshu.com/p/f05423a21e78\n\n通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。\n\n```java\npublic void doSomethingMethod(){\n     synchronized(lock){\n         //do some thing\n     }\n     //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕\n     synchronized(lock){\n         //do other thing\n     }\n }\n```\n\n上面的代码是有两块需要同步操作的，但在这两块需要同步操作的代码之间，需要做一些其它的工作，而这些工作只会花费很少的时间，那么我们就可以把这些工作代码放入锁内，将两个同步代码块合并成一个，以降低多次锁请求、同步、释放带来的系统性能消耗，合并后的代码如下 :\n\n```java\npublic void doSomethingMethod(){\n     //进行锁粗化：整合成一次锁请求、同步、释放\n     synchronized(lock){\n         //do some thing\n         //做其它不需要同步但能很快执行完的工作\n         //do other thing\n     }\n }\n```\n\n 注意：这样做是有前提的，就是中间不需要同步的代码能够很快速地完成，如果不需要同步的代码需要花很长时间，就会导致同步块的执行需要花费很长的时间，这样做也就不合理了。\n\n另一种需要锁粗化的极端的情况是：\n\n```java\nfor(int i=0;i<size;i++){\n     synchronized(lock){\n     }\n }\n```\n\n 上面代码每次循环都会进行锁的请求、同步与释放，看起来貌似没什么问题，且在jdk内部会对这类代码锁的请求做一些优化，但是还不如把加锁代码写在循环体的外面，这样一次锁的请求就可以达到我们的要求，除非有特殊的需要：循环需要花很长时间，但其它线程等不起，要给它们执行的机会。\n\n锁粗化后的代码如下：\n\n```java\nsynchronized(lock){\n     for(int i=0;i<size;i++){\n     }\n }\n```\n\n","slug":"锁粗化","published":1,"updated":"2019-10-15T12:35:31.866Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm2e003evguqyp09wdoh","content":"<p>转自：https://blog.csdn.net/qq_26222859/article/details/80546917</p>\n<p>参考：https://www.jianshu.com/p/f05423a21e78</p>\n<p>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。</p>\n<pre><code class=\"language-java\">public void doSomethingMethod(){\n     synchronized(lock){\n         //do some thing\n     }\n     //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕\n     synchronized(lock){\n         //do other thing\n     }\n }\n</code></pre>\n<p>上面的代码是有两块需要同步操作的，但在这两块需要同步操作的代码之间，需要做一些其它的工作，而这些工作只会花费很少的时间，那么我们就可以把这些工作代码放入锁内，将两个同步代码块合并成一个，以降低多次锁请求、同步、释放带来的系统性能消耗，合并后的代码如下 :</p>\n<pre><code class=\"language-java\">public void doSomethingMethod(){\n     //进行锁粗化：整合成一次锁请求、同步、释放\n     synchronized(lock){\n         //do some thing\n         //做其它不需要同步但能很快执行完的工作\n         //do other thing\n     }\n }\n</code></pre>\n<p>注意：这样做是有前提的，就是中间不需要同步的代码能够很快速地完成，如果不需要同步的代码需要花很长时间，就会导致同步块的执行需要花费很长的时间，这样做也就不合理了。</p>\n<p>另一种需要锁粗化的极端的情况是：</p>\n<pre><code class=\"language-java\">for(int i=0;i&lt;size;i++){\n     synchronized(lock){\n     }\n }\n</code></pre>\n<p>上面代码每次循环都会进行锁的请求、同步与释放，看起来貌似没什么问题，且在jdk内部会对这类代码锁的请求做一些优化，但是还不如把加锁代码写在循环体的外面，这样一次锁的请求就可以达到我们的要求，除非有特殊的需要：循环需要花很长时间，但其它线程等不起，要给它们执行的机会。</p>\n<p>锁粗化后的代码如下：</p>\n<pre><code class=\"language-java\">synchronized(lock){\n     for(int i=0;i&lt;size;i++){\n     }\n }\n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<p>转自：https://blog.csdn.net/qq_26222859/article/details/80546917</p>\n<p>参考：https://www.jianshu.com/p/f05423a21e78</p>\n<p>通常情况下，为了保证多线程间的有效并发，会要求每个线程持有锁的时间尽可能短，但是大某些情况下，一个程序对同一个锁不间断、高频地请求、同步与释放，会消耗掉一定的系统资源，因为锁的讲求、同步与释放本身会带来性能损耗，这样高频的锁请求就反而不利于系统性能的优化了，虽然单次同步操作的时间可能很短。锁粗化就是告诉我们任何事情都有个度，有些情况下我们反而希望把很多次锁的请求合并成一个请求，以降低短时间内大量锁请求、同步、释放带来的性能损耗。</p>\n<pre><code class=\"language-java\">public void doSomethingMethod(){\n     synchronized(lock){\n         //do some thing\n     }\n     //这是还有一些代码，做其它不需要同步的工作，但能很快执行完毕\n     synchronized(lock){\n         //do other thing\n     }\n }\n</code></pre>\n<p>上面的代码是有两块需要同步操作的，但在这两块需要同步操作的代码之间，需要做一些其它的工作，而这些工作只会花费很少的时间，那么我们就可以把这些工作代码放入锁内，将两个同步代码块合并成一个，以降低多次锁请求、同步、释放带来的系统性能消耗，合并后的代码如下 :</p>\n<pre><code class=\"language-java\">public void doSomethingMethod(){\n     //进行锁粗化：整合成一次锁请求、同步、释放\n     synchronized(lock){\n         //do some thing\n         //做其它不需要同步但能很快执行完的工作\n         //do other thing\n     }\n }\n</code></pre>\n<p>注意：这样做是有前提的，就是中间不需要同步的代码能够很快速地完成，如果不需要同步的代码需要花很长时间，就会导致同步块的执行需要花费很长的时间，这样做也就不合理了。</p>\n<p>另一种需要锁粗化的极端的情况是：</p>\n<pre><code class=\"language-java\">for(int i=0;i&lt;size;i++){\n     synchronized(lock){\n     }\n }\n</code></pre>\n<p>上面代码每次循环都会进行锁的请求、同步与释放，看起来貌似没什么问题，且在jdk内部会对这类代码锁的请求做一些优化，但是还不如把加锁代码写在循环体的外面，这样一次锁的请求就可以达到我们的要求，除非有特殊的需要：循环需要花很长时间，但其它线程等不起，要给它们执行的机会。</p>\n<p>锁粗化后的代码如下：</p>\n<pre><code class=\"language-java\">synchronized(lock){\n     for(int i=0;i&lt;size;i++){\n     }\n }\n</code></pre>\n"},{"title":"阻塞锁","author":"郑天祺","date":"2019-08-31T05:00:00.000Z","_content":"\n# 阻塞锁\n\n## 1、阻塞锁优势\n\n​\t与自旋锁不同，改变了线程的运行状态。\n\n​    在JAVA环境中，线程Thread有如下几个状态：\n\n1. 新建状态\n2. 就绪状态\n3. 运行状态\n4. 阻塞状态\n5. 死亡状态\n\n​      阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。\n​       JAVA中，能够进入 / 退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock，Object.wait() / notify() ，LockSupport.park() / unpart() \n\n## 2、阻塞锁的优势：\n\n​\t在于，阻塞的线程不会占用CPU时间， 不会导致 CPU占用率过高，但进入时间以及恢复时间都要比自旋锁略慢。在竞争激烈的情况下 阻塞锁的性能要明显高于自旋锁。\n\n## 3、阻塞锁应用：\n\n​\t理想的情况则是， 在线程竞争不激烈的情况下，使用自旋锁；竞争激烈的情况下使用，阻塞锁。\n\n## 4、阻塞锁的简单实现：\n\n```java\n public class ClhLock {\n     /**\n      * 定义一个节点，默认的lock状态为true\n      */\n     public static class ClhNode {\n         private volatile Thread isLocked;\n     }\n\n    /**\n      * 尾部节点,只用一个节点即可\n      */\n     private volatile ClhNode tail;\n     private static final ThreadLocal<ClhNode> LOCAL = new ThreadLocal<>();\n     private static final AtomicReferenceFieldUpdater<ClhLock, ClhNode> UPDATER = AtomicReferenceFieldUpdater.newUpdater(ClhLock.class, ClhNode.class, \"tail\");\n\n    public void lock() {\n         // 新建节点并将节点与当前线程保存起来\n         ClhNode node = new ClhNode();\n         LOCAL.set(node);\n         // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点\n         // 个人理解=>大概相当于把AtomicReferenceFieldUpdater中原有的tail取出，并用新建的节点将原有的tail替代，这个操作是原子性的。\n         // 操作原子性的由来：AtomicReferenceFieldUpdater是一个基于反射的工具类，它能对指定类的指定的volatile引用字段进行原子更新。(这个字段不能是private的)。\n         ClhNode preNode = UPDATER.getAndSet(this, node);\n         if (preNode != null) {\n             preNode.isLocked = Thread.currentThread();\n             LockSupport.park(this);\n             preNode = null;\n             LOCAL.set(node);\n         }\n         // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁\n     }\n\npublic void unLock() {\n\n\n         // 获取当前线程对应的节点\n         // 对应博客中的这句话：申请线程只在本地变量上自旋，避免了多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum\n         // 每次读写操作都必须在多个处理器缓存之间进行缓存同步\n         ClhNode node = LOCAL.get();\n         // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁\n         if (!UPDATER.compareAndSet(this, node, null)) {\n //            System.out.println(\"unlock\\t\" + node.isLocked.getName());\n             LockSupport.unpark(node.isLocked);\n         }\n         node = null;\n     }\n }\n```\n\n### 5、demo：\n\n```java\npublic class ClhLockTest {\n\n    private static int num = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(1000, 1000, 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(), new DefaultNameThreadFactory(\"SimpleSpinLock\"));\n         CountDownLatch countDownLatch = new CountDownLatch(1000);\n         ClhLock clhLock = new ClhLock();\n         for (int i = 0; i < 1000; i++) {\n             pool.submit(() -> {\n                 clhLock.lock();\n                 num++;\n                 clhLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(num);\n     }\n }\n\n \n```\n\n","source":"_posts/阻塞锁.md","raw":"title: 阻塞锁\nauthor: 郑天祺\ntags:\n  - 锁\ncategories:\n  - java基础\ndate: 2019-08-31 13:00:00\n\n---\n\n# 阻塞锁\n\n## 1、阻塞锁优势\n\n​\t与自旋锁不同，改变了线程的运行状态。\n\n​    在JAVA环境中，线程Thread有如下几个状态：\n\n1. 新建状态\n2. 就绪状态\n3. 运行状态\n4. 阻塞状态\n5. 死亡状态\n\n​      阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。\n​       JAVA中，能够进入 / 退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock，Object.wait() / notify() ，LockSupport.park() / unpart() \n\n## 2、阻塞锁的优势：\n\n​\t在于，阻塞的线程不会占用CPU时间， 不会导致 CPU占用率过高，但进入时间以及恢复时间都要比自旋锁略慢。在竞争激烈的情况下 阻塞锁的性能要明显高于自旋锁。\n\n## 3、阻塞锁应用：\n\n​\t理想的情况则是， 在线程竞争不激烈的情况下，使用自旋锁；竞争激烈的情况下使用，阻塞锁。\n\n## 4、阻塞锁的简单实现：\n\n```java\n public class ClhLock {\n     /**\n      * 定义一个节点，默认的lock状态为true\n      */\n     public static class ClhNode {\n         private volatile Thread isLocked;\n     }\n\n    /**\n      * 尾部节点,只用一个节点即可\n      */\n     private volatile ClhNode tail;\n     private static final ThreadLocal<ClhNode> LOCAL = new ThreadLocal<>();\n     private static final AtomicReferenceFieldUpdater<ClhLock, ClhNode> UPDATER = AtomicReferenceFieldUpdater.newUpdater(ClhLock.class, ClhNode.class, \"tail\");\n\n    public void lock() {\n         // 新建节点并将节点与当前线程保存起来\n         ClhNode node = new ClhNode();\n         LOCAL.set(node);\n         // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点\n         // 个人理解=>大概相当于把AtomicReferenceFieldUpdater中原有的tail取出，并用新建的节点将原有的tail替代，这个操作是原子性的。\n         // 操作原子性的由来：AtomicReferenceFieldUpdater是一个基于反射的工具类，它能对指定类的指定的volatile引用字段进行原子更新。(这个字段不能是private的)。\n         ClhNode preNode = UPDATER.getAndSet(this, node);\n         if (preNode != null) {\n             preNode.isLocked = Thread.currentThread();\n             LockSupport.park(this);\n             preNode = null;\n             LOCAL.set(node);\n         }\n         // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁\n     }\n\npublic void unLock() {\n\n\n         // 获取当前线程对应的节点\n         // 对应博客中的这句话：申请线程只在本地变量上自旋，避免了多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum\n         // 每次读写操作都必须在多个处理器缓存之间进行缓存同步\n         ClhNode node = LOCAL.get();\n         // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁\n         if (!UPDATER.compareAndSet(this, node, null)) {\n //            System.out.println(\"unlock\\t\" + node.isLocked.getName());\n             LockSupport.unpark(node.isLocked);\n         }\n         node = null;\n     }\n }\n```\n\n### 5、demo：\n\n```java\npublic class ClhLockTest {\n\n    private static int num = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(1000, 1000, 1, TimeUnit.SECONDS, new LinkedBlockingQueue<>(), new DefaultNameThreadFactory(\"SimpleSpinLock\"));\n         CountDownLatch countDownLatch = new CountDownLatch(1000);\n         ClhLock clhLock = new ClhLock();\n         for (int i = 0; i < 1000; i++) {\n             pool.submit(() -> {\n                 clhLock.lock();\n                 num++;\n                 clhLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(num);\n     }\n }\n\n \n```\n\n","slug":"阻塞锁","published":1,"updated":"2019-08-31T05:04:33.756Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck4hufm2g003ivguqaqer9ed8","content":"<h1>阻塞锁</h1>\n<h2>1、阻塞锁优势</h2>\n<p>​\t与自旋锁不同，改变了线程的运行状态。</p>\n<p>​    在JAVA环境中，线程Thread有如下几个状态：</p>\n<ol>\n<li>新建状态</li>\n<li>就绪状态</li>\n<li>运行状态</li>\n<li>阻塞状态</li>\n<li>死亡状态</li>\n</ol>\n<p>​      阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。\n​       JAVA中，能够进入 / 退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock，Object.wait() / notify() ，LockSupport.park() / unpart()</p>\n<h2>2、阻塞锁的优势：</h2>\n<p>​\t在于，阻塞的线程不会占用CPU时间， 不会导致 CPU占用率过高，但进入时间以及恢复时间都要比自旋锁略慢。在竞争激烈的情况下 阻塞锁的性能要明显高于自旋锁。</p>\n<h2>3、阻塞锁应用：</h2>\n<p>​\t理想的情况则是， 在线程竞争不激烈的情况下，使用自旋锁；竞争激烈的情况下使用，阻塞锁。</p>\n<h2>4、阻塞锁的简单实现：</h2>\n<pre><code class=\"language-java\"> public class ClhLock {\n     /**\n      * 定义一个节点，默认的lock状态为true\n      */\n     public static class ClhNode {\n         private volatile Thread isLocked;\n     }\n\n    /**\n      * 尾部节点,只用一个节点即可\n      */\n     private volatile ClhNode tail;\n     private static final ThreadLocal&lt;ClhNode&gt; LOCAL = new ThreadLocal&lt;&gt;();\n     private static final AtomicReferenceFieldUpdater&lt;ClhLock, ClhNode&gt; UPDATER = AtomicReferenceFieldUpdater.newUpdater(ClhLock.class, ClhNode.class, &quot;tail&quot;);\n\n    public void lock() {\n         // 新建节点并将节点与当前线程保存起来\n         ClhNode node = new ClhNode();\n         LOCAL.set(node);\n         // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点\n         // 个人理解=&gt;大概相当于把AtomicReferenceFieldUpdater中原有的tail取出，并用新建的节点将原有的tail替代，这个操作是原子性的。\n         // 操作原子性的由来：AtomicReferenceFieldUpdater是一个基于反射的工具类，它能对指定类的指定的volatile引用字段进行原子更新。(这个字段不能是private的)。\n         ClhNode preNode = UPDATER.getAndSet(this, node);\n         if (preNode != null) {\n             preNode.isLocked = Thread.currentThread();\n             LockSupport.park(this);\n             preNode = null;\n             LOCAL.set(node);\n         }\n         // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁\n     }\n\npublic void unLock() {\n\n\n         // 获取当前线程对应的节点\n         // 对应博客中的这句话：申请线程只在本地变量上自旋，避免了多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum\n         // 每次读写操作都必须在多个处理器缓存之间进行缓存同步\n         ClhNode node = LOCAL.get();\n         // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁\n         if (!UPDATER.compareAndSet(this, node, null)) {\n //            System.out.println(&quot;unlock\\t&quot; + node.isLocked.getName());\n             LockSupport.unpark(node.isLocked);\n         }\n         node = null;\n     }\n }\n</code></pre>\n<h3>5、demo：</h3>\n<pre><code class=\"language-java\">public class ClhLockTest {\n\n    private static int num = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(1000, 1000, 1, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new DefaultNameThreadFactory(&quot;SimpleSpinLock&quot;));\n         CountDownLatch countDownLatch = new CountDownLatch(1000);\n         ClhLock clhLock = new ClhLock();\n         for (int i = 0; i &lt; 1000; i++) {\n             pool.submit(() -&gt; {\n                 clhLock.lock();\n                 num++;\n                 clhLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(num);\n     }\n }\n\n \n</code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1>阻塞锁</h1>\n<h2>1、阻塞锁优势</h2>\n<p>​\t与自旋锁不同，改变了线程的运行状态。</p>\n<p>​    在JAVA环境中，线程Thread有如下几个状态：</p>\n<ol>\n<li>新建状态</li>\n<li>就绪状态</li>\n<li>运行状态</li>\n<li>阻塞状态</li>\n<li>死亡状态</li>\n</ol>\n<p>​      阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。\n​       JAVA中，能够进入 / 退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock，Object.wait() / notify() ，LockSupport.park() / unpart()</p>\n<h2>2、阻塞锁的优势：</h2>\n<p>​\t在于，阻塞的线程不会占用CPU时间， 不会导致 CPU占用率过高，但进入时间以及恢复时间都要比自旋锁略慢。在竞争激烈的情况下 阻塞锁的性能要明显高于自旋锁。</p>\n<h2>3、阻塞锁应用：</h2>\n<p>​\t理想的情况则是， 在线程竞争不激烈的情况下，使用自旋锁；竞争激烈的情况下使用，阻塞锁。</p>\n<h2>4、阻塞锁的简单实现：</h2>\n<pre><code class=\"language-java\"> public class ClhLock {\n     /**\n      * 定义一个节点，默认的lock状态为true\n      */\n     public static class ClhNode {\n         private volatile Thread isLocked;\n     }\n\n    /**\n      * 尾部节点,只用一个节点即可\n      */\n     private volatile ClhNode tail;\n     private static final ThreadLocal&lt;ClhNode&gt; LOCAL = new ThreadLocal&lt;&gt;();\n     private static final AtomicReferenceFieldUpdater&lt;ClhLock, ClhNode&gt; UPDATER = AtomicReferenceFieldUpdater.newUpdater(ClhLock.class, ClhNode.class, &quot;tail&quot;);\n\n    public void lock() {\n         // 新建节点并将节点与当前线程保存起来\n         ClhNode node = new ClhNode();\n         LOCAL.set(node);\n         // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点\n         // 个人理解=&gt;大概相当于把AtomicReferenceFieldUpdater中原有的tail取出，并用新建的节点将原有的tail替代，这个操作是原子性的。\n         // 操作原子性的由来：AtomicReferenceFieldUpdater是一个基于反射的工具类，它能对指定类的指定的volatile引用字段进行原子更新。(这个字段不能是private的)。\n         ClhNode preNode = UPDATER.getAndSet(this, node);\n         if (preNode != null) {\n             preNode.isLocked = Thread.currentThread();\n             LockSupport.park(this);\n             preNode = null;\n             LOCAL.set(node);\n         }\n         // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁\n     }\n\npublic void unLock() {\n\n\n         // 获取当前线程对应的节点\n         // 对应博客中的这句话：申请线程只在本地变量上自旋，避免了多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum\n         // 每次读写操作都必须在多个处理器缓存之间进行缓存同步\n         ClhNode node = LOCAL.get();\n         // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁\n         if (!UPDATER.compareAndSet(this, node, null)) {\n //            System.out.println(&quot;unlock\\t&quot; + node.isLocked.getName());\n             LockSupport.unpark(node.isLocked);\n         }\n         node = null;\n     }\n }\n</code></pre>\n<h3>5、demo：</h3>\n<pre><code class=\"language-java\">public class ClhLockTest {\n\n    private static int num = 0;\n\n    public static void main(String[] args) throws InterruptedException {\n         ThreadPoolExecutor pool = new ThreadPoolExecutor(1000, 1000, 1, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new DefaultNameThreadFactory(&quot;SimpleSpinLock&quot;));\n         CountDownLatch countDownLatch = new CountDownLatch(1000);\n         ClhLock clhLock = new ClhLock();\n         for (int i = 0; i &lt; 1000; i++) {\n             pool.submit(() -&gt; {\n                 clhLock.lock();\n                 num++;\n                 clhLock.unLock();\n                 // 计数减一\n                 countDownLatch.countDown();\n             });\n         }\n         // 要求主线程等待所有任务全部准备好才一起并行执行\n         countDownLatch.await();\n         System.out.println(num);\n     }\n }\n\n \n</code></pre>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck4huflzz0000vguqooxia2zy","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm0g000dvguqlub2njm4"},{"post_id":"ck4hufm030001vguqt8wchv1b","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm0l000ivguqlo78ebu9"},{"post_id":"ck4hufm0f000bvguqxfx25e7w","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm0o000lvguqhknfsmkm"},{"post_id":"ck4hufm070004vguq41gihsf1","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm0q000ovguq4mi290fg"},{"post_id":"ck4hufm080005vguqmglnnrjn","category_id":"ck4hufm0l000hvguqs23ergt4","_id":"ck4hufm0u000uvguq3ecg1f8t"},{"post_id":"ck4hufm0a0006vguq02p6g923","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm0y0011vguq1tp7axh1"},{"post_id":"ck4hufm0t000tvguqct2s13hr","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm110016vguqz3o9qh1n"},{"post_id":"ck4hufm0w000xvguqp7ozx9k9","category_id":"ck4hufm050002vguq45ltg04z","_id":"ck4hufm130019vguqgrwsiele"},{"post_id":"ck4hufm0d000avguqti2evtso","category_id":"ck4hufm0v000wvguqvtwbncgw","_id":"ck4hufm15001evguq0o8fnu71"},{"post_id":"ck4hufm0x000zvguqx2u3hlju","category_id":"ck4hufm0l000hvguqs23ergt4","_id":"ck4hufm17001gvguq5e26s12d"},{"post_id":"ck4hufm0h000fvguqew4x0veo","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm19001kvguq4dp8xfox"},{"post_id":"ck4hufm110017vguq33ka4om2","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1b001nvguqslou0qap"},{"post_id":"ck4hufm14001cvguq1k1fnroy","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1d001svguqh8w3sb4w"},{"post_id":"ck4hufm0j000gvguq8rrmeujq","category_id":"ck4hufm0v000wvguqvtwbncgw","_id":"ck4hufm1e001uvguq9lszz7jn"},{"post_id":"ck4hufm16001fvguqd9izxsjs","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1h001xvguq3mow9o79"},{"post_id":"ck4hufm0n000kvguqksfm1mnd","category_id":"ck4hufm0v000wvguqvtwbncgw","_id":"ck4hufm1k0021vguqh2dwrsw5"},{"post_id":"ck4hufm1a001mvguqgq7c7qfj","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1m0025vguqkxvht0ht"},{"post_id":"ck4hufm0p000nvguqsbfsbgbm","category_id":"ck4hufm1b001ovguqd4tr4yc7","_id":"ck4hufm1o0028vguqe1ea1z6p"},{"post_id":"ck4hufm0s000svguqu5zttes6","category_id":"ck4hufm1b001ovguqd4tr4yc7","_id":"ck4hufm1q002cvguqlmaxksn2"},{"post_id":"ck4hufm1n0027vguqr0p1teb1","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1t002hvguqt98mx623"},{"post_id":"ck4hufm0z0014vguqmzhp91um","category_id":"ck4hufm1l0023vguqh0igydis","_id":"ck4hufm1v002kvguqpadbrq16"},{"post_id":"ck4hufm1q002dvguqgy5hfxsu","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm1x002nvguq0ljozkin"},{"post_id":"ck4hufm17001ivguqrm6hqj1h","category_id":"ck4hufm1l0023vguqh0igydis","_id":"ck4hufm1y002qvguq980zdu8q"},{"post_id":"ck4hufm1s002gvguq49abzq2w","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm21002uvguqyjvfyvup"},{"post_id":"ck4hufm1u002jvguqkb7rr2a3","category_id":"ck4hufm1l0023vguqh0igydis","_id":"ck4hufm24002yvguqs2nje5c6"},{"post_id":"ck4hufm1c001qvguqd7mdz42i","category_id":"ck4hufm1t002ivguqv9ku6r8s","_id":"ck4hufm260032vguqb4vfhk4u"},{"post_id":"ck4hufm1w002mvguqgtvl7qwy","category_id":"ck4hufm1b001ovguqd4tr4yc7","_id":"ck4hufm280035vguqrrfusn32"},{"post_id":"ck4hufm1y002pvguq541al7bv","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2a0038vguqge3fl1g1"},{"post_id":"ck4hufm1e001tvguqzbjjdm9z","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2c003cvguqaiqq56zo"},{"post_id":"ck4hufm20002tvguqtqtlmtiv","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2e003fvguq5ztiwtmu"},{"post_id":"ck4hufm23002xvguqbxnjc28l","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2g003jvguqjj057x6l"},{"post_id":"ck4hufm1f001vvguqw2uhdmk5","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2i003lvguqp643gyec"},{"post_id":"ck4hufm250031vguqpa48ujwv","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2k003nvguqk5bpumln"},{"post_id":"ck4hufm270034vguqu35j3yq0","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2m003pvguqep1e5zus"},{"post_id":"ck4hufm1i001zvguqyln2p5u0","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2n003rvguq2bqhc39t"},{"post_id":"ck4hufm2a0037vguq8ceuvjst","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2o003svguq8sq58bax"},{"post_id":"ck4hufm2c003bvguqfsfrmjc6","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2p003vvguqw7cc0zvj"},{"post_id":"ck4hufm1k0022vguq0oj2n2u2","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2q003wvguq07xfzobk"},{"post_id":"ck4hufm2e003evguqyp09wdoh","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2r003yvguqhc26dwuf"},{"post_id":"ck4hufm2g003ivguqaqer9ed8","category_id":"ck4hufm0r000qvguqnhtyix16","_id":"ck4hufm2r0040vguq52eyw788"},{"post_id":"ck4hufm1o002avguq28dayryw","category_id":"ck4hufm1x002ovguq6sejnhmb","_id":"ck4hufm2s0042vguqb8cz195z"}],"PostTag":[{"post_id":"ck4huflzz0000vguqooxia2zy","tag_id":"ck4hufm060003vguqd5zqx2g4","_id":"ck4hufm0d0009vguqfezdvn2s"},{"post_id":"ck4hufm030001vguqt8wchv1b","tag_id":"ck4hufm0b0008vguqup4xa7ke","_id":"ck4hufm0p000mvguq84sxmov5"},{"post_id":"ck4hufm030001vguqt8wchv1b","tag_id":"ck4hufm060003vguqd5zqx2g4","_id":"ck4hufm0q000pvguqf4senmko"},{"post_id":"ck4hufm070004vguq41gihsf1","tag_id":"ck4hufm0b0008vguqup4xa7ke","_id":"ck4hufm0w000yvguqofezkc2l"},{"post_id":"ck4hufm070004vguq41gihsf1","tag_id":"ck4hufm060003vguqd5zqx2g4","_id":"ck4hufm0y0010vguq61zm865u"},{"post_id":"ck4hufm0t000tvguqct2s13hr","tag_id":"ck4hufm060003vguqd5zqx2g4","_id":"ck4hufm100015vguqheubw54a"},{"post_id":"ck4hufm0w000xvguqp7ozx9k9","tag_id":"ck4hufm060003vguqd5zqx2g4","_id":"ck4hufm120018vguqudcuwvy8"},{"post_id":"ck4hufm080005vguqmglnnrjn","tag_id":"ck4hufm0u000vvguqdy689j7i","_id":"ck4hufm15001dvguqhgxpz5aq"},{"post_id":"ck4hufm0a0006vguq02p6g923","tag_id":"ck4hufm0z0012vguqq142mxqs","_id":"ck4hufm19001lvguq9ysvsr6z"},{"post_id":"ck4hufm0a0006vguq02p6g923","tag_id":"ck4hufm13001bvguqf7truxep","_id":"ck4hufm1c001pvguq2nuvvwi4"},{"post_id":"ck4hufm0d000avguqti2evtso","tag_id":"ck4hufm19001jvguq9lohovh8","_id":"ck4hufm1j0020vguq8p3ozrzg"},{"post_id":"ck4hufm0d000avguqti2evtso","tag_id":"ck4hufm1d001rvguqezhs71ua","_id":"ck4hufm1l0024vguqkm5h9ibm"},{"post_id":"ck4hufm0f000bvguqxfx25e7w","tag_id":"ck4hufm1h001yvguq7f6jp0qu","_id":"ck4hufm1o0029vguqqn3hrknx"},{"post_id":"ck4hufm0h000fvguqew4x0veo","tag_id":"ck4hufm1m0026vguqyahju9cs","_id":"ck4hufm1s002fvguq0zfwvrrg"},{"post_id":"ck4hufm0j000gvguq8rrmeujq","tag_id":"ck4hufm19001jvguq9lohovh8","_id":"ck4hufm20002svguqxh56kvhd"},{"post_id":"ck4hufm0j000gvguq8rrmeujq","tag_id":"ck4hufm1d001rvguqezhs71ua","_id":"ck4hufm22002wvguqz9plty6l"},{"post_id":"ck4hufm0n000kvguqksfm1mnd","tag_id":"ck4hufm1d001rvguqezhs71ua","_id":"ck4hufm250030vguq65ufncko"},{"post_id":"ck4hufm0p000nvguqsbfsbgbm","tag_id":"ck4hufm24002zvguqc4rn5l9a","_id":"ck4hufm2b0039vguqe48ww9c5"},{"post_id":"ck4hufm0s000svguqu5zttes6","tag_id":"ck4hufm24002zvguqc4rn5l9a","_id":"ck4hufm2f003gvguqpfnplwxl"},{"post_id":"ck4hufm0x000zvguqx2u3hlju","tag_id":"ck4hufm2d003dvguqg23j1kvh","_id":"ck4hufm2j003mvguqa4wpc26q"},{"post_id":"ck4hufm0z0014vguqmzhp91um","tag_id":"ck4hufm2h003kvguqyg62ara8","_id":"ck4hufm2n003qvguq9wc8o7d5"},{"post_id":"ck4hufm110017vguq33ka4om2","tag_id":"ck4hufm2l003ovguqsmis8s6y","_id":"ck4hufm2p003uvguq2dtzs1n0"},{"post_id":"ck4hufm14001cvguq1k1fnroy","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm2r003zvguqyp1xybxw"},{"post_id":"ck4hufm16001fvguqd9izxsjs","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm2t0043vguqwq98g7s6"},{"post_id":"ck4hufm17001ivguqrm6hqj1h","tag_id":"ck4hufm2h003kvguqyg62ara8","_id":"ck4hufm2u0045vguqzz7gosil"},{"post_id":"ck4hufm1a001mvguqgq7c7qfj","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm2v0047vguqvsmm0twr"},{"post_id":"ck4hufm1c001qvguqd7mdz42i","tag_id":"ck4hufm2v0046vguqoe3aft55","_id":"ck4hufm2w0049vguqy7gixkzn"},{"post_id":"ck4hufm1e001tvguqzbjjdm9z","tag_id":"ck4hufm2w0048vguq1u35jqai","_id":"ck4hufm2x004bvguqimhi8v84"},{"post_id":"ck4hufm1f001vvguqw2uhdmk5","tag_id":"ck4hufm2x004avguqc5tuqbo4","_id":"ck4hufm2y004evguqd8phl0br"},{"post_id":"ck4hufm1f001vvguqw2uhdmk5","tag_id":"ck4hufm2x004cvguqpjm2velf","_id":"ck4hufm2z004fvguqscv1ybsx"},{"post_id":"ck4hufm1i001zvguqyln2p5u0","tag_id":"ck4hufm2y004dvguq4z17s0di","_id":"ck4hufm30004ivguqjn5tyn37"},{"post_id":"ck4hufm1i001zvguqyln2p5u0","tag_id":"ck4hufm2z004gvguqc5kjqwem","_id":"ck4hufm31004jvguq7df3m7b0"},{"post_id":"ck4hufm1k0022vguq0oj2n2u2","tag_id":"ck4hufm2x004avguqc5tuqbo4","_id":"ck4hufm31004lvguqxil0evxo"},{"post_id":"ck4hufm1n0027vguqr0p1teb1","tag_id":"ck4hufm31004kvguqagnhfwuq","_id":"ck4hufm32004nvguqdsp9uze3"},{"post_id":"ck4hufm1o002avguq28dayryw","tag_id":"ck4hufm2x004avguqc5tuqbo4","_id":"ck4hufm34004qvguqoj23g0xn"},{"post_id":"ck4hufm1o002avguq28dayryw","tag_id":"ck4hufm2x004cvguqpjm2velf","_id":"ck4hufm34004rvguql19rdc5c"},{"post_id":"ck4hufm1q002dvguqgy5hfxsu","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm35004tvguqy2yuxhli"},{"post_id":"ck4hufm1s002gvguq49abzq2w","tag_id":"ck4hufm35004svguqzl4iq6fa","_id":"ck4hufm36004vvguqcsrl1vs0"},{"post_id":"ck4hufm1u002jvguqkb7rr2a3","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm37004yvguq3js8c525"},{"post_id":"ck4hufm1u002jvguqkb7rr2a3","tag_id":"ck4hufm2h003kvguqyg62ara8","_id":"ck4hufm38004zvguq3xjg21np"},{"post_id":"ck4hufm1w002mvguqgtvl7qwy","tag_id":"ck4hufm37004xvguqbgh1d1vr","_id":"ck4hufm390052vguqqsgbqm2f"},{"post_id":"ck4hufm1w002mvguqgtvl7qwy","tag_id":"ck4hufm380050vguqzbwe9ac4","_id":"ck4hufm390053vguqbi963wgw"},{"post_id":"ck4hufm1y002pvguq541al7bv","tag_id":"ck4hufm2x004avguqc5tuqbo4","_id":"ck4hufm3b0056vguqnr31amvy"},{"post_id":"ck4hufm1y002pvguq541al7bv","tag_id":"ck4hufm390054vguqf8ulhl80","_id":"ck4hufm3b0057vguqv2zqkoh4"},{"post_id":"ck4hufm20002tvguqtqtlmtiv","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm3c0059vguqaa71d3z0"},{"post_id":"ck4hufm23002xvguqbxnjc28l","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm3d005bvguq6oonjtjd"},{"post_id":"ck4hufm250031vguqpa48ujwv","tag_id":"ck4hufm3c005avguq6l4txgp0","_id":"ck4hufm3e005evguqhgj13jxs"},{"post_id":"ck4hufm250031vguqpa48ujwv","tag_id":"ck4hufm2x004avguqc5tuqbo4","_id":"ck4hufm3e005fvguqna53gliy"},{"post_id":"ck4hufm270034vguqu35j3yq0","tag_id":"ck4hufm3e005dvguq4b8iy767","_id":"ck4hufm3g005ivguqx84l2lw2"},{"post_id":"ck4hufm270034vguqu35j3yq0","tag_id":"ck4hufm3f005gvguqd8jn93os","_id":"ck4hufm3g005jvguq5lm8qzn1"},{"post_id":"ck4hufm2a0037vguq8ceuvjst","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm3h005lvguq3i225azb"},{"post_id":"ck4hufm2c003bvguqfsfrmjc6","tag_id":"ck4hufm3h005kvguq502no7bk","_id":"ck4hufm3i005nvguq4077fksk"},{"post_id":"ck4hufm2e003evguqyp09wdoh","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm3j005pvguqd683iwnq"},{"post_id":"ck4hufm2g003ivguqaqer9ed8","tag_id":"ck4hufm2o003tvguqsu06jbg3","_id":"ck4hufm3j005qvguqr2qykmzb"}],"Tag":[{"name":"HADOOP","_id":"ck4hufm060003vguqd5zqx2g4"},{"name":"HDFS","_id":"ck4hufm0b0008vguqup4xa7ke"},{"name":"git","_id":"ck4hufm0u000vvguqdy689j7i"},{"name":"并发","_id":"ck4hufm0z0012vguqq142mxqs"},{"name":"线程安全","_id":"ck4hufm13001bvguqf7truxep"},{"name":"nacos-config","_id":"ck4hufm19001jvguq9lohovh8"},{"name":"SpringCloud","_id":"ck4hufm1d001rvguqezhs71ua"},{"name":"Spark","_id":"ck4hufm1h001yvguq7f6jp0qu"},{"name":"spring","_id":"ck4hufm1m0026vguqyahju9cs"},{"name":"TCP/IP","_id":"ck4hufm24002zvguqc4rn5l9a"},{"name":"maven","_id":"ck4hufm2d003dvguqg23j1kvh"},{"name":"mysql","_id":"ck4hufm2h003kvguqyg62ara8"},{"name":"JDK1.8新特性","_id":"ck4hufm2l003ovguqsmis8s6y"},{"name":"锁","_id":"ck4hufm2o003tvguqsu06jbg3"},{"name":"分布式","_id":"ck4hufm2v0046vguqoe3aft55"},{"name":"可信计算","_id":"ck4hufm2w0048vguq1u35jqai"},{"name":"可信","_id":"ck4hufm2x004avguqc5tuqbo4"},{"name":"密码学","_id":"ck4hufm2x004cvguqpjm2velf"},{"name":"可靠","_id":"ck4hufm2y004dvguq4z17s0di"},{"name":"容错","_id":"ck4hufm2z004gvguqc5kjqwem"},{"name":"内存模型","_id":"ck4hufm31004kvguqagnhfwuq"},{"name":"文件上传","_id":"ck4hufm35004svguqzl4iq6fa"},{"name":"IO","_id":"ck4hufm37004xvguqbgh1d1vr"},{"name":"阻塞与非阻塞","_id":"ck4hufm380050vguqzbwe9ac4"},{"name":"加密算法","_id":"ck4hufm390054vguqf8ulhl80"},{"name":"网络安全","_id":"ck4hufm3c005avguq6l4txgp0"},{"name":"java","_id":"ck4hufm3e005dvguq4b8iy767"},{"name":"多线程","_id":"ck4hufm3f005gvguqd8jn93os"},{"name":"线程","_id":"ck4hufm3h005kvguq502no7bk"}]}}